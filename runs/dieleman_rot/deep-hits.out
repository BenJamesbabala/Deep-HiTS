Couldn't import dot_parser, loading of dot files will not be possible.
nkerns =  [32 64 64 64] (4,)
validation set =  100000
... building the model
input_data (50, 4, 21, 21)
layer0 (filter)(pool)=  (32, 4, 4, 4) (2, 2)
output =  12
layer1 (filter)(pool) =  (64, 32, 3, 3) (1, 1)
output=  14
layer2 (filter)(pool) =  (64, 64, 3, 3) (2, 2)
output=  8
Hidden units:  64
Dropout ON
Epoch  0 , iteration  0 training @ iter = 0 , loss =  0.693147182465
training @ iter = 0 , error =  0.52
--> train minibatch error =  0.52  at iter  0
-->  0 50 chunk_10_50000.pkl
--> train minibatch error =  0.22  at iter  1
-->  0 100 chunk_10_50000.pkl
--> train minibatch error =  0.22  at iter  2
-->  0 150 chunk_10_50000.pkl
--> train minibatch error =  0.52  at iter  3
-->  0 200 chunk_10_50000.pkl
--> train minibatch error =  0.54  at iter  4
-->  0 250 chunk_10_50000.pkl
--> train minibatch error =  0.48  at iter  5
-->  0 300 chunk_10_50000.pkl
--> train minibatch error =  0.42  at iter  6
-->  0 350 chunk_10_50000.pkl
--> train minibatch error =  0.48  at iter  7
-->  0 400 chunk_10_50000.pkl
--> train minibatch error =  0.44  at iter  8
-->  0 450 chunk_10_50000.pkl
--> train minibatch error =  0.36  at iter  9
-->  0 500 chunk_10_50000.pkl
--> train minibatch error =  0.56  at iter  10
-->  0 550 chunk_10_50000.pkl
--> train minibatch error =  0.5  at iter  11
-->  0 600 chunk_10_50000.pkl
--> train minibatch error =  0.18  at iter  12
-->  0 650 chunk_10_50000.pkl
--> train minibatch error =  0.52  at iter  13
-->  0 700 chunk_10_50000.pkl
--> train minibatch error =  0.52  at iter  14
-->  0 750 chunk_10_50000.pkl
--> train minibatch error =  0.16  at iter  15
-->  0 800 chunk_10_50000.pkl
--> train minibatch error =  0.56  at iter  16
-->  0 850 chunk_10_50000.pkl
--> train minibatch error =  0.58  at iter  17
-->  0 900 chunk_10_50000.pkl
--> train minibatch error =  0.38  at iter  18
-->  0 950 chunk_10_50000.pkl
--> train minibatch error =  0.38  at iter  19
-->  0 1000 chunk_10_50000.pkl
--> train minibatch error =  0.48  at iter  20
-->  0 1050 chunk_10_50000.pkl
--> train minibatch error =  0.5  at iter  21
-->  0 1100 chunk_10_50000.pkl
--> train minibatch error =  0.42  at iter  22
-->  0 1150 chunk_10_50000.pkl
--> train minibatch error =  0.38  at iter  23
-->  0 1200 chunk_10_50000.pkl
--> train minibatch error =  0.44  at iter  24
-->  0 1250 chunk_10_50000.pkl
--> train minibatch error =  0.58  at iter  25
-->  0 1300 chunk_10_50000.pkl
--> train minibatch error =  0.28  at iter  26
-->  0 1350 chunk_10_50000.pkl
--> train minibatch error =  0.28  at iter  27
-->  0 1400 chunk_10_50000.pkl
--> train minibatch error =  0.4  at iter  28
-->  0 1450 chunk_10_50000.pkl
--> train minibatch error =  0.44  at iter  29
-->  0 1500 chunk_10_50000.pkl
--> train minibatch error =  0.56  at iter  30
-->  0 1550 chunk_10_50000.pkl
--> train minibatch error =  0.52  at iter  31
-->  0 1600 chunk_10_50000.pkl
--> train minibatch error =  0.38  at iter  32
-->  0 1650 chunk_10_50000.pkl
--> train minibatch error =  0.36  at iter  33
-->  0 1700 chunk_10_50000.pkl
--> train minibatch error =  0.5  at iter  34
-->  0 1750 chunk_10_50000.pkl
--> train minibatch error =  0.44  at iter  35
-->  0 1800 chunk_10_50000.pkl
--> train minibatch error =  0.38  at iter  36
-->  0 1850 chunk_10_50000.pkl
--> train minibatch error =  0.16  at iter  37
-->  0 1900 chunk_10_50000.pkl
--> train minibatch error =  0.26  at iter  38
-->  0 1950 chunk_10_50000.pkl
--> train minibatch error =  0.56  at iter  39
-->  0 2000 chunk_10_50000.pkl
--> train minibatch error =  0.52  at iter  40
-->  0 2050 chunk_10_50000.pkl
--> train minibatch error =  0.36  at iter  41
-->  0 2100 chunk_10_50000.pkl
--> train minibatch error =  0.26  at iter  42
-->  0 2150 chunk_10_50000.pkl
--> train minibatch error =  0.56  at iter  43
-->  0 2200 chunk_10_50000.pkl
--> train minibatch error =  0.34  at iter  44
-->  0 2250 chunk_10_50000.pkl
--> train minibatch error =  0.22  at iter  45
-->  0 2300 chunk_10_50000.pkl
--> train minibatch error =  0.12  at iter  46
-->  0 2350 chunk_10_50000.pkl
--> train minibatch error =  0.34  at iter  47
-->  0 2400 chunk_10_50000.pkl
--> train minibatch error =  0.2  at iter  48
-->  0 2450 chunk_10_50000.pkl
--> train minibatch error =  0.26  at iter  49
-->  0 2500 chunk_10_50000.pkl
--> train minibatch error =  0.2  at iter  50
-->  0 2550 chunk_10_50000.pkl
--> train minibatch error =  0.16  at iter  51
-->  0 2600 chunk_10_50000.pkl
--> train minibatch error =  0.18  at iter  54
-->  0 2750 chunk_10_50000.pkl
--> train minibatch error =  0.12  at iter  55
-->  0 2800 chunk_10_50000.pkl
--> train minibatch error =  0.14  at iter  58
-->  0 2950 chunk_10_50000.pkl
--> train minibatch error =  0.4  at iter  59
-->  0 3000 chunk_10_50000.pkl
--> train minibatch error =  0.34  at iter  60
-->  0 3050 chunk_10_50000.pkl
--> train minibatch error =  0.32  at iter  61
-->  0 3100 chunk_10_50000.pkl
--> train minibatch error =  0.5  at iter  62
-->  0 3150 chunk_10_50000.pkl
--> train minibatch error =  0.38  at iter  63
-->  0 3200 chunk_10_50000.pkl
--> train minibatch error =  0.42  at iter  64
-->  0 3250 chunk_10_50000.pkl
--> train minibatch error =  0.36  at iter  65
-->  0 3300 chunk_10_50000.pkl
--> train minibatch error =  0.38  at iter  67
-->  0 3400 chunk_10_50000.pkl
--> train minibatch error =  0.3  at iter  68
-->  0 3450 chunk_10_50000.pkl
--> train minibatch error =  0.5  at iter  69
-->  0 3500 chunk_10_50000.pkl
--> train minibatch error =  0.38  at iter  70
-->  0 3550 chunk_10_50000.pkl
--> train minibatch error =  0.36  at iter  71
-->  0 3600 chunk_10_50000.pkl
--> train minibatch error =  0.14  at iter  74
-->  0 3750 chunk_10_50000.pkl
--> train minibatch error =  0.18  at iter  75
-->  0 3800 chunk_10_50000.pkl
--> train minibatch error =  0.36  at iter  76
-->  0 3850 chunk_10_50000.pkl
--> train minibatch error =  0.42  at iter  77
-->  0 3900 chunk_10_50000.pkl
--> train minibatch error =  0.24  at iter  78
-->  0 3950 chunk_10_50000.pkl
--> train minibatch error =  0.24  at iter  79
-->  0 4000 chunk_10_50000.pkl
--> train minibatch error =  0.52  at iter  80
-->  0 4050 chunk_10_50000.pkl
--> train minibatch error =  0.46  at iter  81
-->  0 4100 chunk_10_50000.pkl
--> train minibatch error =  0.36  at iter  82
-->  0 4150 chunk_10_50000.pkl
--> train minibatch error =  0.24  at iter  83
-->  0 4200 chunk_10_50000.pkl
--> train minibatch error =  0.26  at iter  84
-->  0 4250 chunk_10_50000.pkl
--> train minibatch error =  0.12  at iter  85
-->  0 4300 chunk_10_50000.pkl
--> train minibatch error =  0.14  at iter  86
-->  0 4350 chunk_10_50000.pkl
--> train minibatch error =  0.28  at iter  87
-->  0 4400 chunk_10_50000.pkl
--> train minibatch error =  0.2  at iter  88
-->  0 4450 chunk_10_50000.pkl
--> train minibatch error =  0.22  at iter  90
-->  0 4550 chunk_10_50000.pkl
--> train minibatch error =  0.2  at iter  91
-->  0 4600 chunk_10_50000.pkl
--> train minibatch error =  0.26  at iter  92
-->  0 4650 chunk_10_50000.pkl
--> train minibatch error =  0.2  at iter  93
-->  0 4700 chunk_10_50000.pkl
--> train minibatch error =  0.12  at iter  94
-->  0 4750 chunk_10_50000.pkl
--> train minibatch error =  0.16  at iter  97
-->  0 4900 chunk_10_50000.pkl
--> train minibatch error =  0.46  at iter  98
-->  0 4950 chunk_10_50000.pkl
--> train minibatch error =  0.12  at iter  99
-->  0 5000 chunk_10_50000.pkl
training @ iter = 100 , loss =  0.228121325374
training @ iter = 100 , error =  0.0
--> train minibatch error =  0.32  at iter  104
-->  0 5250 chunk_10_50000.pkl
--> train minibatch error =  0.18  at iter  105
-->  0 5300 chunk_10_50000.pkl
--> train minibatch error =  0.18  at iter  106
-->  0 5350 chunk_10_50000.pkl
--> train minibatch error =  0.46  at iter  107
-->  0 5400 chunk_10_50000.pkl
--> train minibatch error =  0.2  at iter  108
-->  0 5450 chunk_10_50000.pkl
--> train minibatch error =  0.16  at iter  109
-->  0 5500 chunk_10_50000.pkl
--> train minibatch error =  0.5  at iter  110
-->  0 5550 chunk_10_50000.pkl
--> train minibatch error =  0.16  at iter  111
-->  0 5600 chunk_10_50000.pkl
--> train minibatch error =  0.26  at iter  113
-->  0 5700 chunk_10_50000.pkl
--> train minibatch error =  0.2  at iter  114
-->  0 5750 chunk_10_50000.pkl
--> train minibatch error =  0.14  at iter  115
-->  0 5800 chunk_10_50000.pkl
--> train minibatch error =  0.4  at iter  116
-->  0 5850 chunk_10_50000.pkl
--> train minibatch error =  0.14  at iter  117
-->  0 5900 chunk_10_50000.pkl
--> train minibatch error =  0.2  at iter  118
-->  0 5950 chunk_10_50000.pkl
--> train minibatch error =  0.44  at iter  119
-->  0 6000 chunk_10_50000.pkl
--> train minibatch error =  0.16  at iter  120
-->  0 6050 chunk_10_50000.pkl
--> train minibatch error =  0.18  at iter  128
-->  0 6450 chunk_10_50000.pkl
--> train minibatch error =  0.2  at iter  129
-->  0 6500 chunk_10_50000.pkl
--> train minibatch error =  0.22  at iter  130
-->  0 6550 chunk_10_50000.pkl
--> train minibatch error =  0.36  at iter  131
-->  0 6600 chunk_10_50000.pkl
--> train minibatch error =  0.12  at iter  132
-->  0 6650 chunk_10_50000.pkl
--> train minibatch error =  0.3  at iter  133
-->  0 6700 chunk_10_50000.pkl
--> train minibatch error =  0.32  at iter  134
-->  0 6750 chunk_10_50000.pkl
--> train minibatch error =  0.16  at iter  135
-->  0 6800 chunk_10_50000.pkl
--> train minibatch error =  0.14  at iter  138
-->  0 6950 chunk_10_50000.pkl
--> train minibatch error =  0.12  at iter  139
-->  0 7000 chunk_10_50000.pkl
--> train minibatch error =  0.14  at iter  140
-->  0 7050 chunk_10_50000.pkl
--> train minibatch error =  0.2  at iter  141
-->  0 7100 chunk_10_50000.pkl
--> train minibatch error =  0.12  at iter  142
-->  0 7150 chunk_10_50000.pkl
--> train minibatch error =  0.18  at iter  143
-->  0 7200 chunk_10_50000.pkl
--> train minibatch error =  0.16  at iter  144
-->  0 7250 chunk_10_50000.pkl
--> train minibatch error =  0.24  at iter  146
-->  0 7350 chunk_10_50000.pkl
--> train minibatch error =  0.16  at iter  147
-->  0 7400 chunk_10_50000.pkl
--> train minibatch error =  0.2  at iter  149
-->  0 7500 chunk_10_50000.pkl
--> train minibatch error =  0.12  at iter  150
-->  0 7550 chunk_10_50000.pkl
--> train minibatch error =  0.16  at iter  156
-->  0 7850 chunk_10_50000.pkl
--> train minibatch error =  0.22  at iter  159
-->  0 8000 chunk_10_50000.pkl
--> train minibatch error =  0.12  at iter  160
-->  0 8050 chunk_10_50000.pkl
--> train minibatch error =  0.12  at iter  161
-->  0 8100 chunk_10_50000.pkl
--> train minibatch error =  0.24  at iter  162
-->  0 8150 chunk_10_50000.pkl
--> train minibatch error =  0.16  at iter  163
-->  0 8200 chunk_10_50000.pkl
--> train minibatch error =  0.12  at iter  164
-->  0 8250 chunk_10_50000.pkl
--> train minibatch error =  0.26  at iter  165
-->  0 8300 chunk_10_50000.pkl
--> train minibatch error =  0.16  at iter  166
-->  0 8350 chunk_10_50000.pkl
--> train minibatch error =  0.12  at iter  168
-->  0 8450 chunk_10_50000.pkl
--> train minibatch error =  0.28  at iter  169
-->  0 8500 chunk_10_50000.pkl
--> train minibatch error =  0.16  at iter  172
-->  0 8650 chunk_10_50000.pkl
--> train minibatch error =  0.14  at iter  178
-->  0 8950 chunk_10_50000.pkl
--> train minibatch error =  0.14  at iter  182
-->  0 9150 chunk_10_50000.pkl
--> train minibatch error =  0.14  at iter  183
-->  0 9200 chunk_10_50000.pkl
--> train minibatch error =  0.28  at iter  185
-->  0 9300 chunk_10_50000.pkl
--> train minibatch error =  0.26  at iter  186
-->  0 9350 chunk_10_50000.pkl
--> train minibatch error =  0.16  at iter  187
-->  0 9400 chunk_10_50000.pkl
--> train minibatch error =  0.14  at iter  188
-->  0 9450 chunk_10_50000.pkl
--> train minibatch error =  0.2  at iter  189
-->  0 9500 chunk_10_50000.pkl
--> train minibatch error =  0.22  at iter  190
-->  0 9550 chunk_10_50000.pkl
--> train minibatch error =  0.16  at iter  192
-->  0 9650 chunk_10_50000.pkl
--> train minibatch error =  0.14  at iter  195
-->  0 9800 chunk_10_50000.pkl
--> train minibatch error =  0.18  at iter  196
-->  0 9850 chunk_10_50000.pkl
--> train minibatch error =  0.24  at iter  197
-->  0 9900 chunk_10_50000.pkl
--> train minibatch error =  0.24  at iter  198
-->  0 9950 chunk_10_50000.pkl
training @ iter = 200 , loss =  0.103359624743
training @ iter = 200 , error =  0.02
--> train minibatch error =  0.12  at iter  202
-->  0 10150 chunk_10_50000.pkl
--> train minibatch error =  0.12  at iter  203
-->  0 10200 chunk_10_50000.pkl
--> train minibatch error =  0.16  at iter  204
-->  0 10250 chunk_10_50000.pkl
--> train minibatch error =  0.14  at iter  207
-->  0 10400 chunk_10_50000.pkl
--> train minibatch error =  0.12  at iter  208
-->  0 10450 chunk_10_50000.pkl
--> train minibatch error =  0.16  at iter  216
-->  0 10850 chunk_10_50000.pkl
--> train minibatch error =  0.14  at iter  232
-->  0 11650 chunk_10_50000.pkl
--> train minibatch error =  0.16  at iter  237
-->  0 11900 chunk_10_50000.pkl
--> train minibatch error =  0.12  at iter  246
-->  0 12350 chunk_10_50000.pkl
--> train minibatch error =  0.12  at iter  257
-->  0 12900 chunk_10_50000.pkl
--> train minibatch error =  0.14  at iter  265
-->  0 13300 chunk_10_50000.pkl
--> train minibatch error =  0.16  at iter  267
-->  0 13400 chunk_10_50000.pkl
--> train minibatch error =  0.12  at iter  273
-->  0 13700 chunk_10_50000.pkl
--> train minibatch error =  0.12  at iter  274
-->  0 13750 chunk_10_50000.pkl
--> train minibatch error =  0.14  at iter  278
-->  0 13950 chunk_10_50000.pkl
--> train minibatch error =  0.24  at iter  288
-->  0 14450 chunk_10_50000.pkl
--> train minibatch error =  0.12  at iter  289
-->  0 14500 chunk_10_50000.pkl
--> train minibatch error =  0.12  at iter  291
-->  0 14600 chunk_10_50000.pkl
--> train minibatch error =  0.18  at iter  296
-->  0 14850 chunk_10_50000.pkl
training @ iter = 300 , loss =  0.148421883583
training @ iter = 300 , error =  0.02
--> train minibatch error =  0.12  at iter  301
-->  0 15100 chunk_10_50000.pkl
--> train minibatch error =  0.26  at iter  309
-->  0 15500 chunk_10_50000.pkl
--> train minibatch error =  0.14  at iter  311
-->  0 15600 chunk_10_50000.pkl
--> train minibatch error =  0.12  at iter  312
-->  0 15650 chunk_10_50000.pkl
--> train minibatch error =  0.18  at iter  319
-->  0 16000 chunk_10_50000.pkl
--> train minibatch error =  0.14  at iter  327
-->  0 16400 chunk_10_50000.pkl
--> train minibatch error =  0.12  at iter  336
-->  0 16850 chunk_10_50000.pkl
--> train minibatch error =  0.12  at iter  350
-->  0 17550 chunk_10_50000.pkl
--> train minibatch error =  0.2  at iter  370
-->  0 18550 chunk_10_50000.pkl
--> train minibatch error =  0.22  at iter  371
-->  0 18600 chunk_10_50000.pkl
--> train minibatch error =  0.12  at iter  374
-->  0 18750 chunk_10_50000.pkl
--> train minibatch error =  0.12  at iter  392
-->  0 19650 chunk_10_50000.pkl
--> train minibatch error =  0.14  at iter  393
-->  0 19700 chunk_10_50000.pkl
training @ iter = 400 , loss =  0.0505222119391
training @ iter = 400 , error =  0.02
--> train minibatch error =  0.14  at iter  405
-->  0 20300 chunk_10_50000.pkl
--> train minibatch error =  0.12  at iter  415
-->  0 20800 chunk_10_50000.pkl
--> train minibatch error =  0.18  at iter  478
-->  0 23950 chunk_10_50000.pkl
--> train minibatch error =  0.14  at iter  480
-->  0 24050 chunk_10_50000.pkl
training @ iter = 500 , loss =  0.252955794334
training @ iter = 500 , error =  0.08
--> train minibatch error =  0.12  at iter  508
-->  0 25450 chunk_10_50000.pkl
--> train minibatch error =  0.12  at iter  513
-->  0 25700 chunk_10_50000.pkl
--> train minibatch error =  0.14  at iter  529
-->  0 26500 chunk_10_50000.pkl
--> train minibatch error =  0.12  at iter  536
-->  0 26850 chunk_10_50000.pkl
--> train minibatch error =  0.14  at iter  577
-->  0 28900 chunk_10_50000.pkl
--> train minibatch error =  0.14  at iter  578
-->  0 28950 chunk_10_50000.pkl
--> train minibatch error =  0.12  at iter  580
-->  0 29050 chunk_10_50000.pkl
training @ iter = 600 , loss =  0.0605398565531
training @ iter = 600 , error =  0.0
--> train minibatch error =  0.24  at iter  623
-->  0 31200 chunk_10_50000.pkl
--> train minibatch error =  0.24  at iter  633
-->  0 31700 chunk_10_50000.pkl
--> train minibatch error =  0.12  at iter  651
-->  0 32600 chunk_10_50000.pkl
--> train minibatch error =  0.12  at iter  654
-->  0 32750 chunk_10_50000.pkl
--> train minibatch error =  0.12  at iter  655
-->  0 32800 chunk_10_50000.pkl
--> train minibatch error =  0.16  at iter  658
-->  0 32950 chunk_10_50000.pkl
--> train minibatch error =  0.14  at iter  671
-->  0 33600 chunk_10_50000.pkl
--> train minibatch error =  0.16  at iter  688
-->  0 34450 chunk_10_50000.pkl
--> train minibatch error =  0.22  at iter  694
-->  0 34750 chunk_10_50000.pkl
training @ iter = 700 , loss =  0.0650301426649
training @ iter = 700 , error =  0.0
--> train minibatch error =  0.14  at iter  703
-->  0 35200 chunk_10_50000.pkl
--> train minibatch error =  0.14  at iter  708
-->  0 35450 chunk_10_50000.pkl
--> train minibatch error =  0.12  at iter  761
-->  0 38100 chunk_10_50000.pkl
--> train minibatch error =  0.16  at iter  768
-->  0 38450 chunk_10_50000.pkl
--> train minibatch error =  0.3  at iter  771
-->  0 38600 chunk_10_50000.pkl
--> train minibatch error =  0.18  at iter  772
-->  0 38650 chunk_10_50000.pkl
--> train minibatch error =  0.3  at iter  777
-->  0 38900 chunk_10_50000.pkl
training @ iter = 800 , loss =  0.0506993308663
training @ iter = 800 , error =  0.0
--> train minibatch error =  0.24  at iter  812
-->  0 40650 chunk_10_50000.pkl
--> train minibatch error =  0.18  at iter  864
-->  0 43250 chunk_10_50000.pkl
--> train minibatch error =  0.2  at iter  865
-->  0 43300 chunk_10_50000.pkl
--> train minibatch error =  0.16  at iter  866
-->  0 43350 chunk_10_50000.pkl
--> train minibatch error =  0.16  at iter  876
-->  0 43850 chunk_10_50000.pkl
--> train minibatch error =  0.14  at iter  878
-->  0 43950 chunk_10_50000.pkl
--> train minibatch error =  0.16  at iter  879
-->  0 44000 chunk_10_50000.pkl
training @ iter = 900 , loss =  0.143725946546
training @ iter = 900 , error =  0.04
--> train minibatch error =  0.16  at iter  925
-->  0 46300 chunk_10_50000.pkl
training @ iter = 1000 , loss =  0.154450640082
training @ iter = 1000 , error =  0.04
--> train minibatch error =  0.24  at iter  1014
-->  1 750 chunk_11_50000.pkl
training @ iter = 1100 , loss =  0.0252385418862
training @ iter = 1100 , error =  0.0
--> train minibatch error =  0.3  at iter  1108
-->  1 5450 chunk_11_50000.pkl
--> train minibatch error =  0.26  at iter  1109
-->  1 5500 chunk_11_50000.pkl
--> train minibatch error =  0.14  at iter  1158
-->  1 7950 chunk_11_50000.pkl
--> train minibatch error =  0.12  at iter  1186
-->  1 9350 chunk_11_50000.pkl
--> train minibatch error =  0.14  at iter  1193
-->  1 9700 chunk_11_50000.pkl
--> train minibatch error =  0.14  at iter  1194
-->  1 9750 chunk_11_50000.pkl
training @ iter = 1200 , loss =  0.0229717306793
training @ iter = 1200 , error =  0.0
--> train minibatch error =  0.16  at iter  1202
-->  1 10150 chunk_11_50000.pkl
training @ iter = 1300 , loss =  0.0432481765747
training @ iter = 1300 , error =  0.0
training @ iter = 1400 , loss =  0.0152248367667
training @ iter = 1400 , error =  0.0
--> train minibatch error =  0.14  at iter  1483
-->  1 24200 chunk_11_50000.pkl
training @ iter = 1500 , loss =  0.0793363824487
training @ iter = 1500 , error =  0.02
--> train minibatch error =  0.14  at iter  1549
-->  1 27500 chunk_11_50000.pkl
training @ iter = 1600 , loss =  0.0219989996403
training @ iter = 1600 , error =  0.0
--> train minibatch error =  0.14  at iter  1684
-->  1 34250 chunk_11_50000.pkl
training @ iter = 1700 , loss =  0.0443815737963
training @ iter = 1700 , error =  0.02
--> train minibatch error =  0.14  at iter  1706
-->  1 35350 chunk_11_50000.pkl
--> train minibatch error =  0.12  at iter  1707
-->  1 35400 chunk_11_50000.pkl
--> train minibatch error =  0.2  at iter  1708
-->  1 35450 chunk_11_50000.pkl
--> train minibatch error =  0.16  at iter  1787
-->  1 39400 chunk_11_50000.pkl
--> train minibatch error =  0.26  at iter  1788
-->  1 39450 chunk_11_50000.pkl
--> train minibatch error =  0.14  at iter  1789
-->  1 39500 chunk_11_50000.pkl
--> train minibatch error =  0.14  at iter  1792
-->  1 39650 chunk_11_50000.pkl
--> train minibatch error =  0.18  at iter  1795
-->  1 39800 chunk_11_50000.pkl
--> train minibatch error =  0.18  at iter  1797
-->  1 39900 chunk_11_50000.pkl
training @ iter = 1800 , loss =  0.17874597013
training @ iter = 1800 , error =  0.04
training @ iter = 1900 , loss =  0.170366331935
training @ iter = 1900 , error =  0.06
--> train minibatch error =  0.12  at iter  1949
-->  1 47500 chunk_11_50000.pkl
training @ iter = 2000 , loss =  0.172307640314
training @ iter = 2000 , error =  0.1
--> train minibatch error =  0.12  at iter  2001
-->  2 100 chunk_12_50000.pkl
--> train minibatch error =  0.18  at iter  2074
-->  2 3750 chunk_12_50000.pkl
training @ iter = 2100 , loss =  0.298938483
training @ iter = 2100 , error =  0.12
--> train minibatch error =  0.12  at iter  2100
-->  2 5050 chunk_12_50000.pkl
--> train minibatch error =  0.12  at iter  2128
-->  2 6450 chunk_12_50000.pkl
--> train minibatch error =  0.2  at iter  2129
-->  2 6500 chunk_12_50000.pkl
--> train minibatch error =  0.22  at iter  2130
-->  2 6550 chunk_12_50000.pkl
--> train minibatch error =  0.22  at iter  2131
-->  2 6600 chunk_12_50000.pkl
--> train minibatch error =  0.18  at iter  2132
-->  2 6650 chunk_12_50000.pkl
--> train minibatch error =  0.12  at iter  2142
-->  2 7150 chunk_12_50000.pkl
--> train minibatch error =  0.5  at iter  2143
-->  2 7200 chunk_12_50000.pkl
--> train minibatch error =  0.38  at iter  2144
-->  2 7250 chunk_12_50000.pkl
--> train minibatch error =  0.28  at iter  2146
-->  2 7350 chunk_12_50000.pkl
--> train minibatch error =  0.32  at iter  2147
-->  2 7400 chunk_12_50000.pkl
--> train minibatch error =  0.12  at iter  2152
-->  2 7650 chunk_12_50000.pkl
--> train minibatch error =  0.16  at iter  2185
-->  2 9300 chunk_12_50000.pkl
training @ iter = 2200 , loss =  0.0196581482887
training @ iter = 2200 , error =  0.0
training @ iter = 2300 , loss =  0.00920998305082
training @ iter = 2300 , error =  0.0
--> train minibatch error =  0.12  at iter  2374
-->  2 18750 chunk_12_50000.pkl
training @ iter = 2400 , loss =  0.0126922680065
training @ iter = 2400 , error =  0.0
training @ iter = 2500 , loss =  0.0409551039338
training @ iter = 2500 , error =  0.0
--> train minibatch error =  0.18  at iter  2537
-->  2 26900 chunk_12_50000.pkl
--> train minibatch error =  0.12  at iter  2565
-->  2 28300 chunk_12_50000.pkl
--> train minibatch error =  0.12  at iter  2570
-->  2 28550 chunk_12_50000.pkl
--> train minibatch error =  0.12  at iter  2585
-->  2 29300 chunk_12_50000.pkl
training @ iter = 2600 , loss =  0.139780059457
training @ iter = 2600 , error =  0.02
--> train minibatch error =  0.2  at iter  2696
-->  2 34850 chunk_12_50000.pkl
training @ iter = 2700 , loss =  0.0382634624839
training @ iter = 2700 , error =  0.02
--> train minibatch error =  0.12  at iter  2784
-->  2 39250 chunk_12_50000.pkl
training @ iter = 2800 , loss =  0.127089172602
training @ iter = 2800 , error =  0.04
--> train minibatch error =  0.16  at iter  2815
-->  2 40800 chunk_12_50000.pkl
training @ iter = 2900 , loss =  0.0281617306173
training @ iter = 2900 , error =  0.0
training @ iter = 3000 , loss =  0.017303597182
training @ iter = 3000 , error =  0.0
--> train minibatch error =  0.14  at iter  3070
-->  3 3550 chunk_13_50000.pkl
training @ iter = 3100 , loss =  0.0334232077003
training @ iter = 3100 , error =  0.02
--> train minibatch error =  0.16  at iter  3130
-->  3 6550 chunk_13_50000.pkl
--> train minibatch error =  0.32  at iter  3132
-->  3 6650 chunk_13_50000.pkl
training @ iter = 3200 , loss =  0.241666436195
training @ iter = 3200 , error =  0.06
--> train minibatch error =  0.14  at iter  3203
-->  3 10200 chunk_13_50000.pkl
--> train minibatch error =  0.32  at iter  3204
-->  3 10250 chunk_13_50000.pkl
--> train minibatch error =  0.48  at iter  3205
-->  3 10300 chunk_13_50000.pkl
--> train minibatch error =  0.34  at iter  3206
-->  3 10350 chunk_13_50000.pkl
--> train minibatch error =  0.12  at iter  3219
-->  3 11000 chunk_13_50000.pkl
training @ iter = 3300 , loss =  0.0395054258406
training @ iter = 3300 , error =  0.0
--> train minibatch error =  0.14  at iter  3366
-->  3 18350 chunk_13_50000.pkl
--> train minibatch error =  0.42  at iter  3368
-->  3 18450 chunk_13_50000.pkl
--> train minibatch error =  0.52  at iter  3369
-->  3 18500 chunk_13_50000.pkl
--> train minibatch error =  0.12  at iter  3370
-->  3 18550 chunk_13_50000.pkl
--> train minibatch error =  0.22  at iter  3377
-->  3 18900 chunk_13_50000.pkl
training @ iter = 3400 , loss =  0.0614150576293
training @ iter = 3400 , error =  0.0
--> train minibatch error =  0.14  at iter  3404
-->  3 20250 chunk_13_50000.pkl
--> train minibatch error =  0.2  at iter  3405
-->  3 20300 chunk_13_50000.pkl
--> train minibatch error =  0.46  at iter  3464
-->  3 23250 chunk_13_50000.pkl
--> train minibatch error =  0.2  at iter  3465
-->  3 23300 chunk_13_50000.pkl
--> train minibatch error =  0.12  at iter  3480
-->  3 24050 chunk_13_50000.pkl
training @ iter = 3500 , loss =  0.0219091325998
training @ iter = 3500 , error =  0.0
--> train minibatch error =  0.18  at iter  3549
-->  3 27500 chunk_13_50000.pkl
training @ iter = 3600 , loss =  0.0100972531363
training @ iter = 3600 , error =  0.0
--> train minibatch error =  0.12  at iter  3641
-->  3 32100 chunk_13_50000.pkl
--> train minibatch error =  0.2  at iter  3668
-->  3 33450 chunk_13_50000.pkl
--> train minibatch error =  0.26  at iter  3679
-->  3 34000 chunk_13_50000.pkl
--> train minibatch error =  0.12  at iter  3687
-->  3 34400 chunk_13_50000.pkl
--> train minibatch error =  0.12  at iter  3688
-->  3 34450 chunk_13_50000.pkl
training @ iter = 3700 , loss =  0.0285089425743
training @ iter = 3700 , error =  0.0
training @ iter = 3800 , loss =  0.127532556653
training @ iter = 3800 , error =  0.02
training @ iter = 3900 , loss =  0.0873151943088
training @ iter = 3900 , error =  0.02
--> train minibatch error =  0.24  at iter  3932
-->  3 46650 chunk_13_50000.pkl
--> train minibatch error =  0.18  at iter  3999
-->  4 0 chunk_14_50000.pkl
training @ iter = 4000 , loss =  0.119306087494
training @ iter = 4000 , error =  0.04
training @ iter = 4100 , loss =  0.287740588188
training @ iter = 4100 , error =  0.08
training @ iter = 4200 , loss =  0.285714566708
training @ iter = 4200 , error =  0.14
--> train minibatch error =  0.14  at iter  4200
-->  4 10050 chunk_14_50000.pkl
--> train minibatch error =  0.16  at iter  4202
-->  4 10150 chunk_14_50000.pkl
--> train minibatch error =  0.36  at iter  4298
-->  4 14950 chunk_14_50000.pkl
training @ iter = 4300 , loss =  0.188707768917
training @ iter = 4300 , error =  0.16
--> train minibatch error =  0.16  at iter  4300
-->  4 15050 chunk_14_50000.pkl
training @ iter = 4400 , loss =  0.0474967099726
training @ iter = 4400 , error =  0.02
training @ iter = 4500 , loss =  0.0174391139299
training @ iter = 4500 , error =  0.0
--> train minibatch error =  0.14  at iter  4527
-->  4 26400 chunk_14_50000.pkl
--> train minibatch error =  0.32  at iter  4529
-->  4 26500 chunk_14_50000.pkl
training @ iter = 4600 , loss =  0.0428909808397
training @ iter = 4600 , error =  0.02
training @ iter = 4700 , loss =  0.0210703182966
training @ iter = 4700 , error =  0.0
--> train minibatch error =  0.2  at iter  4730
-->  4 36550 chunk_14_50000.pkl
--> train minibatch error =  0.28  at iter  4731
-->  4 36600 chunk_14_50000.pkl
--> train minibatch error =  0.14  at iter  4732
-->  4 36650 chunk_14_50000.pkl
--> train minibatch error =  0.38  at iter  4796
-->  4 39850 chunk_14_50000.pkl
training @ iter = 4800 , loss =  0.0771797001362
training @ iter = 4800 , error =  0.0
training @ iter = 4900 , loss =  0.0144549394026
training @ iter = 4900 , error =  0.0
--> train minibatch error =  0.12  at iter  4912
-->  4 45650 chunk_14_50000.pkl
training @ iter = 5000 , loss =  0.0233380272985
training @ iter = 5000 , error =  0.0
training @ iter = 5100 , loss =  0.0792539566755
training @ iter = 5100 , error =  0.04
--> train minibatch error =  0.14  at iter  5117
-->  5 5900 chunk_15_50000.pkl
--> train minibatch error =  0.24  at iter  5118
-->  5 5950 chunk_15_50000.pkl
--> train minibatch error =  0.3  at iter  5119
-->  5 6000 chunk_15_50000.pkl
--> train minibatch error =  0.12  at iter  5184
-->  5 9250 chunk_15_50000.pkl
training @ iter = 5200 , loss =  0.0361094921827
training @ iter = 5200 , error =  0.0
--> train minibatch error =  0.12  at iter  5247
-->  5 12400 chunk_15_50000.pkl
training @ iter = 5300 , loss =  0.0171123296022
training @ iter = 5300 , error =  0.0
training @ iter = 5400 , loss =  0.0151450587437
training @ iter = 5400 , error =  0.0
--> train minibatch error =  0.18  at iter  5417
-->  5 20900 chunk_15_50000.pkl
--> train minibatch error =  0.26  at iter  5466
-->  5 23350 chunk_15_50000.pkl
--> train minibatch error =  0.38  at iter  5468
-->  5 23450 chunk_15_50000.pkl
--> train minibatch error =  0.2  at iter  5469
-->  5 23500 chunk_15_50000.pkl
training @ iter = 5500 , loss =  0.103560850024
training @ iter = 5500 , error =  0.02
training @ iter = 5600 , loss =  0.154164120555
training @ iter = 5600 , error =  0.04
training @ iter = 5700 , loss =  0.0635355263948
training @ iter = 5700 , error =  0.02
--> train minibatch error =  0.12  at iter  5762
-->  5 38150 chunk_15_50000.pkl
training @ iter = 5800 , loss =  0.00823207292706
training @ iter = 5800 , error =  0.0
training @ iter = 5900 , loss =  0.0357207097113
training @ iter = 5900 , error =  0.04
training @ iter = 6000 , loss =  0.042100276798
training @ iter = 6000 , error =  0.02
--> train minibatch error =  0.12  at iter  6056
-->  6 2850 chunk_16_50000.pkl
training @ iter = 6100 , loss =  0.0068393512629
training @ iter = 6100 , error =  0.0
training @ iter = 6200 , loss =  0.144630074501
training @ iter = 6200 , error =  0.04
--> train minibatch error =  0.16  at iter  6201
-->  6 10100 chunk_16_50000.pkl
--> train minibatch error =  0.18  at iter  6203
-->  6 10200 chunk_16_50000.pkl
training @ iter = 6300 , loss =  0.0254133827984
training @ iter = 6300 , error =  0.02
training @ iter = 6400 , loss =  0.0068145240657
training @ iter = 6400 , error =  0.0
training @ iter = 6500 , loss =  0.00335250794888
training @ iter = 6500 , error =  0.0
training @ iter = 6600 , loss =  0.0585280321538
training @ iter = 6600 , error =  0.02
training @ iter = 6700 , loss =  0.203315511346
training @ iter = 6700 , error =  0.06
training @ iter = 6800 , loss =  0.00519662396982
training @ iter = 6800 , error =  0.0
--> train minibatch error =  0.18  at iter  6819
-->  6 41000 chunk_16_50000.pkl
--> train minibatch error =  0.12  at iter  6832
-->  6 41650 chunk_16_50000.pkl
training @ iter = 6900 , loss =  0.0256081651896
training @ iter = 6900 , error =  0.0
--> train minibatch error =  0.12  at iter  6932
-->  6 46650 chunk_16_50000.pkl
training @ iter = 7000 , loss =  0.00756158167496
training @ iter = 7000 , error =  0.0
--> train minibatch error =  0.28  at iter  7029
-->  7 1500 chunk_17_50000.pkl
--> train minibatch error =  0.22  at iter  7031
-->  7 1600 chunk_17_50000.pkl
--> train minibatch error =  0.14  at iter  7072
-->  7 3650 chunk_17_50000.pkl
training @ iter = 7100 , loss =  0.00409199297428
training @ iter = 7100 , error =  0.0
training @ iter = 7200 , loss =  0.00586717389524
training @ iter = 7200 , error =  0.0
training @ iter = 7300 , loss =  0.00941048748791
training @ iter = 7300 , error =  0.0
training @ iter = 7400 , loss =  0.0369878076017
training @ iter = 7400 , error =  0.02
--> train minibatch error =  0.14  at iter  7419
-->  7 21000 chunk_17_50000.pkl
training @ iter = 7500 , loss =  0.0165331680328
training @ iter = 7500 , error =  0.0
--> train minibatch error =  0.12  at iter  7504
-->  7 25250 chunk_17_50000.pkl
training @ iter = 7600 , loss =  0.00410105613992
training @ iter = 7600 , error =  0.0
--> train minibatch error =  0.24  at iter  7666
-->  7 33350 chunk_17_50000.pkl
--> train minibatch error =  0.24  at iter  7668
-->  7 33450 chunk_17_50000.pkl
--> train minibatch error =  0.16  at iter  7687
-->  7 34400 chunk_17_50000.pkl
training @ iter = 7700 , loss =  0.113111115992
training @ iter = 7700 , error =  0.04
training @ iter = 7800 , loss =  0.0297995302826
training @ iter = 7800 , error =  0.0
--> train minibatch error =  0.18  at iter  7893
-->  7 44700 chunk_17_50000.pkl
training @ iter = 7900 , loss =  0.0112779531628
training @ iter = 7900 , error =  0.0
--> train minibatch error =  0.18  at iter  7946
-->  7 47350 chunk_17_50000.pkl
--> train minibatch error =  0.14  at iter  7948
-->  7 47450 chunk_17_50000.pkl
--> train minibatch error =  0.14  at iter  7949
-->  7 47500 chunk_17_50000.pkl
training @ iter = 8000 , loss =  0.0544457733631
training @ iter = 8000 , error =  0.02
--> train minibatch error =  0.3  at iter  8094
-->  8 4750 chunk_18_50000.pkl
--> train minibatch error =  0.32  at iter  8095
-->  8 4800 chunk_18_50000.pkl
--> train minibatch error =  0.24  at iter  8096
-->  8 4850 chunk_18_50000.pkl
training @ iter = 8100 , loss =  0.0782337188721
training @ iter = 8100 , error =  0.04
training @ iter = 8200 , loss =  0.0412410534918
training @ iter = 8200 , error =  0.02
training @ iter = 8300 , loss =  0.0407961495221
training @ iter = 8300 , error =  0.04
training @ iter = 8400 , loss =  0.0549386963248
training @ iter = 8400 , error =  0.02
--> train minibatch error =  0.12  at iter  8493
-->  8 24700 chunk_18_50000.pkl
training @ iter = 8500 , loss =  0.0654623657465
training @ iter = 8500 , error =  0.02
training @ iter = 8600 , loss =  0.113542720675
training @ iter = 8600 , error =  0.02
--> train minibatch error =  0.16  at iter  8606
-->  8 30350 chunk_18_50000.pkl
--> train minibatch error =  0.32  at iter  8607
-->  8 30400 chunk_18_50000.pkl
--> train minibatch error =  0.18  at iter  8608
-->  8 30450 chunk_18_50000.pkl
training @ iter = 8700 , loss =  0.0083417436108
training @ iter = 8700 , error =  0.0
--> train minibatch error =  0.14  at iter  8724
-->  8 36250 chunk_18_50000.pkl
--> train minibatch error =  0.12  at iter  8725
-->  8 36300 chunk_18_50000.pkl
training @ iter = 8800 , loss =  0.0126134613529
training @ iter = 8800 , error =  0.0
--> train minibatch error =  0.12  at iter  8829
-->  8 41500 chunk_18_50000.pkl
training @ iter = 8900 , loss =  0.010941288434
training @ iter = 8900 , error =  0.0
--> train minibatch error =  0.24  at iter  8921
-->  8 46100 chunk_18_50000.pkl
training @ iter = 9000 , loss =  0.154427573085
training @ iter = 9000 , error =  0.04
training @ iter = 9100 , loss =  0.0448876582086
training @ iter = 9100 , error =  0.02
--> train minibatch error =  0.12  at iter  9142
-->  9 7150 chunk_19_50000.pkl
training @ iter = 9200 , loss =  0.0209845378995
training @ iter = 9200 , error =  0.02
training @ iter = 9300 , loss =  0.00842177215964
training @ iter = 9300 , error =  0.0
--> train minibatch error =  0.12  at iter  9314
-->  9 15750 chunk_19_50000.pkl
training @ iter = 9400 , loss =  0.0610352605581
training @ iter = 9400 , error =  0.02
training @ iter = 9500 , loss =  0.00437699444592
training @ iter = 9500 , error =  0.0
--> train minibatch error =  0.14  at iter  9537
-->  9 26900 chunk_19_50000.pkl
training @ iter = 9600 , loss =  0.315973073244
training @ iter = 9600 , error =  0.06
training @ iter = 9700 , loss =  0.0319704301655
training @ iter = 9700 , error =  0.0
--> train minibatch error =  0.12  at iter  9706
-->  9 35350 chunk_19_50000.pkl
training @ iter = 9800 , loss =  0.13298535347
training @ iter = 9800 , error =  0.02
training @ iter = 9900 , loss =  0.0109501704574
training @ iter = 9900 , error =  0.0
validation @ iter 10000
epoch 0, iter 10000, train buffer error 0.400000 %
epoch 0, iter 10000, validation loss 0.043316
epoch 0, iter 10000, validation error 1.320000 %
patience before checkBest 50000
Patience =  50000
patience after checkBest 50000
training @ iter = 10000 , loss =  0.0112028308213
training @ iter = 10000 , error =  0.0
training @ iter = 10100 , loss =  0.123989351094
training @ iter = 10100 , error =  0.02
--> train minibatch error =  0.18  at iter  10181
-->  10 9100 chunk_20_50000.pkl
--> train minibatch error =  0.14  at iter  10182
-->  10 9150 chunk_20_50000.pkl
training @ iter = 10200 , loss =  0.0655029267073
training @ iter = 10200 , error =  0.02
--> train minibatch error =  0.12  at iter  10251
-->  10 12600 chunk_20_50000.pkl
training @ iter = 10300 , loss =  0.0603978745639
training @ iter = 10300 , error =  0.04
--> train minibatch error =  0.12  at iter  10334
-->  10 16750 chunk_20_50000.pkl
training @ iter = 10400 , loss =  0.0466785617173
training @ iter = 10400 , error =  0.02
--> train minibatch error =  0.12  at iter  10445
-->  10 22300 chunk_20_50000.pkl
--> train minibatch error =  0.12  at iter  10466
-->  10 23350 chunk_20_50000.pkl
training @ iter = 10500 , loss =  0.38309520483
training @ iter = 10500 , error =  0.14
--> train minibatch error =  0.14  at iter  10500
-->  10 25050 chunk_20_50000.pkl
training @ iter = 10600 , loss =  0.00479882722721
training @ iter = 10600 , error =  0.0
--> train minibatch error =  0.12  at iter  10648
-->  10 32450 chunk_20_50000.pkl
training @ iter = 10700 , loss =  0.0136383911595
training @ iter = 10700 , error =  0.0
training @ iter = 10800 , loss =  0.0296579841524
training @ iter = 10800 , error =  0.0
training @ iter = 10900 , loss =  0.0143855689093
training @ iter = 10900 , error =  0.0
training @ iter = 11000 , loss =  0.0133653040975
training @ iter = 11000 , error =  0.0
training @ iter = 11100 , loss =  0.00963683798909
training @ iter = 11100 , error =  0.0
training @ iter = 11200 , loss =  0.00255312235095
training @ iter = 11200 , error =  0.0
training @ iter = 11300 , loss =  0.0257637575269
training @ iter = 11300 , error =  0.02
training @ iter = 11400 , loss =  0.0202737040818
training @ iter = 11400 , error =  0.0
--> train minibatch error =  0.2  at iter  11497
-->  11 24900 chunk_21_50000.pkl
--> train minibatch error =  0.46  at iter  11498
-->  11 24950 chunk_21_50000.pkl
training @ iter = 11500 , loss =  0.23674236238
training @ iter = 11500 , error =  0.04
training @ iter = 11600 , loss =  0.229905888438
training @ iter = 11600 , error =  0.02
--> train minibatch error =  0.12  at iter  11601
-->  11 30100 chunk_21_50000.pkl
--> train minibatch error =  0.14  at iter  11603
-->  11 30200 chunk_21_50000.pkl
--> train minibatch error =  0.26  at iter  11668
-->  11 33450 chunk_21_50000.pkl
training @ iter = 11700 , loss =  0.017707541585
training @ iter = 11700 , error =  0.0
training @ iter = 11800 , loss =  0.0286253094673
training @ iter = 11800 , error =  0.02
--> train minibatch error =  0.14  at iter  11824
-->  11 41250 chunk_21_50000.pkl
training @ iter = 11900 , loss =  0.218551024795
training @ iter = 11900 , error =  0.06
training @ iter = 12000 , loss =  0.0201445817947
training @ iter = 12000 , error =  0.0
--> train minibatch error =  0.14  at iter  12014
-->  12 750 chunk_22_50000.pkl
--> train minibatch error =  0.18  at iter  12015
-->  12 800 chunk_22_50000.pkl
--> train minibatch error =  0.14  at iter  12016
-->  12 850 chunk_22_50000.pkl
training @ iter = 12100 , loss =  0.00268630799837
training @ iter = 12100 , error =  0.0
training @ iter = 12200 , loss =  0.0143750868738
training @ iter = 12200 , error =  0.0
training @ iter = 12300 , loss =  0.0291687659919
training @ iter = 12300 , error =  0.0
training @ iter = 12400 , loss =  0.00691323401406
training @ iter = 12400 , error =  0.0
training @ iter = 12500 , loss =  0.0864460468292
training @ iter = 12500 , error =  0.04
--> train minibatch error =  0.14  at iter  12584
-->  12 29250 chunk_22_50000.pkl
training @ iter = 12600 , loss =  0.00344955571927
training @ iter = 12600 , error =  0.0
training @ iter = 12700 , loss =  0.00474616792053
training @ iter = 12700 , error =  0.0
training @ iter = 12800 , loss =  0.0282451342791
training @ iter = 12800 , error =  0.02
training @ iter = 12900 , loss =  0.0106550194323
training @ iter = 12900 , error =  0.0
training @ iter = 13000 , loss =  0.0333058461547
training @ iter = 13000 , error =  0.02
training @ iter = 13100 , loss =  0.00679094390944
training @ iter = 13100 , error =  0.0
--> train minibatch error =  0.14  at iter  13195
-->  13 9800 chunk_23_50000.pkl
training @ iter = 13200 , loss =  0.0060495082289
training @ iter = 13200 , error =  0.0
training @ iter = 13300 , loss =  0.0644396990538
training @ iter = 13300 , error =  0.0
training @ iter = 13400 , loss =  0.138374388218
training @ iter = 13400 , error =  0.02
--> train minibatch error =  0.14  at iter  13477
-->  13 23900 chunk_23_50000.pkl
training @ iter = 13500 , loss =  0.0559537559748
training @ iter = 13500 , error =  0.04
training @ iter = 13600 , loss =  0.0288680549711
training @ iter = 13600 , error =  0.02
training @ iter = 13700 , loss =  0.00879325158894
training @ iter = 13700 , error =  0.0
training @ iter = 13800 , loss =  0.108097583055
training @ iter = 13800 , error =  0.02
training @ iter = 13900 , loss =  0.0928689539433
training @ iter = 13900 , error =  0.02
training @ iter = 14000 , loss =  0.0271797869354
training @ iter = 14000 , error =  0.0
--> train minibatch error =  0.12  at iter  14017
-->  14 900 chunk_24_50000.pkl
training @ iter = 14100 , loss =  0.037192504853
training @ iter = 14100 , error =  0.02
training @ iter = 14200 , loss =  0.00741069158539
training @ iter = 14200 , error =  0.0
training @ iter = 14300 , loss =  0.00787321571261
training @ iter = 14300 , error =  0.0
training @ iter = 14400 , loss =  0.00302577461116
training @ iter = 14400 , error =  0.0
training @ iter = 14500 , loss =  0.0054061152041
training @ iter = 14500 , error =  0.02
training @ iter = 14600 , loss =  0.0259228926152
training @ iter = 14600 , error =  0.0
--> train minibatch error =  0.12  at iter  14643
-->  14 32200 chunk_24_50000.pkl
--> train minibatch error =  0.12  at iter  14652
-->  14 32650 chunk_24_50000.pkl
training @ iter = 14700 , loss =  0.0057104928419
training @ iter = 14700 , error =  0.0
--> train minibatch error =  0.12  at iter  14729
-->  14 36500 chunk_24_50000.pkl
--> train minibatch error =  0.14  at iter  14730
-->  14 36550 chunk_24_50000.pkl
--> train minibatch error =  0.16  at iter  14739
-->  14 37000 chunk_24_50000.pkl
training @ iter = 14800 , loss =  0.0316219776869
training @ iter = 14800 , error =  0.02
training @ iter = 14900 , loss =  0.00477352691814
training @ iter = 14900 , error =  0.0
training @ iter = 15000 , loss =  0.0906731635332
training @ iter = 15000 , error =  0.02
training @ iter = 15100 , loss =  0.00765033485368
training @ iter = 15100 , error =  0.0
training @ iter = 15200 , loss =  0.0547650419176
training @ iter = 15200 , error =  0.04
training @ iter = 15300 , loss =  0.00349758542143
training @ iter = 15300 , error =  0.0
--> train minibatch error =  0.12  at iter  15363
-->  15 18200 chunk_25_50000.pkl
training @ iter = 15400 , loss =  0.0388783849776
training @ iter = 15400 , error =  0.02
training @ iter = 15500 , loss =  0.0213852897286
training @ iter = 15500 , error =  0.02
training @ iter = 15600 , loss =  0.0388957746327
training @ iter = 15600 , error =  0.02
training @ iter = 15700 , loss =  0.014691254124
training @ iter = 15700 , error =  0.0
training @ iter = 15800 , loss =  0.346311420202
training @ iter = 15800 , error =  0.1
training @ iter = 15900 , loss =  0.00431472854689
training @ iter = 15900 , error =  0.0
training @ iter = 16000 , loss =  0.0124878399074
training @ iter = 16000 , error =  0.0
training @ iter = 16100 , loss =  0.00739318598062
training @ iter = 16100 , error =  0.0
training @ iter = 16200 , loss =  0.0213926844299
training @ iter = 16200 , error =  0.0
training @ iter = 16300 , loss =  0.00167609204073
training @ iter = 16300 , error =  0.0
training @ iter = 16400 , loss =  0.0872039198875
training @ iter = 16400 , error =  0.04
training @ iter = 16500 , loss =  0.0018218223704
training @ iter = 16500 , error =  0.0
--> train minibatch error =  0.12  at iter  16516
-->  16 25850 chunk_26_50000.pkl
training @ iter = 16600 , loss =  0.0140125509351
training @ iter = 16600 , error =  0.0
training @ iter = 16700 , loss =  0.00650019058958
training @ iter = 16700 , error =  0.0
training @ iter = 16800 , loss =  0.00808155443519
training @ iter = 16800 , error =  0.0
training @ iter = 16900 , loss =  0.0384202860296
training @ iter = 16900 , error =  0.0
--> train minibatch error =  0.14  at iter  16987
-->  16 49400 chunk_26_50000.pkl
training @ iter = 17000 , loss =  0.0189195293933
training @ iter = 17000 , error =  0.0
training @ iter = 17100 , loss =  0.0268414020538
training @ iter = 17100 , error =  0.0
training @ iter = 17200 , loss =  0.00826813653111
training @ iter = 17200 , error =  0.0
training @ iter = 17300 , loss =  0.00762952445075
training @ iter = 17300 , error =  0.0
training @ iter = 17400 , loss =  0.175584718585
training @ iter = 17400 , error =  0.02
training @ iter = 17500 , loss =  0.017396684736
training @ iter = 17500 , error =  0.0
training @ iter = 17600 , loss =  0.0194543376565
training @ iter = 17600 , error =  0.0
--> train minibatch error =  0.24  at iter  17643
-->  17 32200 chunk_27_50000.pkl
--> train minibatch error =  0.34  at iter  17645
-->  17 32300 chunk_27_50000.pkl
--> train minibatch error =  0.12  at iter  17652
-->  17 32650 chunk_27_50000.pkl
training @ iter = 17700 , loss =  0.00254122912884
training @ iter = 17700 , error =  0.0
training @ iter = 17800 , loss =  0.00810151733458
training @ iter = 17800 , error =  0.0
--> train minibatch error =  0.12  at iter  17888
-->  17 44450 chunk_27_50000.pkl
training @ iter = 17900 , loss =  0.0371396243572
training @ iter = 17900 , error =  0.0
training @ iter = 18000 , loss =  0.0221186764538
training @ iter = 18000 , error =  0.02
training @ iter = 18100 , loss =  0.00600697379559
training @ iter = 18100 , error =  0.0
training @ iter = 18200 , loss =  0.00452247820795
training @ iter = 18200 , error =  0.0
training @ iter = 18300 , loss =  0.0305743888021
training @ iter = 18300 , error =  0.0
training @ iter = 18400 , loss =  0.124797150493
training @ iter = 18400 , error =  0.06
training @ iter = 18500 , loss =  0.00791371706873
training @ iter = 18500 , error =  0.0
training @ iter = 18600 , loss =  0.00311948242597
training @ iter = 18600 , error =  0.0
training @ iter = 18700 , loss =  0.0112628908828
training @ iter = 18700 , error =  0.0
ERROR:  /home/shared/Fields_12-2015/chunks_feat_50000/chunks_train/chunk_28_50000.pkl  has  4  candidates.
training @ iter = 18800 , loss =  0.047341350466
training @ iter = 18800 , error =  0.02
--> train minibatch error =  0.12  at iter  18845
-->  19 6150 chunk_4_50000.pkl
training @ iter = 18900 , loss =  0.0776435285807
training @ iter = 18900 , error =  0.02
--> train minibatch error =  0.14  at iter  18901
-->  19 8950 chunk_4_50000.pkl
training @ iter = 19000 , loss =  0.00255837198347
training @ iter = 19000 , error =  0.0
training @ iter = 19100 , loss =  0.0148444902152
training @ iter = 19100 , error =  0.0
training @ iter = 19200 , loss =  0.00363108585589
training @ iter = 19200 , error =  0.0
--> train minibatch error =  0.12  at iter  19233
-->  19 25550 chunk_4_50000.pkl
training @ iter = 19300 , loss =  0.0182122383267
training @ iter = 19300 , error =  0.0
training @ iter = 19400 , loss =  0.0549480244517
training @ iter = 19400 , error =  0.02
training @ iter = 19500 , loss =  0.00437383912504
training @ iter = 19500 , error =  0.0
--> train minibatch error =  0.14  at iter  19550
-->  19 41400 chunk_4_50000.pkl
training @ iter = 19600 , loss =  0.00293223862536
training @ iter = 19600 , error =  0.0
training @ iter = 19700 , loss =  0.00380119401962
training @ iter = 19700 , error =  0.0
training @ iter = 19800 , loss =  0.00416435580701
training @ iter = 19800 , error =  0.0
--> train minibatch error =  0.28  at iter  19840
-->  20 5900 chunk_5_50000.pkl
--> train minibatch error =  0.12  at iter  19841
-->  20 5950 chunk_5_50000.pkl
training @ iter = 19900 , loss =  0.0147798517719
training @ iter = 19900 , error =  0.0
validation @ iter 20000
epoch 0, iter 20000, train buffer error 0.800000 %
epoch 0, iter 20000, validation loss 0.033889
epoch 0, iter 20000, validation error 1.016000 %
patience before checkBest 50000
Patience =  50000
patience after checkBest 50000
training @ iter = 20000 , loss =  0.12613978982
training @ iter = 20000 , error =  0.04
training @ iter = 20100 , loss =  0.10407923907
training @ iter = 20100 , error =  0.04
--> train minibatch error =  0.12  at iter  20102
-->  20 19000 chunk_5_50000.pkl
training @ iter = 20200 , loss =  0.0105562880635
training @ iter = 20200 , error =  0.0
training @ iter = 20300 , loss =  0.0112185273319
training @ iter = 20300 , error =  0.0
training @ iter = 20400 , loss =  0.0484801195562
training @ iter = 20400 , error =  0.02
training @ iter = 20500 , loss =  0.00263770809397
training @ iter = 20500 , error =  0.0
training @ iter = 20600 , loss =  0.00376435788348
training @ iter = 20600 , error =  0.0
training @ iter = 20700 , loss =  0.00928408838809
training @ iter = 20700 , error =  0.0
training @ iter = 20800 , loss =  0.287548571825
training @ iter = 20800 , error =  0.1
training @ iter = 20900 , loss =  0.00282346154563
training @ iter = 20900 , error =  0.0
training @ iter = 21000 , loss =  0.0875522792339
training @ iter = 21000 , error =  0.02
training @ iter = 21100 , loss =  0.00386964553036
training @ iter = 21100 , error =  0.0
training @ iter = 21200 , loss =  0.00580989941955
training @ iter = 21200 , error =  0.0
training @ iter = 21300 , loss =  0.00445978296921
training @ iter = 21300 , error =  0.0
training @ iter = 21400 , loss =  0.0268604941666
training @ iter = 21400 , error =  0.0
training @ iter = 21500 , loss =  0.0676843300462
training @ iter = 21500 , error =  0.02
training @ iter = 21600 , loss =  0.00555923534557
training @ iter = 21600 , error =  0.0
training @ iter = 21700 , loss =  0.076052993536
training @ iter = 21700 , error =  0.04
training @ iter = 21800 , loss =  0.0019848162774
training @ iter = 21800 , error =  0.0
training @ iter = 21900 , loss =  0.0179366096854
training @ iter = 21900 , error =  0.0
training @ iter = 22000 , loss =  0.0222432203591
training @ iter = 22000 , error =  0.0
training @ iter = 22100 , loss =  0.101765401661
training @ iter = 22100 , error =  0.02
training @ iter = 22200 , loss =  0.0257744509727
training @ iter = 22200 , error =  0.0
training @ iter = 22300 , loss =  0.00758310267702
training @ iter = 22300 , error =  0.0
training @ iter = 22400 , loss =  0.00475192628801
training @ iter = 22400 , error =  0.0
training @ iter = 22500 , loss =  0.194105759263
training @ iter = 22500 , error =  0.04
training @ iter = 22600 , loss =  0.00144800753333
training @ iter = 22600 , error =  0.0
training @ iter = 22700 , loss =  0.00896558724344
training @ iter = 22700 , error =  0.0
training @ iter = 22800 , loss =  0.0771260336041
training @ iter = 22800 , error =  0.02
training @ iter = 22900 , loss =  0.0771702751517
training @ iter = 22900 , error =  0.02
training @ iter = 23000 , loss =  0.027029691264
training @ iter = 23000 , error =  0.02
training @ iter = 23100 , loss =  0.00287335994653
training @ iter = 23100 , error =  0.0
--> train minibatch error =  0.12  at iter  23150
-->  23 21400 chunk_8_50000.pkl
training @ iter = 23200 , loss =  0.00452340207994
training @ iter = 23200 , error =  0.0
--> train minibatch error =  0.12  at iter  23239
-->  23 25850 chunk_8_50000.pkl
--> train minibatch error =  0.14  at iter  23241
-->  23 25950 chunk_8_50000.pkl
training @ iter = 23300 , loss =  0.0164725799114
training @ iter = 23300 , error =  0.0
--> train minibatch error =  0.12  at iter  23359
-->  23 31850 chunk_8_50000.pkl
--> train minibatch error =  0.14  at iter  23361
-->  23 31950 chunk_8_50000.pkl
--> train minibatch error =  0.22  at iter  23362
-->  23 32000 chunk_8_50000.pkl
--> train minibatch error =  0.18  at iter  23363
-->  23 32050 chunk_8_50000.pkl
training @ iter = 23400 , loss =  0.0355046875775
training @ iter = 23400 , error =  0.02
training @ iter = 23500 , loss =  0.00467457948253
training @ iter = 23500 , error =  0.0
training @ iter = 23600 , loss =  0.00393336731941
training @ iter = 23600 , error =  0.0
--> train minibatch error =  0.2  at iter  23620
-->  23 44900 chunk_8_50000.pkl
--> train minibatch error =  0.12  at iter  23649
-->  23 46350 chunk_8_50000.pkl
training @ iter = 23700 , loss =  0.00130907353014
training @ iter = 23700 , error =  0.0
training @ iter = 23800 , loss =  0.00310556683689
training @ iter = 23800 , error =  0.0
training @ iter = 23900 , loss =  0.00866641663015
training @ iter = 23900 , error =  0.0
training @ iter = 24000 , loss =  0.0120942778885
training @ iter = 24000 , error =  0.0
training @ iter = 24100 , loss =  0.0981802046299
training @ iter = 24100 , error =  0.02
training @ iter = 24200 , loss =  0.084758259356
training @ iter = 24200 , error =  0.02
training @ iter = 24300 , loss =  0.200748980045
training @ iter = 24300 , error =  0.06
training @ iter = 24400 , loss =  0.00384072493762
training @ iter = 24400 , error =  0.0
--> train minibatch error =  0.24  at iter  24416
-->  24 34700 chunk_9_50000.pkl
--> train minibatch error =  0.54  at iter  24418
-->  24 34800 chunk_9_50000.pkl
--> train minibatch error =  0.42  at iter  24419
-->  24 34850 chunk_9_50000.pkl
training @ iter = 24500 , loss =  0.0239301994443
training @ iter = 24500 , error =  0.02
training @ iter = 24600 , loss =  0.115574963391
training @ iter = 24600 , error =  0.04
training @ iter = 24700 , loss =  0.0159818511456
training @ iter = 24700 , error =  0.0
Epoch  1 , iteration  24723 training @ iter = 24800 , loss =  0.00300518097356
training @ iter = 24800 , error =  0.0
training @ iter = 24900 , loss =  0.00838636979461
training @ iter = 24900 , error =  0.0
Saving @ iter  25000
training @ iter = 25000 , loss =  0.00255605159327
training @ iter = 25000 , error =  0.0
training @ iter = 25100 , loss =  0.00725727155805
training @ iter = 25100 , error =  0.0
training @ iter = 25200 , loss =  0.0116972336546
training @ iter = 25200 , error =  0.0
training @ iter = 25300 , loss =  0.0231944862753
training @ iter = 25300 , error =  0.0
--> train minibatch error =  0.14  at iter  25303
-->  0 29050 chunk_10_50000.pkl
--> train minibatch error =  0.12  at iter  25346
-->  0 31200 chunk_10_50000.pkl
training @ iter = 25400 , loss =  0.0081199016422
training @ iter = 25400 , error =  0.0
training @ iter = 25500 , loss =  0.0695330798626
training @ iter = 25500 , error =  0.02
training @ iter = 25600 , loss =  0.0502173565328
training @ iter = 25600 , error =  0.02
training @ iter = 25700 , loss =  0.00338198035024
training @ iter = 25700 , error =  0.0
training @ iter = 25800 , loss =  0.0196355525404
training @ iter = 25800 , error =  0.02
training @ iter = 25900 , loss =  0.00256010890007
training @ iter = 25900 , error =  0.0
training @ iter = 26000 , loss =  0.0216585509479
training @ iter = 26000 , error =  0.0
training @ iter = 26100 , loss =  0.0385625399649
training @ iter = 26100 , error =  0.02
training @ iter = 26200 , loss =  0.0167281869799
training @ iter = 26200 , error =  0.0
training @ iter = 26300 , loss =  0.00475921807811
training @ iter = 26300 , error =  0.0
training @ iter = 26400 , loss =  0.0380106940866
training @ iter = 26400 , error =  0.02
training @ iter = 26500 , loss =  0.0215614344925
training @ iter = 26500 , error =  0.0
training @ iter = 26600 , loss =  0.00969007238746
training @ iter = 26600 , error =  0.0
training @ iter = 26700 , loss =  0.00224217795767
training @ iter = 26700 , error =  0.0
training @ iter = 26800 , loss =  0.0637495964766
training @ iter = 26800 , error =  0.0
--> train minibatch error =  0.14  at iter  26852
-->  2 6500 chunk_12_50000.pkl
training @ iter = 26900 , loss =  0.00783677771688
training @ iter = 26900 , error =  0.0
training @ iter = 27000 , loss =  0.00957622285932
training @ iter = 27000 , error =  0.0
training @ iter = 27100 , loss =  0.00788596272469
training @ iter = 27100 , error =  0.0
training @ iter = 27200 , loss =  0.00248303986154
training @ iter = 27200 , error =  0.0
training @ iter = 27300 , loss =  0.0062498152256
training @ iter = 27300 , error =  0.0
training @ iter = 27400 , loss =  0.0308137517422
training @ iter = 27400 , error =  0.02
training @ iter = 27500 , loss =  0.0075245811604
training @ iter = 27500 , error =  0.0
training @ iter = 27600 , loss =  0.0109304795042
training @ iter = 27600 , error =  0.0
--> train minibatch error =  0.12  at iter  27613
-->  2 44550 chunk_12_50000.pkl
training @ iter = 27700 , loss =  0.00320005952381
training @ iter = 27700 , error =  0.0
--> train minibatch error =  0.12  at iter  27793
-->  3 3550 chunk_13_50000.pkl
training @ iter = 27800 , loss =  0.0207263659686
training @ iter = 27800 , error =  0.0
training @ iter = 27900 , loss =  0.00388806592673
training @ iter = 27900 , error =  0.0
training @ iter = 28000 , loss =  0.00214732065797
training @ iter = 28000 , error =  0.0
training @ iter = 28100 , loss =  0.141110271215
training @ iter = 28100 , error =  0.02
training @ iter = 28200 , loss =  0.053029447794
training @ iter = 28200 , error =  0.02
--> train minibatch error =  0.12  at iter  28272
-->  3 27500 chunk_13_50000.pkl
training @ iter = 28300 , loss =  0.0297536328435
training @ iter = 28300 , error =  0.02
training @ iter = 28400 , loss =  0.00870000664145
training @ iter = 28400 , error =  0.02
--> train minibatch error =  0.14  at iter  28402
-->  3 34000 chunk_13_50000.pkl
training @ iter = 28500 , loss =  0.00417381478474
training @ iter = 28500 , error =  0.0
training @ iter = 28600 , loss =  0.00172470125835
training @ iter = 28600 , error =  0.0
training @ iter = 28700 , loss =  0.00133701961022
training @ iter = 28700 , error =  0.0
training @ iter = 28800 , loss =  0.00326610985212
training @ iter = 28800 , error =  0.0
training @ iter = 28900 , loss =  0.0292009450495
training @ iter = 28900 , error =  0.02
training @ iter = 29000 , loss =  0.131795376539
training @ iter = 29000 , error =  0.02
training @ iter = 29100 , loss =  0.0192534979433
training @ iter = 29100 , error =  0.0
training @ iter = 29200 , loss =  0.0151692554355
training @ iter = 29200 , error =  0.0
training @ iter = 29300 , loss =  0.0611388385296
training @ iter = 29300 , error =  0.04
training @ iter = 29400 , loss =  0.0405572205782
training @ iter = 29400 , error =  0.02
training @ iter = 29500 , loss =  0.0236042421311
training @ iter = 29500 , error =  0.0
training @ iter = 29600 , loss =  0.00123155850451
training @ iter = 29600 , error =  0.0
--> train minibatch error =  0.14  at iter  29646
-->  4 46200 chunk_14_50000.pkl
training @ iter = 29700 , loss =  0.0379357300699
training @ iter = 29700 , error =  0.0
training @ iter = 29800 , loss =  0.00304754730314
training @ iter = 29800 , error =  0.0
training @ iter = 29900 , loss =  0.190284073353
training @ iter = 29900 , error =  0.06
validation @ iter 30000
epoch 0, iter 30000, train buffer error 0.100000 %
epoch 0, iter 30000, validation loss 0.027810
epoch 0, iter 30000, validation error 0.883000 %
patience before checkBest 50000
Patience =  60000
patience after checkBest 60000
training @ iter = 30000 , loss =  0.0353775173426
training @ iter = 30000 , error =  0.02
training @ iter = 30100 , loss =  0.0256939250976
training @ iter = 30100 , error =  0.02
training @ iter = 30200 , loss =  0.0281189437956
training @ iter = 30200 , error =  0.02
training @ iter = 30300 , loss =  0.0113450717181
training @ iter = 30300 , error =  0.0
training @ iter = 30400 , loss =  0.00680623389781
training @ iter = 30400 , error =  0.0
training @ iter = 30500 , loss =  0.0981086567044
training @ iter = 30500 , error =  0.02
training @ iter = 30600 , loss =  0.0405562929809
training @ iter = 30600 , error =  0.02
training @ iter = 30700 , loss =  0.00536755658686
training @ iter = 30700 , error =  0.0
training @ iter = 30800 , loss =  0.00208478816785
training @ iter = 30800 , error =  0.0
training @ iter = 30900 , loss =  0.0379518419504
training @ iter = 30900 , error =  0.02
training @ iter = 31000 , loss =  0.0287198442966
training @ iter = 31000 , error =  0.04
training @ iter = 31100 , loss =  0.00547884451225
training @ iter = 31100 , error =  0.0
training @ iter = 31200 , loss =  0.007216387894
training @ iter = 31200 , error =  0.0
training @ iter = 31300 , loss =  0.00181010900997
training @ iter = 31300 , error =  0.0
training @ iter = 31400 , loss =  0.00328857335262
training @ iter = 31400 , error =  0.0
training @ iter = 31500 , loss =  0.0019334340468
training @ iter = 31500 , error =  0.0
training @ iter = 31600 , loss =  0.026818530634
training @ iter = 31600 , error =  0.02
training @ iter = 31700 , loss =  0.00556551944464
training @ iter = 31700 , error =  0.0
training @ iter = 31800 , loss =  0.00243870797567
training @ iter = 31800 , error =  0.0
training @ iter = 31900 , loss =  0.00421619042754
training @ iter = 31900 , error =  0.0
training @ iter = 32000 , loss =  0.0050359275192
training @ iter = 32000 , error =  0.0
training @ iter = 32100 , loss =  0.00370386661962
training @ iter = 32100 , error =  0.0
training @ iter = 32200 , loss =  0.0149413645267
training @ iter = 32200 , error =  0.0
training @ iter = 32300 , loss =  0.0944162681699
training @ iter = 32300 , error =  0.04
--> train minibatch error =  0.18  at iter  32389
-->  7 33350 chunk_17_50000.pkl
--> train minibatch error =  0.18  at iter  32391
-->  7 33450 chunk_17_50000.pkl
training @ iter = 32400 , loss =  0.0682088583708
training @ iter = 32400 , error =  0.02
--> train minibatch error =  0.12  at iter  32410
-->  7 34400 chunk_17_50000.pkl
training @ iter = 32500 , loss =  0.0206457749009
training @ iter = 32500 , error =  0.0
training @ iter = 32600 , loss =  0.00246094516478
training @ iter = 32600 , error =  0.0
--> train minibatch error =  0.12  at iter  32616
-->  7 44700 chunk_17_50000.pkl
--> train minibatch error =  0.12  at iter  32669
-->  7 47350 chunk_17_50000.pkl
training @ iter = 32700 , loss =  0.0103960046545
training @ iter = 32700 , error =  0.0
training @ iter = 32800 , loss =  0.00113046576735
training @ iter = 32800 , error =  0.0
--> train minibatch error =  0.16  at iter  32817
-->  8 4750 chunk_18_50000.pkl
training @ iter = 32900 , loss =  0.00706059765071
training @ iter = 32900 , error =  0.0
training @ iter = 33000 , loss =  0.0447297841311
training @ iter = 33000 , error =  0.02
training @ iter = 33100 , loss =  0.0325327813625
training @ iter = 33100 , error =  0.02
training @ iter = 33200 , loss =  0.0104904314503
training @ iter = 33200 , error =  0.02
training @ iter = 33300 , loss =  0.00799925811589
training @ iter = 33300 , error =  0.0
--> train minibatch error =  0.14  at iter  33328
-->  8 30300 chunk_18_50000.pkl
--> train minibatch error =  0.14  at iter  33329
-->  8 30350 chunk_18_50000.pkl
--> train minibatch error =  0.42  at iter  33330
-->  8 30400 chunk_18_50000.pkl
--> train minibatch error =  0.34  at iter  33331
-->  8 30450 chunk_18_50000.pkl
--> train minibatch error =  0.14  at iter  33394
-->  8 33600 chunk_18_50000.pkl
training @ iter = 33400 , loss =  0.135002180934
training @ iter = 33400 , error =  0.04
training @ iter = 33500 , loss =  0.00576624739915
training @ iter = 33500 , error =  0.0
training @ iter = 33600 , loss =  0.0674138814211
training @ iter = 33600 , error =  0.02
training @ iter = 33700 , loss =  0.0511343479156
training @ iter = 33700 , error =  0.02
training @ iter = 33800 , loss =  0.00802351813763
training @ iter = 33800 , error =  0.0
training @ iter = 33900 , loss =  0.0648473575711
training @ iter = 33900 , error =  0.02
training @ iter = 34000 , loss =  0.00241845543496
training @ iter = 34000 , error =  0.0
training @ iter = 34100 , loss =  0.0443809404969
training @ iter = 34100 , error =  0.04
training @ iter = 34200 , loss =  0.00928113423288
training @ iter = 34200 , error =  0.0
training @ iter = 34300 , loss =  0.00697377929464
training @ iter = 34300 , error =  0.0
training @ iter = 34400 , loss =  0.00175100599881
training @ iter = 34400 , error =  0.0
--> train minibatch error =  0.12  at iter  34429
-->  9 35350 chunk_19_50000.pkl
training @ iter = 34500 , loss =  0.00304483389482
training @ iter = 34500 , error =  0.0
training @ iter = 34600 , loss =  0.00368075910956
training @ iter = 34600 , error =  0.0
training @ iter = 34700 , loss =  0.0218846853822
training @ iter = 34700 , error =  0.0
training @ iter = 34800 , loss =  0.174699351192
training @ iter = 34800 , error =  0.02
training @ iter = 34900 , loss =  0.17185562849
training @ iter = 34900 , error =  0.04
--> train minibatch error =  0.18  at iter  34904
-->  10 9100 chunk_20_50000.pkl
--> train minibatch error =  0.12  at iter  34974
-->  10 12600 chunk_20_50000.pkl
training @ iter = 35000 , loss =  0.173886090517
training @ iter = 35000 , error =  0.04
--> train minibatch error =  0.12  at iter  35057
-->  10 16750 chunk_20_50000.pkl
training @ iter = 35100 , loss =  0.00280085508712
training @ iter = 35100 , error =  0.0
training @ iter = 35200 , loss =  0.192516863346
training @ iter = 35200 , error =  0.06
--> train minibatch error =  0.12  at iter  35223
-->  10 25050 chunk_20_50000.pkl
training @ iter = 35300 , loss =  0.0506646409631
training @ iter = 35300 , error =  0.02
training @ iter = 35400 , loss =  0.0579849183559
training @ iter = 35400 , error =  0.02
training @ iter = 35500 , loss =  0.0114374784753
training @ iter = 35500 , error =  0.0
training @ iter = 35600 , loss =  0.00633791089058
training @ iter = 35600 , error =  0.0
training @ iter = 35700 , loss =  0.0113537441939
training @ iter = 35700 , error =  0.0
training @ iter = 35800 , loss =  0.00352764548734
training @ iter = 35800 , error =  0.0
training @ iter = 35900 , loss =  0.00289308675565
training @ iter = 35900 , error =  0.0
training @ iter = 36000 , loss =  0.0372614897788
training @ iter = 36000 , error =  0.02
training @ iter = 36100 , loss =  0.00300310971215
training @ iter = 36100 , error =  0.0
training @ iter = 36200 , loss =  0.0903317853808
training @ iter = 36200 , error =  0.04
training @ iter = 36300 , loss =  0.0404703095555
training @ iter = 36300 , error =  0.02
training @ iter = 36400 , loss =  0.00300593557768
training @ iter = 36400 , error =  0.0
training @ iter = 36500 , loss =  0.063435472548
training @ iter = 36500 , error =  0.04
--> train minibatch error =  0.12  at iter  36547
-->  11 41250 chunk_21_50000.pkl
training @ iter = 36600 , loss =  0.105368517339
training @ iter = 36600 , error =  0.04
training @ iter = 36700 , loss =  0.0221899766475
training @ iter = 36700 , error =  0.0
--> train minibatch error =  0.12  at iter  36737
-->  12 750 chunk_22_50000.pkl
training @ iter = 36800 , loss =  0.00593239767477
training @ iter = 36800 , error =  0.0
training @ iter = 36900 , loss =  0.00508722197264
training @ iter = 36900 , error =  0.0
training @ iter = 37000 , loss =  0.0405468270183
training @ iter = 37000 , error =  0.0
training @ iter = 37100 , loss =  0.119556605816
training @ iter = 37100 , error =  0.02
training @ iter = 37200 , loss =  0.00180981610902
training @ iter = 37200 , error =  0.0
training @ iter = 37300 , loss =  0.00484310043976
training @ iter = 37300 , error =  0.0
training @ iter = 37400 , loss =  0.0814067423344
training @ iter = 37400 , error =  0.02
training @ iter = 37500 , loss =  0.0943997204304
training @ iter = 37500 , error =  0.02
training @ iter = 37600 , loss =  0.00319810560904
training @ iter = 37600 , error =  0.0
training @ iter = 37700 , loss =  0.00257478188723
training @ iter = 37700 , error =  0.0
training @ iter = 37800 , loss =  0.02446796
training @ iter = 37800 , error =  0.02
training @ iter = 37900 , loss =  0.0389871299267
training @ iter = 37900 , error =  0.0
--> train minibatch error =  0.12  at iter  37918
-->  13 9800 chunk_23_50000.pkl
training @ iter = 38000 , loss =  0.0404179915786
training @ iter = 38000 , error =  0.0
training @ iter = 38100 , loss =  0.024667467922
training @ iter = 38100 , error =  0.0
training @ iter = 38200 , loss =  0.170604899526
training @ iter = 38200 , error =  0.04
training @ iter = 38300 , loss =  0.0159057043493
training @ iter = 38300 , error =  0.02
training @ iter = 38400 , loss =  0.00554171344265
training @ iter = 38400 , error =  0.0
training @ iter = 38500 , loss =  0.0731120854616
training @ iter = 38500 , error =  0.02
training @ iter = 38600 , loss =  0.0065003419295
training @ iter = 38600 , error =  0.0
training @ iter = 38700 , loss =  0.157937481999
training @ iter = 38700 , error =  0.02
training @ iter = 38800 , loss =  0.0547927953303
training @ iter = 38800 , error =  0.02
training @ iter = 38900 , loss =  0.128957077861
training @ iter = 38900 , error =  0.06
training @ iter = 39000 , loss =  0.00650085229427
training @ iter = 39000 , error =  0.0
training @ iter = 39100 , loss =  0.156755566597
training @ iter = 39100 , error =  0.02
training @ iter = 39200 , loss =  0.10503064096
training @ iter = 39200 , error =  0.02
training @ iter = 39300 , loss =  0.00626790383831
training @ iter = 39300 , error =  0.0
--> train minibatch error =  0.12  at iter  39375
-->  14 32650 chunk_24_50000.pkl
training @ iter = 39400 , loss =  0.0016525934916
training @ iter = 39400 , error =  0.0
--> train minibatch error =  0.18  at iter  39453
-->  14 36550 chunk_24_50000.pkl
training @ iter = 39500 , loss =  0.0675624534488
training @ iter = 39500 , error =  0.04
training @ iter = 39600 , loss =  0.0360402949154
training @ iter = 39600 , error =  0.0
training @ iter = 39700 , loss =  0.00267568300478
training @ iter = 39700 , error =  0.0
training @ iter = 39800 , loss =  0.020279949531
training @ iter = 39800 , error =  0.0
training @ iter = 39900 , loss =  0.0143824703991
training @ iter = 39900 , error =  0.0
validation @ iter 40000
epoch 0, iter 40000, train buffer error 0.500000 %
epoch 0, iter 40000, validation loss 0.034550
epoch 0, iter 40000, validation error 1.164000 %
patience before checkBest 60000
patience after checkBest 60000
training @ iter = 40000 , loss =  0.0602857358754
training @ iter = 40000 , error =  0.02
--> train minibatch error =  0.12  at iter  40086
-->  15 18200 chunk_25_50000.pkl
training @ iter = 40100 , loss =  0.0579290352762
training @ iter = 40100 , error =  0.02
training @ iter = 40200 , loss =  0.0234414581209
training @ iter = 40200 , error =  0.0
training @ iter = 40300 , loss =  0.00251499586739
training @ iter = 40300 , error =  0.0
training @ iter = 40400 , loss =  0.00135276908986
training @ iter = 40400 , error =  0.0
training @ iter = 40500 , loss =  0.00226288614795
training @ iter = 40500 , error =  0.0
training @ iter = 40600 , loss =  0.0081191714853
training @ iter = 40600 , error =  0.0
training @ iter = 40700 , loss =  0.00431217299774
training @ iter = 40700 , error =  0.0
training @ iter = 40800 , loss =  0.0104373190552
training @ iter = 40800 , error =  0.0
training @ iter = 40900 , loss =  0.0229798238724
training @ iter = 40900 , error =  0.02
training @ iter = 41000 , loss =  0.00100258458406
training @ iter = 41000 , error =  0.0
training @ iter = 41100 , loss =  0.00802314002067
training @ iter = 41100 , error =  0.0
training @ iter = 41200 , loss =  0.00846974179149
training @ iter = 41200 , error =  0.0
training @ iter = 41300 , loss =  0.0154991121963
training @ iter = 41300 , error =  0.0
training @ iter = 41400 , loss =  0.0147135723382
training @ iter = 41400 , error =  0.0
training @ iter = 41500 , loss =  0.00712803611532
training @ iter = 41500 , error =  0.0
training @ iter = 41600 , loss =  0.0129589913413
training @ iter = 41600 , error =  0.0
training @ iter = 41700 , loss =  0.0699895471334
training @ iter = 41700 , error =  0.02
--> train minibatch error =  0.14  at iter  41710
-->  16 49400 chunk_26_50000.pkl
training @ iter = 41800 , loss =  0.0118802376091
training @ iter = 41800 , error =  0.0
training @ iter = 41900 , loss =  0.0355815887451
training @ iter = 41900 , error =  0.02
training @ iter = 42000 , loss =  0.0272746961564
training @ iter = 42000 , error =  0.02
training @ iter = 42100 , loss =  0.0196833368391
training @ iter = 42100 , error =  0.0
training @ iter = 42200 , loss =  0.00276829744689
training @ iter = 42200 , error =  0.0
training @ iter = 42300 , loss =  0.00209613982588
training @ iter = 42300 , error =  0.0
training @ iter = 42400 , loss =  0.0170592963696
training @ iter = 42400 , error =  0.02
training @ iter = 42500 , loss =  0.00582423619926
training @ iter = 42500 , error =  0.0
training @ iter = 42600 , loss =  0.0868482142687
training @ iter = 42600 , error =  0.02
training @ iter = 42700 , loss =  0.0210486892611
training @ iter = 42700 , error =  0.0
training @ iter = 42800 , loss =  0.0727130919695
training @ iter = 42800 , error =  0.02
training @ iter = 42900 , loss =  0.0126556130126
training @ iter = 42900 , error =  0.0
training @ iter = 43000 , loss =  0.017419045791
training @ iter = 43000 , error =  0.02
training @ iter = 43100 , loss =  0.0389013178647
training @ iter = 43100 , error =  0.02
training @ iter = 43200 , loss =  0.102168977261
training @ iter = 43200 , error =  0.04
training @ iter = 43300 , loss =  0.00410483311862
training @ iter = 43300 , error =  0.0
training @ iter = 43400 , loss =  0.0678593292832
training @ iter = 43400 , error =  0.02
ERROR:  /home/shared/Fields_12-2015/chunks_feat_50000/chunks_train/chunk_28_50000.pkl  has  4  candidates.
training @ iter = 43500 , loss =  0.00237825210206
training @ iter = 43500 , error =  0.0
training @ iter = 43600 , loss =  0.0180545672774
training @ iter = 43600 , error =  0.02
training @ iter = 43700 , loss =  0.0876871272922
training @ iter = 43700 , error =  0.02
training @ iter = 43800 , loss =  0.00408865045756
training @ iter = 43800 , error =  0.0
training @ iter = 43900 , loss =  0.00167986482847
training @ iter = 43900 , error =  0.0
--> train minibatch error =  0.12  at iter  43956
-->  19 25550 chunk_4_50000.pkl
training @ iter = 44000 , loss =  0.0102525856346
training @ iter = 44000 , error =  0.0
training @ iter = 44100 , loss =  0.0167770348489
training @ iter = 44100 , error =  0.0
training @ iter = 44200 , loss =  0.00163886428345
training @ iter = 44200 , error =  0.0
--> train minibatch error =  0.14  at iter  44273
-->  19 41400 chunk_4_50000.pkl
training @ iter = 44300 , loss =  0.0980109795928
training @ iter = 44300 , error =  0.04
training @ iter = 44400 , loss =  0.0273026414216
training @ iter = 44400 , error =  0.0
training @ iter = 44500 , loss =  0.00203836522996
training @ iter = 44500 , error =  0.0
--> train minibatch error =  0.24  at iter  44563
-->  20 5900 chunk_5_50000.pkl
--> train minibatch error =  0.12  at iter  44564
-->  20 5950 chunk_5_50000.pkl
training @ iter = 44600 , loss =  0.0311276223511
training @ iter = 44600 , error =  0.02
training @ iter = 44700 , loss =  0.00187363172881
training @ iter = 44700 , error =  0.0
training @ iter = 44800 , loss =  0.0683640912175
training @ iter = 44800 , error =  0.02
training @ iter = 44900 , loss =  0.00242525967769
training @ iter = 44900 , error =  0.0
training @ iter = 45000 , loss =  0.0131899872795
training @ iter = 45000 , error =  0.0
training @ iter = 45100 , loss =  0.0107790110633
training @ iter = 45100 , error =  0.0
training @ iter = 45200 , loss =  0.00113425031304
training @ iter = 45200 , error =  0.0
training @ iter = 45300 , loss =  0.0037304724101
training @ iter = 45300 , error =  0.0
training @ iter = 45400 , loss =  0.0142101123929
training @ iter = 45400 , error =  0.0
training @ iter = 45500 , loss =  0.00721933227032
training @ iter = 45500 , error =  0.0
training @ iter = 45600 , loss =  0.00256911548786
training @ iter = 45600 , error =  0.0
training @ iter = 45700 , loss =  0.0206916704774
training @ iter = 45700 , error =  0.02
--> train minibatch error =  0.12  at iter  45706
-->  21 13050 chunk_6_50000.pkl
training @ iter = 45800 , loss =  0.110122792423
training @ iter = 45800 , error =  0.02
training @ iter = 45900 , loss =  0.00353517848998
training @ iter = 45900 , error =  0.0
training @ iter = 46000 , loss =  0.00210172496736
training @ iter = 46000 , error =  0.0
training @ iter = 46100 , loss =  0.00332260061987
training @ iter = 46100 , error =  0.0
training @ iter = 46200 , loss =  0.0117774363607
training @ iter = 46200 , error =  0.0
training @ iter = 46300 , loss =  0.00541562121361
training @ iter = 46300 , error =  0.0
training @ iter = 46400 , loss =  0.00384507863782
training @ iter = 46400 , error =  0.0
training @ iter = 46500 , loss =  0.00374962575734
training @ iter = 46500 , error =  0.0
training @ iter = 46600 , loss =  0.0287187006325
training @ iter = 46600 , error =  0.02
training @ iter = 46700 , loss =  0.17466455698
training @ iter = 46700 , error =  0.04
training @ iter = 46800 , loss =  0.159244045615
training @ iter = 46800 , error =  0.02
training @ iter = 46900 , loss =  0.00571767427027
training @ iter = 46900 , error =  0.0
training @ iter = 47000 , loss =  0.000822615576908
training @ iter = 47000 , error =  0.0
--> train minibatch error =  0.12  at iter  47064
-->  22 30950 chunk_7_50000.pkl
training @ iter = 47100 , loss =  0.0901751071215
training @ iter = 47100 , error =  0.04
training @ iter = 47200 , loss =  0.0126928258687
training @ iter = 47200 , error =  0.02
training @ iter = 47300 , loss =  0.0979432016611
training @ iter = 47300 , error =  0.02
training @ iter = 47400 , loss =  0.219205230474
training @ iter = 47400 , error =  0.06
training @ iter = 47500 , loss =  0.0724315717816
training @ iter = 47500 , error =  0.02
training @ iter = 47600 , loss =  0.0021635312587
training @ iter = 47600 , error =  0.0
training @ iter = 47700 , loss =  0.0364840254188
training @ iter = 47700 , error =  0.0
training @ iter = 47800 , loss =  0.0581358671188
training @ iter = 47800 , error =  0.02
--> train minibatch error =  0.12  at iter  47873
-->  23 21400 chunk_8_50000.pkl
training @ iter = 47900 , loss =  0.0162042565644
training @ iter = 47900 , error =  0.0
training @ iter = 48000 , loss =  0.0938055515289
training @ iter = 48000 , error =  0.02
--> train minibatch error =  0.12  at iter  48082
-->  23 31850 chunk_8_50000.pkl
--> train minibatch error =  0.14  at iter  48084
-->  23 31950 chunk_8_50000.pkl
--> train minibatch error =  0.2  at iter  48085
-->  23 32000 chunk_8_50000.pkl
training @ iter = 48100 , loss =  0.0108091998845
training @ iter = 48100 , error =  0.0
training @ iter = 48200 , loss =  0.00707042356953
training @ iter = 48200 , error =  0.0
training @ iter = 48300 , loss =  0.00647630169988
training @ iter = 48300 , error =  0.0
--> train minibatch error =  0.12  at iter  48343
-->  23 44900 chunk_8_50000.pkl
training @ iter = 48400 , loss =  0.00956808403134
training @ iter = 48400 , error =  0.0
training @ iter = 48500 , loss =  0.00321273691952
training @ iter = 48500 , error =  0.0
training @ iter = 48600 , loss =  0.001307390281
training @ iter = 48600 , error =  0.0
training @ iter = 48700 , loss =  0.00280162272975
training @ iter = 48700 , error =  0.0
--> train minibatch error =  0.12  at iter  48774
-->  24 16450 chunk_9_50000.pkl
training @ iter = 48800 , loss =  0.00814492069185
training @ iter = 48800 , error =  0.0
training @ iter = 48900 , loss =  0.0148879196495
training @ iter = 48900 , error =  0.0
training @ iter = 49000 , loss =  0.00820610206574
training @ iter = 49000 , error =  0.0
training @ iter = 49100 , loss =  0.0113484440371
training @ iter = 49100 , error =  0.0
--> train minibatch error =  0.24  at iter  49139
-->  24 34700 chunk_9_50000.pkl
--> train minibatch error =  0.16  at iter  49140
-->  24 34750 chunk_9_50000.pkl
--> train minibatch error =  0.44  at iter  49141
-->  24 34800 chunk_9_50000.pkl
--> train minibatch error =  0.46  at iter  49142
-->  24 34850 chunk_9_50000.pkl
--> train minibatch error =  0.16  at iter  49143
-->  24 34900 chunk_9_50000.pkl
training @ iter = 49200 , loss =  0.0285213515162
training @ iter = 49200 , error =  0.02
training @ iter = 49300 , loss =  0.00961577985436
training @ iter = 49300 , error =  0.0
training @ iter = 49400 , loss =  0.0189256053418
training @ iter = 49400 , error =  0.02
Epoch  2 , iteration  49446 training @ iter = 49500 , loss =  0.0605605095625
training @ iter = 49500 , error =  0.02
training @ iter = 49600 , loss =  0.0118737388402
training @ iter = 49600 , error =  0.0
training @ iter = 49700 , loss =  0.00292916083708
training @ iter = 49700 , error =  0.0
training @ iter = 49800 , loss =  0.00130113016348
training @ iter = 49800 , error =  0.0
training @ iter = 49900 , loss =  0.0072519290261
training @ iter = 49900 , error =  0.0
Saving @ iter  50000
validation @ iter 50000
epoch 0, iter 50000, train buffer error 0.900000 %
epoch 0, iter 50000, validation loss 0.025349
epoch 0, iter 50000, validation error 0.800000 %
patience before checkBest 60000
Patience =  100000
patience after checkBest 100000
training @ iter = 50000 , loss =  0.104508511722
training @ iter = 50000 , error =  0.02
training @ iter = 50100 , loss =  0.0590042509139
training @ iter = 50100 , error =  0.02
training @ iter = 50200 , loss =  0.065957352519
training @ iter = 50200 , error =  0.04
training @ iter = 50300 , loss =  0.000877109006979
training @ iter = 50300 , error =  0.0
training @ iter = 50400 , loss =  0.00366331427358
training @ iter = 50400 , error =  0.0
training @ iter = 50500 , loss =  0.00327184889466
training @ iter = 50500 , error =  0.0
training @ iter = 50600 , loss =  0.0043751061894
training @ iter = 50600 , error =  0.0
training @ iter = 50700 , loss =  0.0173529367894
training @ iter = 50700 , error =  0.0
training @ iter = 50800 , loss =  0.0130752371624
training @ iter = 50800 , error =  0.0
training @ iter = 50900 , loss =  0.0220195241272
training @ iter = 50900 , error =  0.0
training @ iter = 51000 , loss =  0.00922946725041
training @ iter = 51000 , error =  0.0
training @ iter = 51100 , loss =  0.00230537937023
training @ iter = 51100 , error =  0.0
training @ iter = 51200 , loss =  0.014881032519
training @ iter = 51200 , error =  0.0
training @ iter = 51300 , loss =  0.156296521425
training @ iter = 51300 , error =  0.02
training @ iter = 51400 , loss =  0.000903215550352
training @ iter = 51400 , error =  0.0
training @ iter = 51500 , loss =  0.0274339690804
training @ iter = 51500 , error =  0.04
--> train minibatch error =  0.16  at iter  51575
-->  2 6500 chunk_12_50000.pkl
training @ iter = 51600 , loss =  0.00426671653986
training @ iter = 51600 , error =  0.0
training @ iter = 51700 , loss =  0.00706377346069
training @ iter = 51700 , error =  0.0
training @ iter = 51800 , loss =  0.019020691514
training @ iter = 51800 , error =  0.0
training @ iter = 51900 , loss =  0.00633877050132
training @ iter = 51900 , error =  0.0
training @ iter = 52000 , loss =  0.00712864566594
training @ iter = 52000 , error =  0.0
training @ iter = 52100 , loss =  0.0106779430062
training @ iter = 52100 , error =  0.0
training @ iter = 52200 , loss =  0.0608344785869
training @ iter = 52200 , error =  0.02
training @ iter = 52300 , loss =  0.0142587302253
training @ iter = 52300 , error =  0.0
training @ iter = 52400 , loss =  0.00111487112008
training @ iter = 52400 , error =  0.0
training @ iter = 52500 , loss =  0.0239211600274
training @ iter = 52500 , error =  0.02
--> train minibatch error =  0.12  at iter  52516
-->  3 3550 chunk_13_50000.pkl
training @ iter = 52600 , loss =  0.0691314414144
training @ iter = 52600 , error =  0.04
training @ iter = 52700 , loss =  0.152562603354
training @ iter = 52700 , error =  0.06
training @ iter = 52800 , loss =  0.0456868372858
training @ iter = 52800 , error =  0.02
training @ iter = 52900 , loss =  0.080739736557
training @ iter = 52900 , error =  0.04
training @ iter = 53000 , loss =  0.0096873184666
training @ iter = 53000 , error =  0.0
--> train minibatch error =  0.14  at iter  53087
-->  3 32100 chunk_13_50000.pkl
training @ iter = 53100 , loss =  0.00951591692865
training @ iter = 53100 , error =  0.0
--> train minibatch error =  0.14  at iter  53125
-->  3 34000 chunk_13_50000.pkl
training @ iter = 53200 , loss =  0.00412122206762
training @ iter = 53200 , error =  0.0
training @ iter = 53300 , loss =  0.150074273348
training @ iter = 53300 , error =  0.04
training @ iter = 53400 , loss =  0.0126334652305
training @ iter = 53400 , error =  0.0
training @ iter = 53500 , loss =  0.00874355062842
training @ iter = 53500 , error =  0.0
training @ iter = 53600 , loss =  0.00633759843186
training @ iter = 53600 , error =  0.0
training @ iter = 53700 , loss =  0.0128882359713
training @ iter = 53700 , error =  0.02
training @ iter = 53800 , loss =  0.0500243604183
training @ iter = 53800 , error =  0.02
training @ iter = 53900 , loss =  0.0923542380333
training @ iter = 53900 , error =  0.02
training @ iter = 54000 , loss =  0.00671689398587
training @ iter = 54000 , error =  0.0
training @ iter = 54100 , loss =  0.0658738687634
training @ iter = 54100 , error =  0.06
training @ iter = 54200 , loss =  0.212208881974
training @ iter = 54200 , error =  0.06
training @ iter = 54300 , loss =  0.00251757795922
training @ iter = 54300 , error =  0.0
training @ iter = 54400 , loss =  0.116191603243
training @ iter = 54400 , error =  0.06
training @ iter = 54500 , loss =  0.0705620422959
training @ iter = 54500 , error =  0.02
training @ iter = 54600 , loss =  0.0131388595328
training @ iter = 54600 , error =  0.0
training @ iter = 54700 , loss =  0.0870069414377
training @ iter = 54700 , error =  0.02
training @ iter = 54800 , loss =  0.0135518182069
training @ iter = 54800 , error =  0.0
training @ iter = 54900 , loss =  0.0121930744499
training @ iter = 54900 , error =  0.0
training @ iter = 55000 , loss =  0.0378677137196
training @ iter = 55000 , error =  0.02
training @ iter = 55100 , loss =  0.0505791604519
training @ iter = 55100 , error =  0.02
training @ iter = 55200 , loss =  0.0279902312905
training @ iter = 55200 , error =  0.0
training @ iter = 55300 , loss =  0.0582214407623
training @ iter = 55300 , error =  0.02
training @ iter = 55400 , loss =  0.0686486661434
training @ iter = 55400 , error =  0.04
training @ iter = 55500 , loss =  0.15881459415
training @ iter = 55500 , error =  0.06
training @ iter = 55600 , loss =  0.00565725937486
training @ iter = 55600 , error =  0.0
training @ iter = 55700 , loss =  0.104827024043
training @ iter = 55700 , error =  0.04
training @ iter = 55800 , loss =  0.0104495696723
training @ iter = 55800 , error =  0.0
training @ iter = 55900 , loss =  0.00805471278727
training @ iter = 55900 , error =  0.0
training @ iter = 56000 , loss =  0.0740967318416
training @ iter = 56000 , error =  0.04
training @ iter = 56100 , loss =  0.0217112917453
training @ iter = 56100 , error =  0.0
training @ iter = 56200 , loss =  0.019428960979
training @ iter = 56200 , error =  0.02
training @ iter = 56300 , loss =  0.00653628865257
training @ iter = 56300 , error =  0.0
training @ iter = 56400 , loss =  0.00869992468506
training @ iter = 56400 , error =  0.0
training @ iter = 56500 , loss =  0.0596323981881
training @ iter = 56500 , error =  0.02
training @ iter = 56600 , loss =  0.00249782134779
training @ iter = 56600 , error =  0.0
training @ iter = 56700 , loss =  0.0144175561145
training @ iter = 56700 , error =  0.0
training @ iter = 56800 , loss =  0.0505305528641
training @ iter = 56800 , error =  0.02
training @ iter = 56900 , loss =  0.0112282922491
training @ iter = 56900 , error =  0.0
training @ iter = 57000 , loss =  0.00414737407118
training @ iter = 57000 , error =  0.0
training @ iter = 57100 , loss =  0.00719104893506
training @ iter = 57100 , error =  0.0
--> train minibatch error =  0.18  at iter  57112
-->  7 33350 chunk_17_50000.pkl
training @ iter = 57200 , loss =  0.00830760691315
training @ iter = 57200 , error =  0.0
training @ iter = 57300 , loss =  0.137297987938
training @ iter = 57300 , error =  0.04
training @ iter = 57400 , loss =  0.00225719530135
training @ iter = 57400 , error =  0.0
training @ iter = 57500 , loss =  0.00377456750721
training @ iter = 57500 , error =  0.0
--> train minibatch error =  0.16  at iter  57540
-->  8 4750 chunk_18_50000.pkl
training @ iter = 57600 , loss =  0.0222878810018
training @ iter = 57600 , error =  0.02
training @ iter = 57700 , loss =  0.0116218067706
training @ iter = 57700 , error =  0.0
training @ iter = 57800 , loss =  0.0222477316856
training @ iter = 57800 , error =  0.02
training @ iter = 57900 , loss =  0.0146722747013
training @ iter = 57900 , error =  0.0
training @ iter = 58000 , loss =  0.0260294266045
training @ iter = 58000 , error =  0.0
--> train minibatch error =  0.14  at iter  58051
-->  8 30300 chunk_18_50000.pkl
--> train minibatch error =  0.14  at iter  58052
-->  8 30350 chunk_18_50000.pkl
--> train minibatch error =  0.32  at iter  58053
-->  8 30400 chunk_18_50000.pkl
training @ iter = 58100 , loss =  0.0113481320441
training @ iter = 58100 , error =  0.0
--> train minibatch error =  0.14  at iter  58117
-->  8 33600 chunk_18_50000.pkl
training @ iter = 58200 , loss =  0.00364503078163
training @ iter = 58200 , error =  0.0
training @ iter = 58300 , loss =  0.144904211164
training @ iter = 58300 , error =  0.06
training @ iter = 58400 , loss =  0.00217137718573
training @ iter = 58400 , error =  0.0
training @ iter = 58500 , loss =  0.00601181667298
training @ iter = 58500 , error =  0.0
training @ iter = 58600 , loss =  0.101402483881
training @ iter = 58600 , error =  0.04
training @ iter = 58700 , loss =  0.00263320328668
training @ iter = 58700 , error =  0.0
training @ iter = 58800 , loss =  0.0261007770896
training @ iter = 58800 , error =  0.02
training @ iter = 58900 , loss =  0.0157614722848
training @ iter = 58900 , error =  0.02
training @ iter = 59000 , loss =  0.00405343808234
training @ iter = 59000 , error =  0.0
training @ iter = 59100 , loss =  0.0275476891547
training @ iter = 59100 , error =  0.0
training @ iter = 59200 , loss =  0.0134662380442
training @ iter = 59200 , error =  0.0
training @ iter = 59300 , loss =  0.00450622849166
training @ iter = 59300 , error =  0.0
training @ iter = 59400 , loss =  0.0567500777543
training @ iter = 59400 , error =  0.04
training @ iter = 59500 , loss =  0.00256257946603
training @ iter = 59500 , error =  0.0
training @ iter = 59600 , loss =  0.000913164520171
training @ iter = 59600 , error =  0.0
--> train minibatch error =  0.16  at iter  59627
-->  10 9100 chunk_20_50000.pkl
training @ iter = 59700 , loss =  0.0507246740162
training @ iter = 59700 , error =  0.02
--> train minibatch error =  0.12  at iter  59779
-->  10 16700 chunk_20_50000.pkl
training @ iter = 59800 , loss =  0.0036337650381
training @ iter = 59800 , error =  0.0
training @ iter = 59900 , loss =  0.0113553330302
training @ iter = 59900 , error =  0.0
validation @ iter 60000
epoch 0, iter 60000, train buffer error 0.400000 %
epoch 0, iter 60000, validation loss 0.024782
epoch 0, iter 60000, validation error 0.786000 %
patience before checkBest 100000
Patience =  120000
patience after checkBest 120000
training @ iter = 60000 , loss =  0.134632915258
training @ iter = 60000 , error =  0.06
training @ iter = 60100 , loss =  0.0318258590996
training @ iter = 60100 , error =  0.0
training @ iter = 60200 , loss =  0.0039286762476
training @ iter = 60200 , error =  0.0
training @ iter = 60300 , loss =  0.0194138363004
training @ iter = 60300 , error =  0.02
training @ iter = 60400 , loss =  0.00433807587251
training @ iter = 60400 , error =  0.0
training @ iter = 60500 , loss =  0.00195745751262
training @ iter = 60500 , error =  0.0
training @ iter = 60600 , loss =  0.0659798234701
training @ iter = 60600 , error =  0.02
training @ iter = 60700 , loss =  0.00120587390848
training @ iter = 60700 , error =  0.0
training @ iter = 60800 , loss =  0.00166976789478
training @ iter = 60800 , error =  0.0
training @ iter = 60900 , loss =  0.00721195340157
training @ iter = 60900 , error =  0.0
training @ iter = 61000 , loss =  0.0134747531265
training @ iter = 61000 , error =  0.0
training @ iter = 61100 , loss =  0.00700002117082
training @ iter = 61100 , error =  0.0
training @ iter = 61200 , loss =  0.0117785157636
training @ iter = 61200 , error =  0.0
training @ iter = 61300 , loss =  0.0198505073786
training @ iter = 61300 , error =  0.0
training @ iter = 61400 , loss =  0.0066551133059
training @ iter = 61400 , error =  0.0
--> train minibatch error =  0.12  at iter  61460
-->  12 750 chunk_22_50000.pkl
training @ iter = 61500 , loss =  0.0129762711003
training @ iter = 61500 , error =  0.02
training @ iter = 61600 , loss =  0.0547307245433
training @ iter = 61600 , error =  0.02
training @ iter = 61700 , loss =  0.00300504174083
training @ iter = 61700 , error =  0.0
training @ iter = 61800 , loss =  0.0023757526651
training @ iter = 61800 , error =  0.0
training @ iter = 61900 , loss =  0.0460969172418
training @ iter = 61900 , error =  0.02
training @ iter = 62000 , loss =  0.101542204618
training @ iter = 62000 , error =  0.02
training @ iter = 62100 , loss =  0.0502060763538
training @ iter = 62100 , error =  0.02
training @ iter = 62200 , loss =  0.0473099984229
training @ iter = 62200 , error =  0.04
training @ iter = 62300 , loss =  0.0125576397404
training @ iter = 62300 , error =  0.0
training @ iter = 62400 , loss =  0.00280905188993
training @ iter = 62400 , error =  0.0
training @ iter = 62500 , loss =  0.0551497749984
training @ iter = 62500 , error =  0.02
training @ iter = 62600 , loss =  0.000699770462234
training @ iter = 62600 , error =  0.0
--> train minibatch error =  0.12  at iter  62641
-->  13 9800 chunk_23_50000.pkl
training @ iter = 62700 , loss =  0.0431503616273
training @ iter = 62700 , error =  0.02
training @ iter = 62800 , loss =  0.00298788305372
training @ iter = 62800 , error =  0.0
training @ iter = 62900 , loss =  0.00416596885771
training @ iter = 62900 , error =  0.0
training @ iter = 63000 , loss =  0.00285779917613
training @ iter = 63000 , error =  0.0
training @ iter = 63100 , loss =  0.00780774373561
training @ iter = 63100 , error =  0.0
training @ iter = 63200 , loss =  0.0265578981489
training @ iter = 63200 , error =  0.02
training @ iter = 63300 , loss =  0.00485373241827
training @ iter = 63300 , error =  0.0
training @ iter = 63400 , loss =  0.00370910414495
training @ iter = 63400 , error =  0.0
training @ iter = 63500 , loss =  0.00163060962223
training @ iter = 63500 , error =  0.0
training @ iter = 63600 , loss =  0.105179481208
training @ iter = 63600 , error =  0.04
training @ iter = 63700 , loss =  0.0106476834044
training @ iter = 63700 , error =  0.0
training @ iter = 63800 , loss =  0.0412692837417
training @ iter = 63800 , error =  0.0
training @ iter = 63900 , loss =  0.00520928762853
training @ iter = 63900 , error =  0.0
training @ iter = 64000 , loss =  0.00198615621775
training @ iter = 64000 , error =  0.0
training @ iter = 64100 , loss =  0.181121394038
training @ iter = 64100 , error =  0.04
--> train minibatch error =  0.14  at iter  64174
-->  14 36450 chunk_24_50000.pkl
training @ iter = 64200 , loss =  0.0329779163003
training @ iter = 64200 , error =  0.02
training @ iter = 64300 , loss =  0.0465799383819
training @ iter = 64300 , error =  0.02
training @ iter = 64400 , loss =  0.0147469900548
training @ iter = 64400 , error =  0.0
training @ iter = 64500 , loss =  0.00765663245693
training @ iter = 64500 , error =  0.0
training @ iter = 64600 , loss =  0.00256832176819
training @ iter = 64600 , error =  0.0
training @ iter = 64700 , loss =  0.107578068972
training @ iter = 64700 , error =  0.02
training @ iter = 64800 , loss =  0.0441498421133
training @ iter = 64800 , error =  0.02
training @ iter = 64900 , loss =  0.00141396431718
training @ iter = 64900 , error =  0.0
training @ iter = 65000 , loss =  0.00544277438894
training @ iter = 65000 , error =  0.0
training @ iter = 65100 , loss =  0.0305203273892
training @ iter = 65100 , error =  0.02
training @ iter = 65200 , loss =  0.00917341373861
training @ iter = 65200 , error =  0.0
training @ iter = 65300 , loss =  0.0447075478733
training @ iter = 65300 , error =  0.02
training @ iter = 65400 , loss =  0.00276974448934
training @ iter = 65400 , error =  0.0
training @ iter = 65500 , loss =  0.0131066730246
training @ iter = 65500 , error =  0.0
training @ iter = 65600 , loss =  0.00143421115354
training @ iter = 65600 , error =  0.0
training @ iter = 65700 , loss =  0.00265152473003
training @ iter = 65700 , error =  0.0
training @ iter = 65800 , loss =  0.00291666598059
training @ iter = 65800 , error =  0.0
training @ iter = 65900 , loss =  0.0022406715434
training @ iter = 65900 , error =  0.0
training @ iter = 66000 , loss =  0.0556072555482
training @ iter = 66000 , error =  0.02
training @ iter = 66100 , loss =  0.0206165332347
training @ iter = 66100 , error =  0.02
training @ iter = 66200 , loss =  0.0117611773312
training @ iter = 66200 , error =  0.0
training @ iter = 66300 , loss =  0.00188743858598
training @ iter = 66300 , error =  0.0
training @ iter = 66400 , loss =  0.0304979868233
training @ iter = 66400 , error =  0.02
--> train minibatch error =  0.14  at iter  66433
-->  16 49400 chunk_26_50000.pkl
training @ iter = 66500 , loss =  0.033127784729
training @ iter = 66500 , error =  0.04
training @ iter = 66600 , loss =  0.000940627534874
training @ iter = 66600 , error =  0.0
training @ iter = 66700 , loss =  0.01164528355
training @ iter = 66700 , error =  0.0
training @ iter = 66800 , loss =  0.00214455323294
training @ iter = 66800 , error =  0.0
training @ iter = 66900 , loss =  0.0220241975039
training @ iter = 66900 , error =  0.02
training @ iter = 67000 , loss =  0.00297182914801
training @ iter = 67000 , error =  0.0
training @ iter = 67100 , loss =  0.0310350731015
training @ iter = 67100 , error =  0.02
training @ iter = 67200 , loss =  0.00354036828503
training @ iter = 67200 , error =  0.0
training @ iter = 67300 , loss =  0.223693758249
training @ iter = 67300 , error =  0.04
training @ iter = 67400 , loss =  0.0330242887139
training @ iter = 67400 , error =  0.02
training @ iter = 67500 , loss =  0.00503519037738
training @ iter = 67500 , error =  0.0
training @ iter = 67600 , loss =  0.00336059718393
training @ iter = 67600 , error =  0.0
training @ iter = 67700 , loss =  0.00544913299382
training @ iter = 67700 , error =  0.0
training @ iter = 67800 , loss =  0.00397943891585
training @ iter = 67800 , error =  0.0
training @ iter = 67900 , loss =  0.031049773097
training @ iter = 67900 , error =  0.02
training @ iter = 68000 , loss =  0.00242619891651
training @ iter = 68000 , error =  0.0
training @ iter = 68100 , loss =  0.00400618789718
training @ iter = 68100 , error =  0.0
ERROR:  /home/shared/Fields_12-2015/chunks_feat_50000/chunks_train/chunk_28_50000.pkl  has  4  candidates.
training @ iter = 68200 , loss =  0.00853684451431
training @ iter = 68200 , error =  0.0
training @ iter = 68300 , loss =  0.0169491358101
training @ iter = 68300 , error =  0.0
training @ iter = 68400 , loss =  0.00484561966732
training @ iter = 68400 , error =  0.0
training @ iter = 68500 , loss =  0.00508976634592
training @ iter = 68500 , error =  0.0
training @ iter = 68600 , loss =  0.00155655667186
training @ iter = 68600 , error =  0.0
--> train minibatch error =  0.14  at iter  68679
-->  19 25550 chunk_4_50000.pkl
training @ iter = 68700 , loss =  0.173812389374
training @ iter = 68700 , error =  0.04
training @ iter = 68800 , loss =  0.0387612134218
training @ iter = 68800 , error =  0.02
training @ iter = 68900 , loss =  0.0499363951385
training @ iter = 68900 , error =  0.02
training @ iter = 69000 , loss =  0.00458503793925
training @ iter = 69000 , error =  0.0
training @ iter = 69100 , loss =  0.00293795368634
training @ iter = 69100 , error =  0.0
training @ iter = 69200 , loss =  0.0541071742773
training @ iter = 69200 , error =  0.02
--> train minibatch error =  0.24  at iter  69286
-->  20 5900 chunk_5_50000.pkl
--> train minibatch error =  0.14  at iter  69287
-->  20 5950 chunk_5_50000.pkl
training @ iter = 69300 , loss =  0.0120831374079
training @ iter = 69300 , error =  0.0
training @ iter = 69400 , loss =  0.0143188806251
training @ iter = 69400 , error =  0.0
training @ iter = 69500 , loss =  0.00862590223551
training @ iter = 69500 , error =  0.0
training @ iter = 69600 , loss =  0.00656228139997
training @ iter = 69600 , error =  0.0
training @ iter = 69700 , loss =  0.00306268990971
training @ iter = 69700 , error =  0.0
training @ iter = 69800 , loss =  0.0116810314357
training @ iter = 69800 , error =  0.0
training @ iter = 69900 , loss =  0.049661975354
training @ iter = 69900 , error =  0.02
validation @ iter 70000
epoch 0, iter 70000, train buffer error 0.600000 %
epoch 0, iter 70000, validation loss 0.023226
epoch 0, iter 70000, validation error 0.732000 %
patience before checkBest 120000
Patience =  140000
patience after checkBest 140000
training @ iter = 70000 , loss =  0.208454936743
training @ iter = 70000 , error =  0.06
training @ iter = 70100 , loss =  0.0101392222568
training @ iter = 70100 , error =  0.0
training @ iter = 70200 , loss =  0.00153327640146
training @ iter = 70200 , error =  0.0
training @ iter = 70300 , loss =  0.124563634396
training @ iter = 70300 , error =  0.02
training @ iter = 70400 , loss =  0.0416894443333
training @ iter = 70400 , error =  0.04
training @ iter = 70500 , loss =  0.00276094907895
training @ iter = 70500 , error =  0.0
training @ iter = 70600 , loss =  0.0937816202641
training @ iter = 70600 , error =  0.02
training @ iter = 70700 , loss =  0.0213029105216
training @ iter = 70700 , error =  0.0
training @ iter = 70800 , loss =  0.0269970949739
training @ iter = 70800 , error =  0.02
training @ iter = 70900 , loss =  0.0489475429058
training @ iter = 70900 , error =  0.02
training @ iter = 71000 , loss =  0.00586376804858
training @ iter = 71000 , error =  0.0
training @ iter = 71100 , loss =  0.0100201657042
training @ iter = 71100 , error =  0.0
training @ iter = 71200 , loss =  0.0470714233816
training @ iter = 71200 , error =  0.02
training @ iter = 71300 , loss =  0.0630154907703
training @ iter = 71300 , error =  0.04
training @ iter = 71400 , loss =  0.00883657671511
training @ iter = 71400 , error =  0.0
training @ iter = 71500 , loss =  0.0680124461651
training @ iter = 71500 , error =  0.04
training @ iter = 71600 , loss =  0.00546864280477
training @ iter = 71600 , error =  0.0
training @ iter = 71700 , loss =  0.00820111948997
training @ iter = 71700 , error =  0.0
--> train minibatch error =  0.12  at iter  71787
-->  22 30950 chunk_7_50000.pkl
training @ iter = 71800 , loss =  0.00893825758249
training @ iter = 71800 , error =  0.0
training @ iter = 71900 , loss =  0.00105786439963
training @ iter = 71900 , error =  0.0
training @ iter = 72000 , loss =  0.00317942257971
training @ iter = 72000 , error =  0.0
training @ iter = 72100 , loss =  0.00157173816115
training @ iter = 72100 , error =  0.0
training @ iter = 72200 , loss =  0.00240977504291
training @ iter = 72200 , error =  0.0
training @ iter = 72300 , loss =  0.00245486851782
training @ iter = 72300 , error =  0.0
training @ iter = 72400 , loss =  0.00205137114972
training @ iter = 72400 , error =  0.0
training @ iter = 72500 , loss =  0.0223593339324
training @ iter = 72500 , error =  0.0
--> train minibatch error =  0.12  at iter  72596
-->  23 21400 chunk_8_50000.pkl
training @ iter = 72600 , loss =  0.205565109849
training @ iter = 72600 , error =  0.0
training @ iter = 72700 , loss =  0.0659695863724
training @ iter = 72700 , error =  0.02
training @ iter = 72800 , loss =  0.00127736118156
training @ iter = 72800 , error =  0.0
--> train minibatch error =  0.12  at iter  72805
-->  23 31850 chunk_8_50000.pkl
--> train minibatch error =  0.14  at iter  72808
-->  23 32000 chunk_8_50000.pkl
--> train minibatch error =  0.16  at iter  72809
-->  23 32050 chunk_8_50000.pkl
training @ iter = 72900 , loss =  0.00728260166943
training @ iter = 72900 , error =  0.0
training @ iter = 73000 , loss =  0.0323441326618
training @ iter = 73000 , error =  0.02
--> train minibatch error =  0.14  at iter  73066
-->  23 44900 chunk_8_50000.pkl
training @ iter = 73100 , loss =  0.0035762602929
training @ iter = 73100 , error =  0.0
training @ iter = 73200 , loss =  0.114339850843
training @ iter = 73200 , error =  0.04
training @ iter = 73300 , loss =  0.00396877946332
training @ iter = 73300 , error =  0.0
training @ iter = 73400 , loss =  0.0966637358069
training @ iter = 73400 , error =  0.02
--> train minibatch error =  0.12  at iter  73497
-->  24 16450 chunk_9_50000.pkl
training @ iter = 73500 , loss =  0.00429500592873
training @ iter = 73500 , error =  0.0
training @ iter = 73600 , loss =  0.0159351453185
training @ iter = 73600 , error =  0.02
training @ iter = 73700 , loss =  0.00259554805234
training @ iter = 73700 , error =  0.0
training @ iter = 73800 , loss =  0.012802798301
training @ iter = 73800 , error =  0.0
--> train minibatch error =  0.24  at iter  73862
-->  24 34700 chunk_9_50000.pkl
--> train minibatch error =  0.12  at iter  73863
-->  24 34750 chunk_9_50000.pkl
--> train minibatch error =  0.38  at iter  73864
-->  24 34800 chunk_9_50000.pkl
--> train minibatch error =  0.34  at iter  73865
-->  24 34850 chunk_9_50000.pkl
--> train minibatch error =  0.14  at iter  73866
-->  24 34900 chunk_9_50000.pkl
training @ iter = 73900 , loss =  0.0200552027673
training @ iter = 73900 , error =  0.0
training @ iter = 74000 , loss =  0.0596996359527
training @ iter = 74000 , error =  0.02
training @ iter = 74100 , loss =  0.106788896024
training @ iter = 74100 , error =  0.02
Epoch  3 , iteration  74169 training @ iter = 74200 , loss =  0.00353189418092
training @ iter = 74200 , error =  0.0
training @ iter = 74300 , loss =  0.00305143091828
training @ iter = 74300 , error =  0.0
training @ iter = 74400 , loss =  0.0166727397591
training @ iter = 74400 , error =  0.02
training @ iter = 74500 , loss =  0.00388349127024
training @ iter = 74500 , error =  0.0
training @ iter = 74600 , loss =  0.00237419758923
training @ iter = 74600 , error =  0.0
training @ iter = 74700 , loss =  0.00619579572231
training @ iter = 74700 , error =  0.0
training @ iter = 74800 , loss =  0.10623498261
training @ iter = 74800 , error =  0.04
training @ iter = 74900 , loss =  0.00555709656328
training @ iter = 74900 , error =  0.0
Saving @ iter  75000
training @ iter = 75000 , loss =  0.00448710098863
training @ iter = 75000 , error =  0.0
training @ iter = 75100 , loss =  0.0236184261739
training @ iter = 75100 , error =  0.0
training @ iter = 75200 , loss =  0.118876837194
training @ iter = 75200 , error =  0.02
training @ iter = 75300 , loss =  0.00822252128273
training @ iter = 75300 , error =  0.0
training @ iter = 75400 , loss =  0.00583744049072
training @ iter = 75400 , error =  0.0
training @ iter = 75500 , loss =  0.0890706554055
training @ iter = 75500 , error =  0.04
training @ iter = 75600 , loss =  0.000695479044225
training @ iter = 75600 , error =  0.0
training @ iter = 75700 , loss =  0.00176245125476
training @ iter = 75700 , error =  0.0
training @ iter = 75800 , loss =  0.00164279853925
training @ iter = 75800 , error =  0.0
training @ iter = 75900 , loss =  0.00757985003293
training @ iter = 75900 , error =  0.0
training @ iter = 76000 , loss =  0.000870058254804
training @ iter = 76000 , error =  0.0
training @ iter = 76100 , loss =  0.0103413248435
training @ iter = 76100 , error =  0.0
training @ iter = 76200 , loss =  0.00190802558791
training @ iter = 76200 , error =  0.0
--> train minibatch error =  0.14  at iter  76298
-->  2 6500 chunk_12_50000.pkl
training @ iter = 76300 , loss =  0.217261850834
training @ iter = 76300 , error =  0.12
--> train minibatch error =  0.12  at iter  76300
-->  2 6600 chunk_12_50000.pkl
training @ iter = 76400 , loss =  0.0720020160079
training @ iter = 76400 , error =  0.04
training @ iter = 76500 , loss =  0.0559750422835
training @ iter = 76500 , error =  0.02
training @ iter = 76600 , loss =  0.00839124899358
training @ iter = 76600 , error =  0.0
training @ iter = 76700 , loss =  0.0161953326315
training @ iter = 76700 , error =  0.0
training @ iter = 76800 , loss =  0.0146444365382
training @ iter = 76800 , error =  0.0
training @ iter = 76900 , loss =  0.00523259397596
training @ iter = 76900 , error =  0.0
training @ iter = 77000 , loss =  0.0407239831984
training @ iter = 77000 , error =  0.02
training @ iter = 77100 , loss =  0.0602353364229
training @ iter = 77100 , error =  0.02
training @ iter = 77200 , loss =  0.00677488278598
training @ iter = 77200 , error =  0.0
training @ iter = 77300 , loss =  0.0262231919914
training @ iter = 77300 , error =  0.0
training @ iter = 77400 , loss =  0.0360424406826
training @ iter = 77400 , error =  0.02
training @ iter = 77500 , loss =  0.0134989097714
training @ iter = 77500 , error =  0.0
training @ iter = 77600 , loss =  0.00323478411883
training @ iter = 77600 , error =  0.0
training @ iter = 77700 , loss =  0.00198399089277
training @ iter = 77700 , error =  0.0
training @ iter = 77800 , loss =  0.0978717580438
training @ iter = 77800 , error =  0.02
--> train minibatch error =  0.14  at iter  77848
-->  3 34000 chunk_13_50000.pkl
training @ iter = 77900 , loss =  0.0546693354845
training @ iter = 77900 , error =  0.02
training @ iter = 78000 , loss =  0.155977800488
training @ iter = 78000 , error =  0.06
training @ iter = 78100 , loss =  0.0133797340095
training @ iter = 78100 , error =  0.0
training @ iter = 78200 , loss =  0.0125124668702
training @ iter = 78200 , error =  0.0
training @ iter = 78300 , loss =  0.0974184349179
training @ iter = 78300 , error =  0.04
training @ iter = 78400 , loss =  0.0261605605483
training @ iter = 78400 , error =  0.0
training @ iter = 78500 , loss =  0.00109478028025
training @ iter = 78500 , error =  0.0
training @ iter = 78600 , loss =  0.00279134325683
training @ iter = 78600 , error =  0.0
training @ iter = 78700 , loss =  0.00224805972539
training @ iter = 78700 , error =  0.0
training @ iter = 78800 , loss =  0.00186384725384
training @ iter = 78800 , error =  0.0
training @ iter = 78900 , loss =  0.00994604080915
training @ iter = 78900 , error =  0.02
training @ iter = 79000 , loss =  0.0944876223803
training @ iter = 79000 , error =  0.02
training @ iter = 79100 , loss =  0.00181822094601
training @ iter = 79100 , error =  0.0
training @ iter = 79200 , loss =  0.0142691321671
training @ iter = 79200 , error =  0.02
training @ iter = 79300 , loss =  0.00480783171952
training @ iter = 79300 , error =  0.0
training @ iter = 79400 , loss =  0.0426147431135
training @ iter = 79400 , error =  0.02
training @ iter = 79500 , loss =  0.00113149150275
training @ iter = 79500 , error =  0.0
training @ iter = 79600 , loss =  0.00804336089641
training @ iter = 79600 , error =  0.0
training @ iter = 79700 , loss =  0.00271467957646
training @ iter = 79700 , error =  0.0
training @ iter = 79800 , loss =  0.00369998137467
training @ iter = 79800 , error =  0.0
training @ iter = 79900 , loss =  0.0063167787157
training @ iter = 79900 , error =  0.0
validation @ iter 80000
epoch 0, iter 80000, train buffer error 0.700000 %
epoch 0, iter 80000, validation loss 0.024724
epoch 0, iter 80000, validation error 0.795000 %
patience before checkBest 140000
patience after checkBest 140000
training @ iter = 80000 , loss =  0.0488996617496
training @ iter = 80000 , error =  0.02
training @ iter = 80100 , loss =  0.00625200849026
training @ iter = 80100 , error =  0.0
training @ iter = 80200 , loss =  0.00308469962329
training @ iter = 80200 , error =  0.0
training @ iter = 80300 , loss =  0.0359560139477
training @ iter = 80300 , error =  0.02
training @ iter = 80400 , loss =  0.00145451584831
training @ iter = 80400 , error =  0.0
training @ iter = 80500 , loss =  0.0256338603795
training @ iter = 80500 , error =  0.0
training @ iter = 80600 , loss =  0.0557813346386
training @ iter = 80600 , error =  0.02
training @ iter = 80700 , loss =  0.026352532208
training @ iter = 80700 , error =  0.02
training @ iter = 80800 , loss =  0.0398541428149
training @ iter = 80800 , error =  0.02
training @ iter = 80900 , loss =  0.00515687232837
training @ iter = 80900 , error =  0.0
training @ iter = 81000 , loss =  0.00936249177903
training @ iter = 81000 , error =  0.0
training @ iter = 81100 , loss =  0.00781796593219
training @ iter = 81100 , error =  0.0
training @ iter = 81200 , loss =  0.00387203809805
training @ iter = 81200 , error =  0.0
training @ iter = 81300 , loss =  0.00602722400799
training @ iter = 81300 , error =  0.0
training @ iter = 81400 , loss =  0.00195839861408
training @ iter = 81400 , error =  0.0
training @ iter = 81500 , loss =  0.00323062413372
training @ iter = 81500 , error =  0.0
training @ iter = 81600 , loss =  0.00683413399383
training @ iter = 81600 , error =  0.0
training @ iter = 81700 , loss =  0.0402177534997
training @ iter = 81700 , error =  0.02
training @ iter = 81800 , loss =  0.00543933641165
training @ iter = 81800 , error =  0.0
--> train minibatch error =  0.2  at iter  81835
-->  7 33350 chunk_17_50000.pkl
training @ iter = 81900 , loss =  0.0263805482537
training @ iter = 81900 , error =  0.0
training @ iter = 82000 , loss =  0.0255863294005
training @ iter = 82000 , error =  0.0
training @ iter = 82100 , loss =  0.00396016612649
training @ iter = 82100 , error =  0.0
training @ iter = 82200 , loss =  0.00820422917604
training @ iter = 82200 , error =  0.0
--> train minibatch error =  0.14  at iter  82263
-->  8 4750 chunk_18_50000.pkl
--> train minibatch error =  0.12  at iter  82268
-->  8 5000 chunk_18_50000.pkl
training @ iter = 82300 , loss =  0.00881106965244
training @ iter = 82300 , error =  0.0
training @ iter = 82400 , loss =  0.00141688855365
training @ iter = 82400 , error =  0.0
training @ iter = 82500 , loss =  0.00260305101983
training @ iter = 82500 , error =  0.0
training @ iter = 82600 , loss =  0.0266738608479
training @ iter = 82600 , error =  0.0
training @ iter = 82700 , loss =  0.116510860622
training @ iter = 82700 , error =  0.02
--> train minibatch error =  0.16  at iter  82774
-->  8 30300 chunk_18_50000.pkl
--> train minibatch error =  0.18  at iter  82775
-->  8 30350 chunk_18_50000.pkl
--> train minibatch error =  0.32  at iter  82776
-->  8 30400 chunk_18_50000.pkl
training @ iter = 82800 , loss =  0.0694599896669
training @ iter = 82800 , error =  0.06
--> train minibatch error =  0.16  at iter  82840
-->  8 33600 chunk_18_50000.pkl
training @ iter = 82900 , loss =  0.0108540318906
training @ iter = 82900 , error =  0.0
training @ iter = 83000 , loss =  0.000814735365566
training @ iter = 83000 , error =  0.0
training @ iter = 83100 , loss =  0.0220296103507
training @ iter = 83100 , error =  0.0
training @ iter = 83200 , loss =  0.00492560304701
training @ iter = 83200 , error =  0.0
training @ iter = 83300 , loss =  0.0119757922366
training @ iter = 83300 , error =  0.0
training @ iter = 83400 , loss =  0.0129577443004
training @ iter = 83400 , error =  0.0
training @ iter = 83500 , loss =  0.00297465827316
training @ iter = 83500 , error =  0.0
training @ iter = 83600 , loss =  0.175170332193
training @ iter = 83600 , error =  0.06
training @ iter = 83700 , loss =  0.0337197482586
training @ iter = 83700 , error =  0.02
--> train minibatch error =  0.14  at iter  83765
-->  9 29850 chunk_19_50000.pkl
training @ iter = 83800 , loss =  0.00569563638419
training @ iter = 83800 , error =  0.0
training @ iter = 83900 , loss =  0.157209545374
training @ iter = 83900 , error =  0.04
training @ iter = 84000 , loss =  0.0743171721697
training @ iter = 84000 , error =  0.02
training @ iter = 84100 , loss =  0.00793140474707
training @ iter = 84100 , error =  0.0
training @ iter = 84200 , loss =  0.0024871500209
training @ iter = 84200 , error =  0.0
training @ iter = 84300 , loss =  0.127400040627
training @ iter = 84300 , error =  0.04
--> train minibatch error =  0.16  at iter  84350
-->  10 9100 chunk_20_50000.pkl
training @ iter = 84400 , loss =  0.00878545083106
training @ iter = 84400 , error =  0.02
--> train minibatch error =  0.12  at iter  84420
-->  10 12600 chunk_20_50000.pkl
training @ iter = 84500 , loss =  0.139717847109
training @ iter = 84500 , error =  0.02
--> train minibatch error =  0.12  at iter  84502
-->  10 16700 chunk_20_50000.pkl
training @ iter = 84600 , loss =  0.00159373867791
training @ iter = 84600 , error =  0.0
training @ iter = 84700 , loss =  0.161399006844
training @ iter = 84700 , error =  0.02
training @ iter = 84800 , loss =  0.318974733353
training @ iter = 84800 , error =  0.08
training @ iter = 84900 , loss =  0.00353909912519
training @ iter = 84900 , error =  0.0
training @ iter = 85000 , loss =  0.00390497664921
training @ iter = 85000 , error =  0.0
training @ iter = 85100 , loss =  0.0199027564377
training @ iter = 85100 , error =  0.0
training @ iter = 85200 , loss =  0.0171361714602
training @ iter = 85200 , error =  0.0
training @ iter = 85300 , loss =  0.00260941754095
training @ iter = 85300 , error =  0.0
training @ iter = 85400 , loss =  0.0240637287498
training @ iter = 85400 , error =  0.02
training @ iter = 85500 , loss =  0.00315892277285
training @ iter = 85500 , error =  0.0
training @ iter = 85600 , loss =  0.00427813548595
training @ iter = 85600 , error =  0.0
training @ iter = 85700 , loss =  0.0372592583299
training @ iter = 85700 , error =  0.02
training @ iter = 85800 , loss =  0.0106138922274
training @ iter = 85800 , error =  0.0
training @ iter = 85900 , loss =  0.00576522015035
training @ iter = 85900 , error =  0.0
training @ iter = 86000 , loss =  0.0622882507741
training @ iter = 86000 , error =  0.02
training @ iter = 86100 , loss =  0.0378970988095
training @ iter = 86100 , error =  0.0
--> train minibatch error =  0.12  at iter  86183
-->  12 750 chunk_22_50000.pkl
training @ iter = 86200 , loss =  0.0126403383911
training @ iter = 86200 , error =  0.0
training @ iter = 86300 , loss =  0.00313064339571
training @ iter = 86300 , error =  0.0
training @ iter = 86400 , loss =  0.00297991093248
training @ iter = 86400 , error =  0.0
training @ iter = 86500 , loss =  0.0741234719753
training @ iter = 86500 , error =  0.02
training @ iter = 86600 , loss =  0.00101294193882
training @ iter = 86600 , error =  0.0
training @ iter = 86700 , loss =  0.0739246606827
training @ iter = 86700 , error =  0.02
training @ iter = 86800 , loss =  0.0256876666099
training @ iter = 86800 , error =  0.0
training @ iter = 86900 , loss =  0.00949563458562
training @ iter = 86900 , error =  0.0
training @ iter = 87000 , loss =  0.0130787678063
training @ iter = 87000 , error =  0.0
training @ iter = 87100 , loss =  0.0241586714983
training @ iter = 87100 , error =  0.0
training @ iter = 87200 , loss =  0.00970047246665
training @ iter = 87200 , error =  0.0
training @ iter = 87300 , loss =  0.00187520147301
training @ iter = 87300 , error =  0.0
--> train minibatch error =  0.14  at iter  87364
-->  13 9800 chunk_23_50000.pkl
training @ iter = 87400 , loss =  0.0152510749176
training @ iter = 87400 , error =  0.0
training @ iter = 87500 , loss =  0.00478589721024
training @ iter = 87500 , error =  0.0
training @ iter = 87600 , loss =  0.00440076179802
training @ iter = 87600 , error =  0.0
training @ iter = 87700 , loss =  0.00447372952476
training @ iter = 87700 , error =  0.0
training @ iter = 87800 , loss =  0.042144279927
training @ iter = 87800 , error =  0.0
training @ iter = 87900 , loss =  0.00282000470906
training @ iter = 87900 , error =  0.0
training @ iter = 88000 , loss =  0.00439803022891
training @ iter = 88000 , error =  0.0
training @ iter = 88100 , loss =  0.073257945478
training @ iter = 88100 , error =  0.04
training @ iter = 88200 , loss =  0.0148790450767
training @ iter = 88200 , error =  0.0
training @ iter = 88300 , loss =  0.0710749030113
training @ iter = 88300 , error =  0.02
training @ iter = 88400 , loss =  0.015587775968
training @ iter = 88400 , error =  0.0
training @ iter = 88500 , loss =  0.00889756903052
training @ iter = 88500 , error =  0.0
training @ iter = 88600 , loss =  0.0934569165111
training @ iter = 88600 , error =  0.04
training @ iter = 88700 , loss =  0.00567036028951
training @ iter = 88700 , error =  0.0
training @ iter = 88800 , loss =  0.0127676045522
training @ iter = 88800 , error =  0.0
training @ iter = 88900 , loss =  0.0193046759814
training @ iter = 88900 , error =  0.0
training @ iter = 89000 , loss =  0.00214886362664
training @ iter = 89000 , error =  0.0
training @ iter = 89100 , loss =  0.0200558211654
training @ iter = 89100 , error =  0.0
training @ iter = 89200 , loss =  0.00686115724966
training @ iter = 89200 , error =  0.0
training @ iter = 89300 , loss =  0.00124881917145
training @ iter = 89300 , error =  0.0
training @ iter = 89400 , loss =  0.00630514044315
training @ iter = 89400 , error =  0.0
training @ iter = 89500 , loss =  0.0736980736256
training @ iter = 89500 , error =  0.02
training @ iter = 89600 , loss =  0.00568746728823
training @ iter = 89600 , error =  0.0
training @ iter = 89700 , loss =  0.12853628397
training @ iter = 89700 , error =  0.04
training @ iter = 89800 , loss =  0.00645560026169
training @ iter = 89800 , error =  0.0
training @ iter = 89900 , loss =  0.0125431809574
training @ iter = 89900 , error =  0.0
validation @ iter 90000
epoch 0, iter 90000, train buffer error 0.900000 %
epoch 0, iter 90000, validation loss 0.025505
epoch 0, iter 90000, validation error 0.833000 %
patience before checkBest 140000
patience after checkBest 140000
training @ iter = 90000 , loss =  0.00367098860443
training @ iter = 90000 , error =  0.0
training @ iter = 90100 , loss =  0.10430072993
training @ iter = 90100 , error =  0.02
training @ iter = 90200 , loss =  0.00193520530593
training @ iter = 90200 , error =  0.0
training @ iter = 90300 , loss =  0.00361782219261
training @ iter = 90300 , error =  0.0
training @ iter = 90400 , loss =  0.00283470284194
training @ iter = 90400 , error =  0.0
training @ iter = 90500 , loss =  0.0128043340519
training @ iter = 90500 , error =  0.0
training @ iter = 90600 , loss =  0.000731420062948
training @ iter = 90600 , error =  0.0
training @ iter = 90700 , loss =  0.0120378015563
training @ iter = 90700 , error =  0.0
training @ iter = 90800 , loss =  0.00285156071186
training @ iter = 90800 , error =  0.0
training @ iter = 90900 , loss =  0.138246148825
training @ iter = 90900 , error =  0.02
training @ iter = 91000 , loss =  0.117586582899
training @ iter = 91000 , error =  0.04
training @ iter = 91100 , loss =  0.00384025392123
training @ iter = 91100 , error =  0.0
--> train minibatch error =  0.14  at iter  91156
-->  16 49400 chunk_26_50000.pkl
training @ iter = 91200 , loss =  0.00737619539723
training @ iter = 91200 , error =  0.0
training @ iter = 91300 , loss =  0.00113683077507
training @ iter = 91300 , error =  0.0
training @ iter = 91400 , loss =  0.00361274648458
training @ iter = 91400 , error =  0.0
training @ iter = 91500 , loss =  0.00165300280787
training @ iter = 91500 , error =  0.0
training @ iter = 91600 , loss =  0.139170646667
training @ iter = 91600 , error =  0.02
training @ iter = 91700 , loss =  0.00275201443583
training @ iter = 91700 , error =  0.0
training @ iter = 91800 , loss =  0.00448794197291
training @ iter = 91800 , error =  0.0
training @ iter = 91900 , loss =  0.00140151218511
training @ iter = 91900 , error =  0.0
training @ iter = 92000 , loss =  0.00323964189738
training @ iter = 92000 , error =  0.0
training @ iter = 92100 , loss =  0.00317361066118
training @ iter = 92100 , error =  0.0
training @ iter = 92200 , loss =  0.00613585487008
training @ iter = 92200 , error =  0.0
training @ iter = 92300 , loss =  0.00238126982003
training @ iter = 92300 , error =  0.0
training @ iter = 92400 , loss =  0.00172447378282
training @ iter = 92400 , error =  0.0
training @ iter = 92500 , loss =  0.0246681831777
training @ iter = 92500 , error =  0.02
training @ iter = 92600 , loss =  0.00512503506616
training @ iter = 92600 , error =  0.0
training @ iter = 92700 , loss =  0.0975889861584
training @ iter = 92700 , error =  0.02
training @ iter = 92800 , loss =  0.0455044060946
training @ iter = 92800 , error =  0.04
ERROR:  /home/shared/Fields_12-2015/chunks_feat_50000/chunks_train/chunk_28_50000.pkl  has  4  candidates.
training @ iter = 92900 , loss =  0.0979608893394
training @ iter = 92900 , error =  0.02
training @ iter = 93000 , loss =  0.00271014147438
training @ iter = 93000 , error =  0.0
--> train minibatch error =  0.12  at iter  93070
-->  19 8950 chunk_4_50000.pkl
training @ iter = 93100 , loss =  0.121377259493
training @ iter = 93100 , error =  0.08
training @ iter = 93200 , loss =  0.0185838583857
training @ iter = 93200 , error =  0.0
training @ iter = 93300 , loss =  0.0124445417896
training @ iter = 93300 , error =  0.0
training @ iter = 93400 , loss =  0.0199083685875
training @ iter = 93400 , error =  0.0
training @ iter = 93500 , loss =  0.0153633495793
training @ iter = 93500 , error =  0.0
training @ iter = 93600 , loss =  0.0187765713781
training @ iter = 93600 , error =  0.0
training @ iter = 93700 , loss =  0.00122118601575
training @ iter = 93700 , error =  0.0
training @ iter = 93800 , loss =  0.00523813674226
training @ iter = 93800 , error =  0.0
training @ iter = 93900 , loss =  0.018259992823
training @ iter = 93900 , error =  0.0
training @ iter = 94000 , loss =  0.0107813477516
training @ iter = 94000 , error =  0.0
--> train minibatch error =  0.28  at iter  94009
-->  20 5900 chunk_5_50000.pkl
--> train minibatch error =  0.14  at iter  94010
-->  20 5950 chunk_5_50000.pkl
training @ iter = 94100 , loss =  0.02179646492
training @ iter = 94100 , error =  0.02
training @ iter = 94200 , loss =  0.0500094406307
training @ iter = 94200 , error =  0.02
training @ iter = 94300 , loss =  0.0552986972034
training @ iter = 94300 , error =  0.0
training @ iter = 94400 , loss =  0.00327605963685
training @ iter = 94400 , error =  0.0
training @ iter = 94500 , loss =  0.00140713411383
training @ iter = 94500 , error =  0.0
training @ iter = 94600 , loss =  0.0149800805375
training @ iter = 94600 , error =  0.0
training @ iter = 94700 , loss =  0.0187623184174
training @ iter = 94700 , error =  0.0
training @ iter = 94800 , loss =  0.0385942831635
training @ iter = 94800 , error =  0.02
training @ iter = 94900 , loss =  0.146514892578
training @ iter = 94900 , error =  0.02
training @ iter = 95000 , loss =  0.00139577582013
training @ iter = 95000 , error =  0.0
training @ iter = 95100 , loss =  0.026550065726
training @ iter = 95100 , error =  0.0
training @ iter = 95200 , loss =  0.069413729012
training @ iter = 95200 , error =  0.04
training @ iter = 95300 , loss =  0.0466510802507
training @ iter = 95300 , error =  0.02
training @ iter = 95400 , loss =  0.0152904149145
training @ iter = 95400 , error =  0.0
training @ iter = 95500 , loss =  0.0049034608528
training @ iter = 95500 , error =  0.0
training @ iter = 95600 , loss =  0.00851047039032
training @ iter = 95600 , error =  0.0
training @ iter = 95700 , loss =  0.006390592549
training @ iter = 95700 , error =  0.0
training @ iter = 95800 , loss =  0.0095432177186
training @ iter = 95800 , error =  0.0
training @ iter = 95900 , loss =  0.0411208719015
training @ iter = 95900 , error =  0.02
training @ iter = 96000 , loss =  0.0104127908126
training @ iter = 96000 , error =  0.0
training @ iter = 96100 , loss =  0.00490755820647
training @ iter = 96100 , error =  0.0
training @ iter = 96200 , loss =  0.000903652980924
training @ iter = 96200 , error =  0.0
training @ iter = 96300 , loss =  0.00792951975018
training @ iter = 96300 , error =  0.0
training @ iter = 96400 , loss =  0.0145560242236
training @ iter = 96400 , error =  0.0
training @ iter = 96500 , loss =  0.00346293626353
training @ iter = 96500 , error =  0.0
--> train minibatch error =  0.12  at iter  96510
-->  22 30950 chunk_7_50000.pkl
training @ iter = 96600 , loss =  0.033508900553
training @ iter = 96600 , error =  0.0
training @ iter = 96700 , loss =  0.0158174019307
training @ iter = 96700 , error =  0.02
training @ iter = 96800 , loss =  0.00261916196905
training @ iter = 96800 , error =  0.0
training @ iter = 96900 , loss =  0.00902331620455
training @ iter = 96900 , error =  0.0
training @ iter = 97000 , loss =  0.00522871129215
training @ iter = 97000 , error =  0.0
training @ iter = 97100 , loss =  0.0782301872969
training @ iter = 97100 , error =  0.02
training @ iter = 97200 , loss =  0.123698309064
training @ iter = 97200 , error =  0.06
training @ iter = 97300 , loss =  0.00556405773386
training @ iter = 97300 , error =  0.0
--> train minibatch error =  0.12  at iter  97319
-->  23 21400 chunk_8_50000.pkl
training @ iter = 97400 , loss =  0.00311752269045
training @ iter = 97400 , error =  0.0
training @ iter = 97500 , loss =  0.00203915336169
training @ iter = 97500 , error =  0.0
--> train minibatch error =  0.14  at iter  97531
-->  23 32000 chunk_8_50000.pkl
--> train minibatch error =  0.14  at iter  97532
-->  23 32050 chunk_8_50000.pkl
training @ iter = 97600 , loss =  0.0485140420496
training @ iter = 97600 , error =  0.0
training @ iter = 97700 , loss =  0.00337411672808
training @ iter = 97700 , error =  0.0
training @ iter = 97800 , loss =  0.00147578353062
training @ iter = 97800 , error =  0.0
training @ iter = 97900 , loss =  0.000953608367126
training @ iter = 97900 , error =  0.0
training @ iter = 98000 , loss =  0.00926067400724
training @ iter = 98000 , error =  0.0
training @ iter = 98100 , loss =  0.00796778127551
training @ iter = 98100 , error =  0.0
training @ iter = 98200 , loss =  0.0660240203142
training @ iter = 98200 , error =  0.02
training @ iter = 98300 , loss =  0.126774728298
training @ iter = 98300 , error =  0.06
training @ iter = 98400 , loss =  0.0378224216402
training @ iter = 98400 , error =  0.0
training @ iter = 98500 , loss =  0.00124576652888
training @ iter = 98500 , error =  0.0
--> train minibatch error =  0.22  at iter  98585
-->  24 34700 chunk_9_50000.pkl
--> train minibatch error =  0.12  at iter  98586
-->  24 34750 chunk_9_50000.pkl
--> train minibatch error =  0.36  at iter  98587
-->  24 34800 chunk_9_50000.pkl
--> train minibatch error =  0.36  at iter  98588
-->  24 34850 chunk_9_50000.pkl
training @ iter = 98600 , loss =  0.0511360168457
training @ iter = 98600 , error =  0.0
training @ iter = 98700 , loss =  0.0116121442989
training @ iter = 98700 , error =  0.0
training @ iter = 98800 , loss =  0.0489475093782
training @ iter = 98800 , error =  0.02
Epoch  4 , iteration  98892 training @ iter = 98900 , loss =  0.00801965687424
training @ iter = 98900 , error =  0.0
training @ iter = 99000 , loss =  0.0708382502198
training @ iter = 99000 , error =  0.02
training @ iter = 99100 , loss =  0.160674020648
training @ iter = 99100 , error =  0.02
training @ iter = 99200 , loss =  0.00148031651042
training @ iter = 99200 , error =  0.0
training @ iter = 99300 , loss =  0.0460443198681
training @ iter = 99300 , error =  0.02
training @ iter = 99400 , loss =  0.00705232843757
training @ iter = 99400 , error =  0.0
training @ iter = 99500 , loss =  0.01122931391
training @ iter = 99500 , error =  0.0
training @ iter = 99600 , loss =  0.0104005625471
training @ iter = 99600 , error =  0.0
training @ iter = 99700 , loss =  0.00142126204446
training @ iter = 99700 , error =  0.0
training @ iter = 99800 , loss =  0.00205691251904
training @ iter = 99800 , error =  0.0
training @ iter = 99900 , loss =  0.00506396638229
training @ iter = 99900 , error =  0.0
Saving @ iter  100000
Learning rate:  0.02
validation @ iter 100000
epoch 0, iter 100000, train buffer error 0.800000 %
epoch 0, iter 100000, validation loss 0.024206
epoch 0, iter 100000, validation error 0.738000 %
patience before checkBest 140000
patience after checkBest 140000
training @ iter = 100000 , loss =  0.226211845875
training @ iter = 100000 , error =  0.04
training @ iter = 100100 , loss =  0.0910741314292
training @ iter = 100100 , error =  0.02
training @ iter = 100200 , loss =  0.00810496415943
training @ iter = 100200 , error =  0.0
--> train minibatch error =  0.12  at iter  100214
-->  1 16150 chunk_11_50000.pkl
training @ iter = 100300 , loss =  0.00657647615299
training @ iter = 100300 , error =  0.0
training @ iter = 100400 , loss =  0.0601994469762
training @ iter = 100400 , error =  0.02
training @ iter = 100500 , loss =  0.00159100594465
training @ iter = 100500 , error =  0.0
training @ iter = 100600 , loss =  0.00695241615176
training @ iter = 100600 , error =  0.02
training @ iter = 100700 , loss =  0.00340312928893
training @ iter = 100700 , error =  0.0
training @ iter = 100800 , loss =  0.00523909460753
training @ iter = 100800 , error =  0.0
training @ iter = 100900 , loss =  0.0264072436839
training @ iter = 100900 , error =  0.0
training @ iter = 101000 , loss =  0.0187222622335
training @ iter = 101000 , error =  0.0
--> train minibatch error =  0.14  at iter  101021
-->  2 6500 chunk_12_50000.pkl
training @ iter = 101100 , loss =  0.0028292753268
training @ iter = 101100 , error =  0.0
training @ iter = 101200 , loss =  0.0200813245028
training @ iter = 101200 , error =  0.02
training @ iter = 101300 , loss =  0.00641674688086
training @ iter = 101300 , error =  0.0
training @ iter = 101400 , loss =  0.00284075015225
training @ iter = 101400 , error =  0.0
training @ iter = 101500 , loss =  0.00217397208326
training @ iter = 101500 , error =  0.0
training @ iter = 101600 , loss =  0.000651669804938
training @ iter = 101600 , error =  0.0
training @ iter = 101700 , loss =  0.118705503643
training @ iter = 101700 , error =  0.02
training @ iter = 101800 , loss =  0.00189194595441
training @ iter = 101800 , error =  0.0
training @ iter = 101900 , loss =  0.0109545346349
training @ iter = 101900 , error =  0.0
training @ iter = 102000 , loss =  0.0148817980662
training @ iter = 102000 , error =  0.0
training @ iter = 102100 , loss =  0.0114324353635
training @ iter = 102100 , error =  0.0
training @ iter = 102200 , loss =  0.00127057614736
training @ iter = 102200 , error =  0.0
--> train minibatch error =  0.12  at iter  102269
-->  3 18900 chunk_13_50000.pkl
training @ iter = 102300 , loss =  0.0059746732004
training @ iter = 102300 , error =  0.0
training @ iter = 102400 , loss =  0.00118591659702
training @ iter = 102400 , error =  0.0
training @ iter = 102500 , loss =  0.0149820577353
training @ iter = 102500 , error =  0.0
--> train minibatch error =  0.12  at iter  102533
-->  3 32100 chunk_13_50000.pkl
--> train minibatch error =  0.12  at iter  102571
-->  3 34000 chunk_13_50000.pkl
training @ iter = 102600 , loss =  0.00286222272553
training @ iter = 102600 , error =  0.0
training @ iter = 102700 , loss =  0.00546188792214
training @ iter = 102700 , error =  0.0
training @ iter = 102800 , loss =  0.0112583171576
training @ iter = 102800 , error =  0.02
training @ iter = 102900 , loss =  0.0281020998955
training @ iter = 102900 , error =  0.0
training @ iter = 103000 , loss =  0.00217231083661
training @ iter = 103000 , error =  0.0
training @ iter = 103100 , loss =  0.00347933056764
training @ iter = 103100 , error =  0.0
training @ iter = 103200 , loss =  0.00652542850003
training @ iter = 103200 , error =  0.02
training @ iter = 103300 , loss =  0.00417254678905
training @ iter = 103300 , error =  0.0
training @ iter = 103400 , loss =  0.00304496753961
training @ iter = 103400 , error =  0.0
training @ iter = 103500 , loss =  0.00324794463813
training @ iter = 103500 , error =  0.0
training @ iter = 103600 , loss =  0.00383300846443
training @ iter = 103600 , error =  0.0
training @ iter = 103700 , loss =  0.00458097085357
training @ iter = 103700 , error =  0.0
training @ iter = 103800 , loss =  0.00106265966315
training @ iter = 103800 , error =  0.0
training @ iter = 103900 , loss =  0.0309932045639
training @ iter = 103900 , error =  0.02
training @ iter = 104000 , loss =  0.00865634810179
training @ iter = 104000 , error =  0.0
training @ iter = 104100 , loss =  0.00456399330869
training @ iter = 104100 , error =  0.0
training @ iter = 104200 , loss =  0.00173937366344
training @ iter = 104200 , error =  0.0
training @ iter = 104300 , loss =  0.00579815171659
training @ iter = 104300 , error =  0.0
training @ iter = 104400 , loss =  0.00114453781862
training @ iter = 104400 , error =  0.0
training @ iter = 104500 , loss =  0.0671758055687
training @ iter = 104500 , error =  0.02
training @ iter = 104600 , loss =  0.00178749498446
training @ iter = 104600 , error =  0.0
training @ iter = 104700 , loss =  0.000708614301402
training @ iter = 104700 , error =  0.0
training @ iter = 104800 , loss =  0.0986024662852
training @ iter = 104800 , error =  0.04
training @ iter = 104900 , loss =  0.0539937540889
training @ iter = 104900 , error =  0.02
training @ iter = 105000 , loss =  0.00266718864441
training @ iter = 105000 , error =  0.0
training @ iter = 105100 , loss =  0.00472567277029
training @ iter = 105100 , error =  0.0
training @ iter = 105200 , loss =  0.140931472182
training @ iter = 105200 , error =  0.04
training @ iter = 105300 , loss =  0.079741448164
training @ iter = 105300 , error =  0.02
training @ iter = 105400 , loss =  0.00362698384561
training @ iter = 105400 , error =  0.0
training @ iter = 105500 , loss =  0.00426782062277
training @ iter = 105500 , error =  0.0
training @ iter = 105600 , loss =  0.034485001117
training @ iter = 105600 , error =  0.02
training @ iter = 105700 , loss =  0.00328998151235
training @ iter = 105700 , error =  0.0
training @ iter = 105800 , loss =  0.0456991046667
training @ iter = 105800 , error =  0.0
training @ iter = 105900 , loss =  0.0317433252931
training @ iter = 105900 , error =  0.0
training @ iter = 106000 , loss =  0.00314511009492
training @ iter = 106000 , error =  0.0
training @ iter = 106100 , loss =  0.00934903603047
training @ iter = 106100 , error =  0.0
training @ iter = 106200 , loss =  0.117971546948
training @ iter = 106200 , error =  0.02
training @ iter = 106300 , loss =  0.000668633496389
training @ iter = 106300 , error =  0.0
training @ iter = 106400 , loss =  0.0114857042208
training @ iter = 106400 , error =  0.0
training @ iter = 106500 , loss =  0.0142661742866
training @ iter = 106500 , error =  0.0
--> train minibatch error =  0.18  at iter  106558
-->  7 33350 chunk_17_50000.pkl
training @ iter = 106600 , loss =  0.00671068858355
training @ iter = 106600 , error =  0.0
training @ iter = 106700 , loss =  0.0357888303697
training @ iter = 106700 , error =  0.0
training @ iter = 106800 , loss =  0.00676792021841
training @ iter = 106800 , error =  0.0
training @ iter = 106900 , loss =  0.243201255798
training @ iter = 106900 , error =  0.08
--> train minibatch error =  0.12  at iter  106986
-->  8 4750 chunk_18_50000.pkl
training @ iter = 107000 , loss =  0.0118377804756
training @ iter = 107000 , error =  0.0
training @ iter = 107100 , loss =  0.00116435438395
training @ iter = 107100 , error =  0.0
training @ iter = 107200 , loss =  0.0024015463423
training @ iter = 107200 , error =  0.0
training @ iter = 107300 , loss =  0.00250896299258
training @ iter = 107300 , error =  0.0
training @ iter = 107400 , loss =  0.115981295705
training @ iter = 107400 , error =  0.04
--> train minibatch error =  0.16  at iter  107497
-->  8 30300 chunk_18_50000.pkl
--> train minibatch error =  0.28  at iter  107498
-->  8 30350 chunk_18_50000.pkl
training @ iter = 107500 , loss =  0.0730765610933
training @ iter = 107500 , error =  0.02
--> train minibatch error =  0.14  at iter  107563
-->  8 33600 chunk_18_50000.pkl
training @ iter = 107600 , loss =  0.00167487363797
training @ iter = 107600 , error =  0.0
training @ iter = 107700 , loss =  0.0373486913741
training @ iter = 107700 , error =  0.0
training @ iter = 107800 , loss =  0.122294619679
training @ iter = 107800 , error =  0.04
training @ iter = 107900 , loss =  0.00185347581282
training @ iter = 107900 , error =  0.0
training @ iter = 108000 , loss =  0.0100144622847
training @ iter = 108000 , error =  0.0
training @ iter = 108100 , loss =  0.0106776319444
training @ iter = 108100 , error =  0.0
training @ iter = 108200 , loss =  0.0539818108082
training @ iter = 108200 , error =  0.02
training @ iter = 108300 , loss =  0.00625476241112
training @ iter = 108300 , error =  0.0
training @ iter = 108400 , loss =  0.0243116710335
training @ iter = 108400 , error =  0.0
--> train minibatch error =  0.14  at iter  108488
-->  9 29850 chunk_19_50000.pkl
training @ iter = 108500 , loss =  0.00592550635338
training @ iter = 108500 , error =  0.0
training @ iter = 108600 , loss =  0.00823972281069
training @ iter = 108600 , error =  0.0
training @ iter = 108700 , loss =  0.00552493333817
training @ iter = 108700 , error =  0.0
training @ iter = 108800 , loss =  0.0270424373448
training @ iter = 108800 , error =  0.02
training @ iter = 108900 , loss =  0.00183210789692
training @ iter = 108900 , error =  0.0
training @ iter = 109000 , loss =  0.0044742631726
training @ iter = 109000 , error =  0.0
--> train minibatch error =  0.18  at iter  109073
-->  10 9100 chunk_20_50000.pkl
training @ iter = 109100 , loss =  0.0466087162495
training @ iter = 109100 , error =  0.02
training @ iter = 109200 , loss =  0.0515550561249
training @ iter = 109200 , error =  0.02
--> train minibatch error =  0.12  at iter  109225
-->  10 16700 chunk_20_50000.pkl
training @ iter = 109300 , loss =  0.00503479316831
training @ iter = 109300 , error =  0.0
training @ iter = 109400 , loss =  0.00601334078237
training @ iter = 109400 , error =  0.0
training @ iter = 109500 , loss =  0.0694525241852
training @ iter = 109500 , error =  0.04
training @ iter = 109600 , loss =  0.00803665537387
training @ iter = 109600 , error =  0.0
training @ iter = 109700 , loss =  0.00668659014627
training @ iter = 109700 , error =  0.0
training @ iter = 109800 , loss =  0.0018985173665
training @ iter = 109800 , error =  0.0
training @ iter = 109900 , loss =  0.00146890059114
training @ iter = 109900 , error =  0.0
validation @ iter 110000
epoch 0, iter 110000, train buffer error 0.600000 %
epoch 0, iter 110000, validation loss 0.021669
epoch 0, iter 110000, validation error 0.692000 %
patience before checkBest 140000
Patience =  210000
patience after checkBest 210000
training @ iter = 110000 , loss =  0.00929706729949
training @ iter = 110000 , error =  0.0
training @ iter = 110100 , loss =  0.00127410772257
training @ iter = 110100 , error =  0.0
training @ iter = 110200 , loss =  0.00110557256266
training @ iter = 110200 , error =  0.0
training @ iter = 110300 , loss =  0.0444327816367
training @ iter = 110300 , error =  0.02
training @ iter = 110400 , loss =  0.0653155818582
training @ iter = 110400 , error =  0.02
training @ iter = 110500 , loss =  0.0422241985798
training @ iter = 110500 , error =  0.02
training @ iter = 110600 , loss =  0.0171485841274
training @ iter = 110600 , error =  0.0
training @ iter = 110700 , loss =  0.00101023796014
training @ iter = 110700 , error =  0.0
training @ iter = 110800 , loss =  0.056256622076
training @ iter = 110800 , error =  0.04
training @ iter = 110900 , loss =  0.047193121165
training @ iter = 110900 , error =  0.02
--> train minibatch error =  0.12  at iter  110906
-->  12 750 chunk_22_50000.pkl
training @ iter = 111000 , loss =  0.00185289327055
training @ iter = 111000 , error =  0.0
training @ iter = 111100 , loss =  0.0119828544557
training @ iter = 111100 , error =  0.0
training @ iter = 111200 , loss =  0.00104872370139
training @ iter = 111200 , error =  0.0
training @ iter = 111300 , loss =  0.0041775656864
training @ iter = 111300 , error =  0.0
training @ iter = 111400 , loss =  0.00203670142218
training @ iter = 111400 , error =  0.0
training @ iter = 111500 , loss =  0.000977022107691
training @ iter = 111500 , error =  0.0
training @ iter = 111600 , loss =  0.00178464595228
training @ iter = 111600 , error =  0.0
training @ iter = 111700 , loss =  0.001090567559
training @ iter = 111700 , error =  0.0
training @ iter = 111800 , loss =  0.00104431342334
training @ iter = 111800 , error =  0.0
training @ iter = 111900 , loss =  0.00287218112499
training @ iter = 111900 , error =  0.0
training @ iter = 112000 , loss =  0.0211823005229
training @ iter = 112000 , error =  0.0
--> train minibatch error =  0.14  at iter  112087
-->  13 9800 chunk_23_50000.pkl
training @ iter = 112100 , loss =  0.0131443785504
training @ iter = 112100 , error =  0.0
training @ iter = 112200 , loss =  0.0634202435613
training @ iter = 112200 , error =  0.02
training @ iter = 112300 , loss =  0.0021044081077
training @ iter = 112300 , error =  0.0
training @ iter = 112400 , loss =  0.0161460209638
training @ iter = 112400 , error =  0.0
training @ iter = 112500 , loss =  0.00408640038222
training @ iter = 112500 , error =  0.0
training @ iter = 112600 , loss =  0.0226931199431
training @ iter = 112600 , error =  0.02
training @ iter = 112700 , loss =  0.0184061788023
training @ iter = 112700 , error =  0.0
training @ iter = 112800 , loss =  0.0907019451261
training @ iter = 112800 , error =  0.04
training @ iter = 112900 , loss =  0.00452395156026
training @ iter = 112900 , error =  0.0
training @ iter = 113000 , loss =  0.0216114688665
training @ iter = 113000 , error =  0.02
training @ iter = 113100 , loss =  0.0541941076517
training @ iter = 113100 , error =  0.02
training @ iter = 113200 , loss =  0.0100856069475
training @ iter = 113200 , error =  0.0
training @ iter = 113300 , loss =  0.00122507964261
training @ iter = 113300 , error =  0.0
training @ iter = 113400 , loss =  0.00063252018299
training @ iter = 113400 , error =  0.0
training @ iter = 113500 , loss =  0.00339393434115
training @ iter = 113500 , error =  0.0
training @ iter = 113600 , loss =  0.000688043248374
training @ iter = 113600 , error =  0.0
training @ iter = 113700 , loss =  0.0222305972129
training @ iter = 113700 , error =  0.02
training @ iter = 113800 , loss =  0.00394174642861
training @ iter = 113800 , error =  0.0
training @ iter = 113900 , loss =  0.00175061286427
training @ iter = 113900 , error =  0.0
training @ iter = 114000 , loss =  0.00175478099845
training @ iter = 114000 , error =  0.0
training @ iter = 114100 , loss =  0.0254291910678
training @ iter = 114100 , error =  0.0
training @ iter = 114200 , loss =  0.107609942555
training @ iter = 114200 , error =  0.02
training @ iter = 114300 , loss =  0.0852817595005
training @ iter = 114300 , error =  0.02
training @ iter = 114400 , loss =  0.00207786029205
training @ iter = 114400 , error =  0.0
training @ iter = 114500 , loss =  0.000844115042128
training @ iter = 114500 , error =  0.0
training @ iter = 114600 , loss =  0.0325411222875
training @ iter = 114600 , error =  0.0
training @ iter = 114700 , loss =  0.005313845817
training @ iter = 114700 , error =  0.0
training @ iter = 114800 , loss =  0.00173443113454
training @ iter = 114800 , error =  0.0
training @ iter = 114900 , loss =  0.00400993600488
training @ iter = 114900 , error =  0.0
training @ iter = 115000 , loss =  0.00245828321204
training @ iter = 115000 , error =  0.0
training @ iter = 115100 , loss =  0.00558518944308
training @ iter = 115100 , error =  0.0
training @ iter = 115200 , loss =  0.000768453348428
training @ iter = 115200 , error =  0.0
training @ iter = 115300 , loss =  0.00274380925111
training @ iter = 115300 , error =  0.0
training @ iter = 115400 , loss =  0.00140796776395
training @ iter = 115400 , error =  0.0
training @ iter = 115500 , loss =  0.154350325465
training @ iter = 115500 , error =  0.02
training @ iter = 115600 , loss =  0.0765589028597
training @ iter = 115600 , error =  0.04
training @ iter = 115700 , loss =  0.0140826180577
training @ iter = 115700 , error =  0.0
training @ iter = 115800 , loss =  0.00192758906633
training @ iter = 115800 , error =  0.0
--> train minibatch error =  0.14  at iter  115879
-->  16 49400 chunk_26_50000.pkl
training @ iter = 115900 , loss =  0.00184140983038
training @ iter = 115900 , error =  0.0
training @ iter = 116000 , loss =  0.0107351671904
training @ iter = 116000 , error =  0.0
training @ iter = 116100 , loss =  0.00274185696617
training @ iter = 116100 , error =  0.0
training @ iter = 116200 , loss =  0.00514288665727
training @ iter = 116200 , error =  0.0
training @ iter = 116300 , loss =  0.00107092189137
training @ iter = 116300 , error =  0.0
training @ iter = 116400 , loss =  0.00550392642617
training @ iter = 116400 , error =  0.0
training @ iter = 116500 , loss =  0.0013151258463
training @ iter = 116500 , error =  0.0
training @ iter = 116600 , loss =  0.0173989851028
training @ iter = 116600 , error =  0.02
training @ iter = 116700 , loss =  0.00267767766491
training @ iter = 116700 , error =  0.0
training @ iter = 116800 , loss =  0.00225846027024
training @ iter = 116800 , error =  0.0
training @ iter = 116900 , loss =  0.00106319284532
training @ iter = 116900 , error =  0.0
training @ iter = 117000 , loss =  0.0124034248292
training @ iter = 117000 , error =  0.0
training @ iter = 117100 , loss =  0.069799631834
training @ iter = 117100 , error =  0.02
training @ iter = 117200 , loss =  0.00233297329396
training @ iter = 117200 , error =  0.0
training @ iter = 117300 , loss =  0.00177175016142
training @ iter = 117300 , error =  0.0
training @ iter = 117400 , loss =  0.00142714765389
training @ iter = 117400 , error =  0.0
training @ iter = 117500 , loss =  0.00417095376179
training @ iter = 117500 , error =  0.02
training @ iter = 117600 , loss =  0.00120479625184
training @ iter = 117600 , error =  0.0
ERROR:  /home/shared/Fields_12-2015/chunks_feat_50000/chunks_train/chunk_28_50000.pkl  has  4  candidates.
training @ iter = 117700 , loss =  0.197560459375
training @ iter = 117700 , error =  0.04
training @ iter = 117800 , loss =  0.00103147607297
training @ iter = 117800 , error =  0.0
training @ iter = 117900 , loss =  0.0719616562128
training @ iter = 117900 , error =  0.04
training @ iter = 118000 , loss =  0.0120160793886
training @ iter = 118000 , error =  0.02
training @ iter = 118100 , loss =  0.00225989357568
training @ iter = 118100 , error =  0.0
training @ iter = 118200 , loss =  0.00507309613749
training @ iter = 118200 , error =  0.0
training @ iter = 118300 , loss =  0.000989920692518
training @ iter = 118300 , error =  0.0
training @ iter = 118400 , loss =  0.0012688228162
training @ iter = 118400 , error =  0.0
training @ iter = 118500 , loss =  0.0452680103481
training @ iter = 118500 , error =  0.02
training @ iter = 118600 , loss =  0.0051115793176
training @ iter = 118600 , error =  0.0
training @ iter = 118700 , loss =  0.0359139069915
training @ iter = 118700 , error =  0.02
--> train minibatch error =  0.24  at iter  118732
-->  20 5900 chunk_5_50000.pkl
--> train minibatch error =  0.16  at iter  118733
-->  20 5950 chunk_5_50000.pkl
training @ iter = 118800 , loss =  0.00174760585651
training @ iter = 118800 , error =  0.0
training @ iter = 118900 , loss =  0.00345055223443
training @ iter = 118900 , error =  0.0
training @ iter = 119000 , loss =  0.0522059872746
training @ iter = 119000 , error =  0.02
training @ iter = 119100 , loss =  0.0104793962091
training @ iter = 119100 , error =  0.0
training @ iter = 119200 , loss =  0.0501119717956
training @ iter = 119200 , error =  0.02
training @ iter = 119300 , loss =  0.0434818267822
training @ iter = 119300 , error =  0.02
training @ iter = 119400 , loss =  0.0175007265061
training @ iter = 119400 , error =  0.0
training @ iter = 119500 , loss =  0.0196782071143
training @ iter = 119500 , error =  0.0
training @ iter = 119600 , loss =  0.0406783856452
training @ iter = 119600 , error =  0.02
training @ iter = 119700 , loss =  0.163329198956
training @ iter = 119700 , error =  0.1
training @ iter = 119800 , loss =  0.00217074505053
training @ iter = 119800 , error =  0.0
training @ iter = 119900 , loss =  0.00448639830574
training @ iter = 119900 , error =  0.0
validation @ iter 120000
epoch 0, iter 120000, train buffer error 0.600000 %
epoch 0, iter 120000, validation loss 0.021480
epoch 0, iter 120000, validation error 0.673000 %
patience before checkBest 210000
Patience =  220000
patience after checkBest 220000
training @ iter = 120000 , loss =  0.0255460515618
training @ iter = 120000 , error =  0.02
training @ iter = 120100 , loss =  0.154485359788
training @ iter = 120100 , error =  0.06
training @ iter = 120200 , loss =  0.00180515844841
training @ iter = 120200 , error =  0.0
training @ iter = 120300 , loss =  0.00448302458972
training @ iter = 120300 , error =  0.0
training @ iter = 120400 , loss =  0.0167072415352
training @ iter = 120400 , error =  0.0
training @ iter = 120500 , loss =  0.0129899382591
training @ iter = 120500 , error =  0.0
training @ iter = 120600 , loss =  0.00618319027126
training @ iter = 120600 , error =  0.0
training @ iter = 120700 , loss =  0.00462104007602
training @ iter = 120700 , error =  0.0
training @ iter = 120800 , loss =  0.0246450956911
training @ iter = 120800 , error =  0.02
training @ iter = 120900 , loss =  0.0235920287669
training @ iter = 120900 , error =  0.02
training @ iter = 121000 , loss =  0.00383624667302
training @ iter = 121000 , error =  0.0
training @ iter = 121100 , loss =  0.00193045462947
training @ iter = 121100 , error =  0.0
training @ iter = 121200 , loss =  0.0402981564403
training @ iter = 121200 , error =  0.02
--> train minibatch error =  0.12  at iter  121233
-->  22 30950 chunk_7_50000.pkl
training @ iter = 121300 , loss =  0.0521385632455
training @ iter = 121300 , error =  0.02
training @ iter = 121400 , loss =  0.00422476744279
training @ iter = 121400 , error =  0.0
training @ iter = 121500 , loss =  0.00184861989692
training @ iter = 121500 , error =  0.0
training @ iter = 121600 , loss =  0.00328932260163
training @ iter = 121600 , error =  0.0
training @ iter = 121700 , loss =  0.159028485417
training @ iter = 121700 , error =  0.04
training @ iter = 121800 , loss =  0.0239857863635
training @ iter = 121800 , error =  0.02
training @ iter = 121900 , loss =  0.0409682653844
training @ iter = 121900 , error =  0.04
training @ iter = 122000 , loss =  0.0105196274817
training @ iter = 122000 , error =  0.0
--> train minibatch error =  0.16  at iter  122042
-->  23 21400 chunk_8_50000.pkl
training @ iter = 122100 , loss =  0.0104616191238
training @ iter = 122100 , error =  0.0
training @ iter = 122200 , loss =  0.0347611680627
training @ iter = 122200 , error =  0.0
--> train minibatch error =  0.12  at iter  122252
-->  23 31900 chunk_8_50000.pkl
training @ iter = 122300 , loss =  0.0703065916896
training @ iter = 122300 , error =  0.02
training @ iter = 122400 , loss =  0.0340640433133
training @ iter = 122400 , error =  0.0
training @ iter = 122500 , loss =  0.0183985140175
training @ iter = 122500 , error =  0.0
training @ iter = 122600 , loss =  0.0123497089371
training @ iter = 122600 , error =  0.0
training @ iter = 122700 , loss =  0.0113414693624
training @ iter = 122700 , error =  0.0
training @ iter = 122800 , loss =  0.0174140390009
training @ iter = 122800 , error =  0.0
training @ iter = 122900 , loss =  0.00201555807143
training @ iter = 122900 , error =  0.0
training @ iter = 123000 , loss =  0.0551083572209
training @ iter = 123000 , error =  0.02
training @ iter = 123100 , loss =  0.10060044378
training @ iter = 123100 , error =  0.04
training @ iter = 123200 , loss =  0.00346533767879
training @ iter = 123200 , error =  0.0
training @ iter = 123300 , loss =  0.0122399451211
training @ iter = 123300 , error =  0.0
--> train minibatch error =  0.22  at iter  123308
-->  24 34700 chunk_9_50000.pkl
--> train minibatch error =  0.26  at iter  123309
-->  24 34750 chunk_9_50000.pkl
training @ iter = 123400 , loss =  0.0185244102031
training @ iter = 123400 , error =  0.02
training @ iter = 123500 , loss =  0.0114108324051
training @ iter = 123500 , error =  0.0
training @ iter = 123600 , loss =  0.00374051998369
training @ iter = 123600 , error =  0.0
Epoch  5 , iteration  123615 training @ iter = 123700 , loss =  0.0280231516808
training @ iter = 123700 , error =  0.02
training @ iter = 123800 , loss =  0.0250769741833
training @ iter = 123800 , error =  0.0
training @ iter = 123900 , loss =  0.00682532181963
training @ iter = 123900 , error =  0.02
training @ iter = 124000 , loss =  0.0406864434481
training @ iter = 124000 , error =  0.02
training @ iter = 124100 , loss =  0.0734932199121
training @ iter = 124100 , error =  0.02
training @ iter = 124200 , loss =  0.000677899515722
training @ iter = 124200 , error =  0.0
training @ iter = 124300 , loss =  0.079922221601
training @ iter = 124300 , error =  0.02
training @ iter = 124400 , loss =  0.00564829353243
training @ iter = 124400 , error =  0.0
training @ iter = 124500 , loss =  0.000723577861208
training @ iter = 124500 , error =  0.0
training @ iter = 124600 , loss =  0.090937808156
training @ iter = 124600 , error =  0.02
training @ iter = 124700 , loss =  0.00418369891122
training @ iter = 124700 , error =  0.0
training @ iter = 124800 , loss =  0.00764620536938
training @ iter = 124800 , error =  0.0
training @ iter = 124900 , loss =  0.0134244691581
training @ iter = 124900 , error =  0.02
--> train minibatch error =  0.14  at iter  124937
-->  1 16150 chunk_11_50000.pkl
Saving @ iter  125000
training @ iter = 125000 , loss =  0.0229067318141
training @ iter = 125000 , error =  0.02
training @ iter = 125100 , loss =  0.00380353094079
training @ iter = 125100 , error =  0.0
training @ iter = 125200 , loss =  0.129580885172
training @ iter = 125200 , error =  0.04
training @ iter = 125300 , loss =  0.0669819414616
training @ iter = 125300 , error =  0.02
training @ iter = 125400 , loss =  0.00187469541561
training @ iter = 125400 , error =  0.0
training @ iter = 125500 , loss =  0.00744240032509
training @ iter = 125500 , error =  0.0
training @ iter = 125600 , loss =  0.00245816027746
training @ iter = 125600 , error =  0.0
training @ iter = 125700 , loss =  0.00189997826237
training @ iter = 125700 , error =  0.0
--> train minibatch error =  0.14  at iter  125744
-->  2 6500 chunk_12_50000.pkl
training @ iter = 125800 , loss =  0.00728313066065
training @ iter = 125800 , error =  0.0
training @ iter = 125900 , loss =  0.0187655352056
training @ iter = 125900 , error =  0.0
training @ iter = 126000 , loss =  0.00485412357375
training @ iter = 126000 , error =  0.0
training @ iter = 126100 , loss =  0.150730341673
training @ iter = 126100 , error =  0.04
training @ iter = 126200 , loss =  0.0431779809296
training @ iter = 126200 , error =  0.0
training @ iter = 126300 , loss =  0.00595020037144
training @ iter = 126300 , error =  0.0
training @ iter = 126400 , loss =  0.0167954992503
training @ iter = 126400 , error =  0.0
training @ iter = 126500 , loss =  0.00158442615066
training @ iter = 126500 , error =  0.0
training @ iter = 126600 , loss =  0.000913257827051
training @ iter = 126600 , error =  0.0
training @ iter = 126700 , loss =  0.0114780226722
training @ iter = 126700 , error =  0.0
training @ iter = 126800 , loss =  0.0188395008445
training @ iter = 126800 , error =  0.02
training @ iter = 126900 , loss =  0.00118448666763
training @ iter = 126900 , error =  0.0
training @ iter = 127000 , loss =  0.00529043935239
training @ iter = 127000 , error =  0.0
training @ iter = 127100 , loss =  0.00753254536539
training @ iter = 127100 , error =  0.0
training @ iter = 127200 , loss =  0.00527492212132
training @ iter = 127200 , error =  0.0
--> train minibatch error =  0.12  at iter  127256
-->  3 32100 chunk_13_50000.pkl
training @ iter = 127300 , loss =  0.0343427993357
training @ iter = 127300 , error =  0.0
training @ iter = 127400 , loss =  0.0164648815989
training @ iter = 127400 , error =  0.0
training @ iter = 127500 , loss =  0.00150189187843
training @ iter = 127500 , error =  0.0
training @ iter = 127600 , loss =  0.00205759098753
training @ iter = 127600 , error =  0.0
training @ iter = 127700 , loss =  0.00131722539663
training @ iter = 127700 , error =  0.0
training @ iter = 127800 , loss =  0.00124239828438
training @ iter = 127800 , error =  0.0
training @ iter = 127900 , loss =  0.00140935066156
training @ iter = 127900 , error =  0.0
training @ iter = 128000 , loss =  0.00259472220205
training @ iter = 128000 , error =  0.0
training @ iter = 128100 , loss =  0.00456382334232
training @ iter = 128100 , error =  0.0
training @ iter = 128200 , loss =  0.0112705733627
training @ iter = 128200 , error =  0.0
training @ iter = 128300 , loss =  0.0243434999138
training @ iter = 128300 , error =  0.0
training @ iter = 128400 , loss =  0.00283566233702
training @ iter = 128400 , error =  0.0
training @ iter = 128500 , loss =  0.074830815196
training @ iter = 128500 , error =  0.02
training @ iter = 128600 , loss =  0.00740070594475
training @ iter = 128600 , error =  0.0
training @ iter = 128700 , loss =  0.0272051505744
training @ iter = 128700 , error =  0.0
training @ iter = 128800 , loss =  0.00378751894459
training @ iter = 128800 , error =  0.0
training @ iter = 128900 , loss =  0.00636384729296
training @ iter = 128900 , error =  0.0
training @ iter = 129000 , loss =  0.000627094006632
training @ iter = 129000 , error =  0.0
training @ iter = 129100 , loss =  0.000848593423143
training @ iter = 129100 , error =  0.0
training @ iter = 129200 , loss =  0.0496468879282
training @ iter = 129200 , error =  0.02
training @ iter = 129300 , loss =  0.00250829732977
training @ iter = 129300 , error =  0.0
training @ iter = 129400 , loss =  0.0296406038105
training @ iter = 129400 , error =  0.0
training @ iter = 129500 , loss =  0.00141086801887
training @ iter = 129500 , error =  0.0
training @ iter = 129600 , loss =  0.0011137254769
training @ iter = 129600 , error =  0.0
training @ iter = 129700 , loss =  0.0377217680216
training @ iter = 129700 , error =  0.02
training @ iter = 129800 , loss =  0.00647104065865
training @ iter = 129800 , error =  0.0
training @ iter = 129900 , loss =  0.00550800981
training @ iter = 129900 , error =  0.0
validation @ iter 130000
epoch 0, iter 130000, train buffer error 0.600000 %
epoch 0, iter 130000, validation loss 0.020201
epoch 0, iter 130000, validation error 0.611000 %
patience before checkBest 220000
Patience =  230000
patience after checkBest 230000
training @ iter = 130000 , loss =  0.000612971722148
training @ iter = 130000 , error =  0.0
training @ iter = 130100 , loss =  0.0165841504931
training @ iter = 130100 , error =  0.02
training @ iter = 130200 , loss =  0.00815945863724
training @ iter = 130200 , error =  0.0
training @ iter = 130300 , loss =  0.0600772239268
training @ iter = 130300 , error =  0.02
training @ iter = 130400 , loss =  0.00420658988878
training @ iter = 130400 , error =  0.0
training @ iter = 130500 , loss =  0.00277024973184
training @ iter = 130500 , error =  0.0
training @ iter = 130600 , loss =  0.00407340517268
training @ iter = 130600 , error =  0.0
training @ iter = 130700 , loss =  0.000414320529671
training @ iter = 130700 , error =  0.0
training @ iter = 130800 , loss =  0.00112584989984
training @ iter = 130800 , error =  0.0
training @ iter = 130900 , loss =  0.00171702587977
training @ iter = 130900 , error =  0.0
training @ iter = 131000 , loss =  0.00179200794082
training @ iter = 131000 , error =  0.0
training @ iter = 131100 , loss =  0.0118226250634
training @ iter = 131100 , error =  0.02
training @ iter = 131200 , loss =  0.0156017793342
training @ iter = 131200 , error =  0.0
--> train minibatch error =  0.18  at iter  131281
-->  7 33350 chunk_17_50000.pkl
training @ iter = 131300 , loss =  0.0176730826497
training @ iter = 131300 , error =  0.02
training @ iter = 131400 , loss =  0.0351452194154
training @ iter = 131400 , error =  0.04
training @ iter = 131500 , loss =  0.00364582776092
training @ iter = 131500 , error =  0.0
training @ iter = 131600 , loss =  0.00260585546494
training @ iter = 131600 , error =  0.0
training @ iter = 131700 , loss =  0.00175469636451
training @ iter = 131700 , error =  0.0
training @ iter = 131800 , loss =  0.0263155605644
training @ iter = 131800 , error =  0.02
training @ iter = 131900 , loss =  0.0192406177521
training @ iter = 131900 , error =  0.0
training @ iter = 132000 , loss =  0.0584889948368
training @ iter = 132000 , error =  0.02
training @ iter = 132100 , loss =  0.140582948923
training @ iter = 132100 , error =  0.04
training @ iter = 132200 , loss =  0.158762201667
training @ iter = 132200 , error =  0.04
--> train minibatch error =  0.14  at iter  132220
-->  8 30300 chunk_18_50000.pkl
--> train minibatch error =  0.22  at iter  132221
-->  8 30350 chunk_18_50000.pkl
--> train minibatch error =  0.14  at iter  132286
-->  8 33600 chunk_18_50000.pkl
training @ iter = 132300 , loss =  0.115743011236
training @ iter = 132300 , error =  0.02
training @ iter = 132400 , loss =  0.0666461139917
training @ iter = 132400 , error =  0.04
training @ iter = 132500 , loss =  0.0166115220636
training @ iter = 132500 , error =  0.02
training @ iter = 132600 , loss =  0.0449531823397
training @ iter = 132600 , error =  0.0
training @ iter = 132700 , loss =  0.0337820500135
training @ iter = 132700 , error =  0.02
training @ iter = 132800 , loss =  0.000768644968048
training @ iter = 132800 , error =  0.0
--> train minibatch error =  0.12  at iter  132825
-->  9 10550 chunk_19_50000.pkl
training @ iter = 132900 , loss =  0.00352214416489
training @ iter = 132900 , error =  0.0
training @ iter = 133000 , loss =  0.012563101016
training @ iter = 133000 , error =  0.0
training @ iter = 133100 , loss =  0.0027799254749
training @ iter = 133100 , error =  0.0
training @ iter = 133200 , loss =  0.0210122633725
training @ iter = 133200 , error =  0.0
--> train minibatch error =  0.14  at iter  133211
-->  9 29850 chunk_19_50000.pkl
training @ iter = 133300 , loss =  0.0418574623764
training @ iter = 133300 , error =  0.02
training @ iter = 133400 , loss =  0.00670513743535
training @ iter = 133400 , error =  0.0
training @ iter = 133500 , loss =  0.00864069443196
training @ iter = 133500 , error =  0.0
training @ iter = 133600 , loss =  0.00217736512423
training @ iter = 133600 , error =  0.0
training @ iter = 133700 , loss =  0.00377614796162
training @ iter = 133700 , error =  0.0
--> train minibatch error =  0.16  at iter  133796
-->  10 9100 chunk_20_50000.pkl
training @ iter = 133800 , loss =  0.00600616214797
training @ iter = 133800 , error =  0.0
training @ iter = 133900 , loss =  0.00424623256549
training @ iter = 133900 , error =  0.0
--> train minibatch error =  0.14  at iter  133948
-->  10 16700 chunk_20_50000.pkl
training @ iter = 134000 , loss =  0.00223779166117
training @ iter = 134000 , error =  0.0
training @ iter = 134100 , loss =  0.0737576410174
training @ iter = 134100 , error =  0.02
training @ iter = 134200 , loss =  0.0311693567783
training @ iter = 134200 , error =  0.02
training @ iter = 134300 , loss =  0.00146157830022
training @ iter = 134300 , error =  0.0
training @ iter = 134400 , loss =  0.00792494323105
training @ iter = 134400 , error =  0.0
training @ iter = 134500 , loss =  0.126586169004
training @ iter = 134500 , error =  0.02
training @ iter = 134600 , loss =  0.00936487782747
training @ iter = 134600 , error =  0.0
training @ iter = 134700 , loss =  0.00118831591681
training @ iter = 134700 , error =  0.0
training @ iter = 134800 , loss =  0.00128806976136
training @ iter = 134800 , error =  0.0
training @ iter = 134900 , loss =  0.00647651217878
training @ iter = 134900 , error =  0.0
training @ iter = 135000 , loss =  0.00192760734353
training @ iter = 135000 , error =  0.0
training @ iter = 135100 , loss =  0.0175092443824
training @ iter = 135100 , error =  0.0
training @ iter = 135200 , loss =  0.00403282511979
training @ iter = 135200 , error =  0.0
training @ iter = 135300 , loss =  0.0102017167956
training @ iter = 135300 , error =  0.0
training @ iter = 135400 , loss =  0.00473071960732
training @ iter = 135400 , error =  0.0
training @ iter = 135500 , loss =  0.0094259371981
training @ iter = 135500 , error =  0.0
training @ iter = 135600 , loss =  0.0565479844809
training @ iter = 135600 , error =  0.0
--> train minibatch error =  0.14  at iter  135629
-->  12 750 chunk_22_50000.pkl
training @ iter = 135700 , loss =  0.00271414290182
training @ iter = 135700 , error =  0.0
training @ iter = 135800 , loss =  0.00549293123186
training @ iter = 135800 , error =  0.0
training @ iter = 135900 , loss =  0.00784264598042
training @ iter = 135900 , error =  0.0
training @ iter = 136000 , loss =  0.00233221589588
training @ iter = 136000 , error =  0.0
training @ iter = 136100 , loss =  0.00776692805812
training @ iter = 136100 , error =  0.0
training @ iter = 136200 , loss =  0.0476125180721
training @ iter = 136200 , error =  0.02
training @ iter = 136300 , loss =  0.143120244145
training @ iter = 136300 , error =  0.04
training @ iter = 136400 , loss =  0.00670422893018
training @ iter = 136400 , error =  0.0
training @ iter = 136500 , loss =  0.00407122541219
training @ iter = 136500 , error =  0.0
training @ iter = 136600 , loss =  0.00595424696803
training @ iter = 136600 , error =  0.0
training @ iter = 136700 , loss =  0.00961769837886
training @ iter = 136700 , error =  0.0
training @ iter = 136800 , loss =  0.146678298712
training @ iter = 136800 , error =  0.04
--> train minibatch error =  0.14  at iter  136810
-->  13 9800 chunk_23_50000.pkl
training @ iter = 136900 , loss =  0.005394177977
training @ iter = 136900 , error =  0.0
training @ iter = 137000 , loss =  0.00554203754291
training @ iter = 137000 , error =  0.0
training @ iter = 137100 , loss =  0.000536259205546
training @ iter = 137100 , error =  0.0
training @ iter = 137200 , loss =  0.010174524039
training @ iter = 137200 , error =  0.0
training @ iter = 137300 , loss =  0.0172465648502
training @ iter = 137300 , error =  0.02
training @ iter = 137400 , loss =  0.00435912469402
training @ iter = 137400 , error =  0.0
training @ iter = 137500 , loss =  0.000878198887222
training @ iter = 137500 , error =  0.0
training @ iter = 137600 , loss =  0.00692424038425
training @ iter = 137600 , error =  0.0
training @ iter = 137700 , loss =  0.0183170866221
training @ iter = 137700 , error =  0.0
training @ iter = 137800 , loss =  0.00288606993854
training @ iter = 137800 , error =  0.0
training @ iter = 137900 , loss =  0.0144305089489
training @ iter = 137900 , error =  0.0
training @ iter = 138000 , loss =  0.00417143106461
training @ iter = 138000 , error =  0.0
training @ iter = 138100 , loss =  0.00188237498514
training @ iter = 138100 , error =  0.0
training @ iter = 138200 , loss =  0.00112465338316
training @ iter = 138200 , error =  0.0
training @ iter = 138300 , loss =  0.00197006901726
training @ iter = 138300 , error =  0.0
--> train minibatch error =  0.12  at iter  138343
-->  14 36450 chunk_24_50000.pkl
training @ iter = 138400 , loss =  0.0535538718104
training @ iter = 138400 , error =  0.02
training @ iter = 138500 , loss =  0.000615196069703
training @ iter = 138500 , error =  0.0
training @ iter = 138600 , loss =  0.176682472229
training @ iter = 138600 , error =  0.04
training @ iter = 138700 , loss =  0.000992747372948
training @ iter = 138700 , error =  0.0
training @ iter = 138800 , loss =  0.0152865955606
training @ iter = 138800 , error =  0.02
training @ iter = 138900 , loss =  0.00187047664076
training @ iter = 138900 , error =  0.0
training @ iter = 139000 , loss =  0.0030449249316
training @ iter = 139000 , error =  0.0
training @ iter = 139100 , loss =  0.00110134354327
training @ iter = 139100 , error =  0.0
training @ iter = 139200 , loss =  0.00172988127451
training @ iter = 139200 , error =  0.0
training @ iter = 139300 , loss =  0.00349080422893
training @ iter = 139300 , error =  0.0
training @ iter = 139400 , loss =  0.00818519853055
training @ iter = 139400 , error =  0.0
training @ iter = 139500 , loss =  0.0575349703431
training @ iter = 139500 , error =  0.02
training @ iter = 139600 , loss =  0.0980723872781
training @ iter = 139600 , error =  0.02
training @ iter = 139700 , loss =  0.0018474352546
training @ iter = 139700 , error =  0.0
training @ iter = 139800 , loss =  0.00329217291437
training @ iter = 139800 , error =  0.0
training @ iter = 139900 , loss =  0.00270318891853
training @ iter = 139900 , error =  0.0
validation @ iter 140000
epoch 0, iter 140000, train buffer error 0.100000 %
epoch 0, iter 140000, validation loss 0.020488
epoch 0, iter 140000, validation error 0.623000 %
patience before checkBest 230000
patience after checkBest 230000
training @ iter = 140000 , loss =  0.000703121710103
training @ iter = 140000 , error =  0.0
training @ iter = 140100 , loss =  0.010762498714
training @ iter = 140100 , error =  0.0
training @ iter = 140200 , loss =  0.0421570986509
training @ iter = 140200 , error =  0.02
training @ iter = 140300 , loss =  0.0595619641244
training @ iter = 140300 , error =  0.02
training @ iter = 140400 , loss =  0.00295902602375
training @ iter = 140400 , error =  0.0
training @ iter = 140500 , loss =  0.000760859227739
training @ iter = 140500 , error =  0.0
training @ iter = 140600 , loss =  0.00427477946505
training @ iter = 140600 , error =  0.0
--> train minibatch error =  0.14  at iter  140602
-->  16 49400 chunk_26_50000.pkl
training @ iter = 140700 , loss =  0.0197074711323
training @ iter = 140700 , error =  0.0
training @ iter = 140800 , loss =  0.0592152066529
training @ iter = 140800 , error =  0.04
training @ iter = 140900 , loss =  0.048823967576
training @ iter = 140900 , error =  0.02
training @ iter = 141000 , loss =  0.00530682690442
training @ iter = 141000 , error =  0.0
training @ iter = 141100 , loss =  0.0110162105411
training @ iter = 141100 , error =  0.0
training @ iter = 141200 , loss =  0.00165392993949
training @ iter = 141200 , error =  0.0
training @ iter = 141300 , loss =  0.00142102537211
training @ iter = 141300 , error =  0.0
training @ iter = 141400 , loss =  0.00232690293342
training @ iter = 141400 , error =  0.0
training @ iter = 141500 , loss =  0.00785857718438
training @ iter = 141500 , error =  0.0
training @ iter = 141600 , loss =  0.004984438885
training @ iter = 141600 , error =  0.0
training @ iter = 141700 , loss =  0.053306337446
training @ iter = 141700 , error =  0.02
training @ iter = 141800 , loss =  0.024604126811
training @ iter = 141800 , error =  0.0
training @ iter = 141900 , loss =  0.00632566073909
training @ iter = 141900 , error =  0.0
training @ iter = 142000 , loss =  0.00104733591434
training @ iter = 142000 , error =  0.0
training @ iter = 142100 , loss =  0.00100890372414
training @ iter = 142100 , error =  0.0
training @ iter = 142200 , loss =  0.00209899269976
training @ iter = 142200 , error =  0.0
training @ iter = 142300 , loss =  0.00171741214581
training @ iter = 142300 , error =  0.0
ERROR:  /home/shared/Fields_12-2015/chunks_feat_50000/chunks_train/chunk_28_50000.pkl  has  4  candidates.
training @ iter = 142400 , loss =  0.00116340816021
training @ iter = 142400 , error =  0.0
training @ iter = 142500 , loss =  0.00555681809783
training @ iter = 142500 , error =  0.0
training @ iter = 142600 , loss =  0.0102098332718
training @ iter = 142600 , error =  0.0
training @ iter = 142700 , loss =  0.0149524183944
training @ iter = 142700 , error =  0.0
training @ iter = 142800 , loss =  0.178504139185
training @ iter = 142800 , error =  0.02
training @ iter = 142900 , loss =  0.106977082789
training @ iter = 142900 , error =  0.02
training @ iter = 143000 , loss =  0.00279016047716
training @ iter = 143000 , error =  0.0
training @ iter = 143100 , loss =  0.00369802652858
training @ iter = 143100 , error =  0.0
training @ iter = 143200 , loss =  0.00256039435044
training @ iter = 143200 , error =  0.0
training @ iter = 143300 , loss =  0.0503854751587
training @ iter = 143300 , error =  0.02
training @ iter = 143400 , loss =  0.0166913121939
training @ iter = 143400 , error =  0.0
--> train minibatch error =  0.28  at iter  143455
-->  20 5900 chunk_5_50000.pkl
--> train minibatch error =  0.14  at iter  143456
-->  20 5950 chunk_5_50000.pkl
training @ iter = 143500 , loss =  0.00824054144323
training @ iter = 143500 , error =  0.0
training @ iter = 143600 , loss =  0.0051350556314
training @ iter = 143600 , error =  0.0
training @ iter = 143700 , loss =  0.00185736920685
training @ iter = 143700 , error =  0.0
training @ iter = 143800 , loss =  0.00191447918769
training @ iter = 143800 , error =  0.0
training @ iter = 143900 , loss =  0.108200185001
training @ iter = 143900 , error =  0.02
training @ iter = 144000 , loss =  0.0526516102254
training @ iter = 144000 , error =  0.02
training @ iter = 144100 , loss =  0.049008499831
training @ iter = 144100 , error =  0.02
training @ iter = 144200 , loss =  0.0586154684424
training @ iter = 144200 , error =  0.02
training @ iter = 144300 , loss =  0.0543132722378
training @ iter = 144300 , error =  0.02
training @ iter = 144400 , loss =  0.00863183662295
training @ iter = 144400 , error =  0.0
training @ iter = 144500 , loss =  0.000760278082453
training @ iter = 144500 , error =  0.0
training @ iter = 144600 , loss =  0.00743656884879
training @ iter = 144600 , error =  0.0
training @ iter = 144700 , loss =  0.00318036950193
training @ iter = 144700 , error =  0.0
training @ iter = 144800 , loss =  0.00912128482014
training @ iter = 144800 , error =  0.0
training @ iter = 144900 , loss =  0.0300538353622
training @ iter = 144900 , error =  0.0
training @ iter = 145000 , loss =  0.1027918607
training @ iter = 145000 , error =  0.02
training @ iter = 145100 , loss =  0.00896681565791
training @ iter = 145100 , error =  0.0
training @ iter = 145200 , loss =  0.00463418103755
training @ iter = 145200 , error =  0.0
training @ iter = 145300 , loss =  0.00239853234962
training @ iter = 145300 , error =  0.0
training @ iter = 145400 , loss =  0.00220748758875
training @ iter = 145400 , error =  0.0
training @ iter = 145500 , loss =  0.00310046086088
training @ iter = 145500 , error =  0.0
training @ iter = 145600 , loss =  0.0141375456005
training @ iter = 145600 , error =  0.0
training @ iter = 145700 , loss =  0.000778782938141
training @ iter = 145700 , error =  0.0
training @ iter = 145800 , loss =  0.00146900920663
training @ iter = 145800 , error =  0.0
training @ iter = 145900 , loss =  0.00474634533748
training @ iter = 145900 , error =  0.0
--> train minibatch error =  0.12  at iter  145956
-->  22 30950 chunk_7_50000.pkl
training @ iter = 146000 , loss =  0.0270009692758
training @ iter = 146000 , error =  0.0
training @ iter = 146100 , loss =  0.0068314508535
training @ iter = 146100 , error =  0.0
training @ iter = 146200 , loss =  0.151812598109
training @ iter = 146200 , error =  0.04
training @ iter = 146300 , loss =  0.0023746646475
training @ iter = 146300 , error =  0.0
training @ iter = 146400 , loss =  0.0136972023174
training @ iter = 146400 , error =  0.02
training @ iter = 146500 , loss =  0.0427134670317
training @ iter = 146500 , error =  0.02
training @ iter = 146600 , loss =  0.015215232037
training @ iter = 146600 , error =  0.0
training @ iter = 146700 , loss =  0.00290863541886
training @ iter = 146700 , error =  0.0
--> train minibatch error =  0.12  at iter  146765
-->  23 21400 chunk_8_50000.pkl
training @ iter = 146800 , loss =  0.0356949456036
training @ iter = 146800 , error =  0.02
training @ iter = 146900 , loss =  0.00484382733703
training @ iter = 146900 , error =  0.0
--> train minibatch error =  0.14  at iter  146975
-->  23 31900 chunk_8_50000.pkl
training @ iter = 147000 , loss =  0.0951843932271
training @ iter = 147000 , error =  0.02
training @ iter = 147100 , loss =  0.0215641111135
training @ iter = 147100 , error =  0.02
training @ iter = 147200 , loss =  0.00531511893496
training @ iter = 147200 , error =  0.0
training @ iter = 147300 , loss =  0.00132765155286
training @ iter = 147300 , error =  0.0
training @ iter = 147400 , loss =  0.00761418649927
training @ iter = 147400 , error =  0.0
training @ iter = 147500 , loss =  0.00146246701479
training @ iter = 147500 , error =  0.0
training @ iter = 147600 , loss =  0.00165831740014
training @ iter = 147600 , error =  0.0
training @ iter = 147700 , loss =  0.00665355101228
training @ iter = 147700 , error =  0.0
training @ iter = 147800 , loss =  0.014361994341
training @ iter = 147800 , error =  0.0
training @ iter = 147900 , loss =  0.00440297601745
training @ iter = 147900 , error =  0.0
training @ iter = 148000 , loss =  0.00895352475345
training @ iter = 148000 , error =  0.0
--> train minibatch error =  0.22  at iter  148031
-->  24 34700 chunk_9_50000.pkl
--> train minibatch error =  0.16  at iter  148032
-->  24 34750 chunk_9_50000.pkl
--> train minibatch error =  0.14  at iter  148034
-->  24 34850 chunk_9_50000.pkl
training @ iter = 148100 , loss =  0.00705714337528
training @ iter = 148100 , error =  0.0
training @ iter = 148200 , loss =  0.0128747439012
training @ iter = 148200 , error =  0.02
training @ iter = 148300 , loss =  0.00117648986634
training @ iter = 148300 , error =  0.0
Epoch  6 , iteration  148338 training @ iter = 148400 , loss =  0.00285687576979
training @ iter = 148400 , error =  0.0
training @ iter = 148500 , loss =  0.00290209823288
training @ iter = 148500 , error =  0.0
training @ iter = 148600 , loss =  0.00140309985727
training @ iter = 148600 , error =  0.0
training @ iter = 148700 , loss =  0.000921366445255
training @ iter = 148700 , error =  0.0
training @ iter = 148800 , loss =  0.0344160087407
training @ iter = 148800 , error =  0.02
training @ iter = 148900 , loss =  0.0224025063217
training @ iter = 148900 , error =  0.02
--> train minibatch error =  0.14  at iter  148918
-->  0 29050 chunk_10_50000.pkl
training @ iter = 149000 , loss =  0.0077339517884
training @ iter = 149000 , error =  0.0
training @ iter = 149100 , loss =  0.00961985997856
training @ iter = 149100 , error =  0.0
training @ iter = 149200 , loss =  0.00672226212919
training @ iter = 149200 , error =  0.0
training @ iter = 149300 , loss =  0.0172498673201
training @ iter = 149300 , error =  0.02
training @ iter = 149400 , loss =  0.0232200976461
training @ iter = 149400 , error =  0.0
training @ iter = 149500 , loss =  0.00138731719926
training @ iter = 149500 , error =  0.0
training @ iter = 149600 , loss =  0.0048987925984
training @ iter = 149600 , error =  0.0
--> train minibatch error =  0.14  at iter  149660
-->  1 16150 chunk_11_50000.pkl
training @ iter = 149700 , loss =  0.0285326987505
training @ iter = 149700 , error =  0.02
training @ iter = 149800 , loss =  0.00507065607235
training @ iter = 149800 , error =  0.0
training @ iter = 149900 , loss =  0.000931527640205
training @ iter = 149900 , error =  0.0
Saving @ iter  150000
validation @ iter 150000
epoch 0, iter 150000, train buffer error 0.400000 %
epoch 0, iter 150000, validation loss 0.022029
epoch 0, iter 150000, validation error 0.672000 %
patience before checkBest 230000
patience after checkBest 230000
training @ iter = 150000 , loss =  0.00473965937272
training @ iter = 150000 , error =  0.0
training @ iter = 150100 , loss =  0.00863321591169
training @ iter = 150100 , error =  0.0
training @ iter = 150200 , loss =  0.00428506126627
training @ iter = 150200 , error =  0.0
training @ iter = 150300 , loss =  0.0170649401844
training @ iter = 150300 , error =  0.0
training @ iter = 150400 , loss =  0.00762929813936
training @ iter = 150400 , error =  0.0
--> train minibatch error =  0.12  at iter  150467
-->  2 6500 chunk_12_50000.pkl
training @ iter = 150500 , loss =  0.0981070995331
training @ iter = 150500 , error =  0.02
training @ iter = 150600 , loss =  0.00290193967521
training @ iter = 150600 , error =  0.0
training @ iter = 150700 , loss =  0.0262521151453
training @ iter = 150700 , error =  0.0
training @ iter = 150800 , loss =  0.0115315970033
training @ iter = 150800 , error =  0.0
training @ iter = 150900 , loss =  0.0068793320097
training @ iter = 150900 , error =  0.0
training @ iter = 151000 , loss =  0.00141871825326
training @ iter = 151000 , error =  0.0
training @ iter = 151100 , loss =  0.00748335616663
training @ iter = 151100 , error =  0.0
training @ iter = 151200 , loss =  0.00127349281684
training @ iter = 151200 , error =  0.0
training @ iter = 151300 , loss =  0.00510980188847
training @ iter = 151300 , error =  0.0
training @ iter = 151400 , loss =  0.0765655711293
training @ iter = 151400 , error =  0.02
training @ iter = 151500 , loss =  0.00498875277117
training @ iter = 151500 , error =  0.0
training @ iter = 151600 , loss =  0.00510381301865
training @ iter = 151600 , error =  0.0
training @ iter = 151700 , loss =  0.00213581835851
training @ iter = 151700 , error =  0.0
training @ iter = 151800 , loss =  0.0247159413993
training @ iter = 151800 , error =  0.0
training @ iter = 151900 , loss =  0.0164750926197
training @ iter = 151900 , error =  0.0
--> train minibatch error =  0.12  at iter  151979
-->  3 32100 chunk_13_50000.pkl
training @ iter = 152000 , loss =  0.00291846925393
training @ iter = 152000 , error =  0.0
training @ iter = 152100 , loss =  0.0029648730997
training @ iter = 152100 , error =  0.0
training @ iter = 152200 , loss =  0.00146842328832
training @ iter = 152200 , error =  0.0
training @ iter = 152300 , loss =  0.00133345427457
training @ iter = 152300 , error =  0.0
training @ iter = 152400 , loss =  0.011250173673
training @ iter = 152400 , error =  0.0
training @ iter = 152500 , loss =  0.0045120716095
training @ iter = 152500 , error =  0.0
training @ iter = 152600 , loss =  0.0152066489682
training @ iter = 152600 , error =  0.0
training @ iter = 152700 , loss =  0.0031509550754
training @ iter = 152700 , error =  0.0
training @ iter = 152800 , loss =  0.0422176159918
training @ iter = 152800 , error =  0.02
training @ iter = 152900 , loss =  0.00947788543999
training @ iter = 152900 , error =  0.0
training @ iter = 153000 , loss =  0.00547010544688
training @ iter = 153000 , error =  0.0
training @ iter = 153100 , loss =  0.00530879991129
training @ iter = 153100 , error =  0.0
training @ iter = 153200 , loss =  0.00385175622068
training @ iter = 153200 , error =  0.0
training @ iter = 153300 , loss =  0.00233499077149
training @ iter = 153300 , error =  0.0
training @ iter = 153400 , loss =  0.00173969578464
training @ iter = 153400 , error =  0.0
training @ iter = 153500 , loss =  0.00921497680247
training @ iter = 153500 , error =  0.0
training @ iter = 153600 , loss =  0.0156711563468
training @ iter = 153600 , error =  0.0
training @ iter = 153700 , loss =  0.0047684693709
training @ iter = 153700 , error =  0.0
training @ iter = 153800 , loss =  0.00166729418561
training @ iter = 153800 , error =  0.0
training @ iter = 153900 , loss =  0.0026028517168
training @ iter = 153900 , error =  0.0
training @ iter = 154000 , loss =  0.0185892116278
training @ iter = 154000 , error =  0.0
training @ iter = 154100 , loss =  0.0879450589418
training @ iter = 154100 , error =  0.04
training @ iter = 154200 , loss =  0.0101375440136
training @ iter = 154200 , error =  0.0
training @ iter = 154300 , loss =  0.00118614733219
training @ iter = 154300 , error =  0.0
training @ iter = 154400 , loss =  0.00146068667527
training @ iter = 154400 , error =  0.0
training @ iter = 154500 , loss =  0.00138005206827
training @ iter = 154500 , error =  0.0
training @ iter = 154600 , loss =  0.00263807689771
training @ iter = 154600 , error =  0.0
training @ iter = 154700 , loss =  0.000840355292894
training @ iter = 154700 , error =  0.0
training @ iter = 154800 , loss =  0.0033663099166
training @ iter = 154800 , error =  0.0
training @ iter = 154900 , loss =  0.00123698229436
training @ iter = 154900 , error =  0.0
training @ iter = 155000 , loss =  0.0221317559481
training @ iter = 155000 , error =  0.0
training @ iter = 155100 , loss =  0.00461332686245
training @ iter = 155100 , error =  0.0
training @ iter = 155200 , loss =  0.0739894509315
training @ iter = 155200 , error =  0.02
training @ iter = 155300 , loss =  0.00107022596058
training @ iter = 155300 , error =  0.0
training @ iter = 155400 , loss =  0.00779189355671
training @ iter = 155400 , error =  0.0
training @ iter = 155500 , loss =  0.0101421521977
training @ iter = 155500 , error =  0.0
training @ iter = 155600 , loss =  0.0857716351748
training @ iter = 155600 , error =  0.02
training @ iter = 155700 , loss =  0.0632061362267
training @ iter = 155700 , error =  0.02
training @ iter = 155800 , loss =  0.00538593297824
training @ iter = 155800 , error =  0.0
training @ iter = 155900 , loss =  0.0278189331293
training @ iter = 155900 , error =  0.0
training @ iter = 156000 , loss =  0.0189847070724
training @ iter = 156000 , error =  0.0
--> train minibatch error =  0.18  at iter  156004
-->  7 33350 chunk_17_50000.pkl
training @ iter = 156100 , loss =  0.224450573325
training @ iter = 156100 , error =  0.06
training @ iter = 156200 , loss =  0.00216652918607
training @ iter = 156200 , error =  0.0
training @ iter = 156300 , loss =  0.0028270483017
training @ iter = 156300 , error =  0.0
training @ iter = 156400 , loss =  0.00487851630896
training @ iter = 156400 , error =  0.0
--> train minibatch error =  0.12  at iter  156432
-->  8 4750 chunk_18_50000.pkl
training @ iter = 156500 , loss =  0.00888180173934
training @ iter = 156500 , error =  0.0
training @ iter = 156600 , loss =  0.0115317292511
training @ iter = 156600 , error =  0.0
training @ iter = 156700 , loss =  0.107042811811
training @ iter = 156700 , error =  0.02
training @ iter = 156800 , loss =  0.0563092753291
training @ iter = 156800 , error =  0.04
training @ iter = 156900 , loss =  0.00246769213118
training @ iter = 156900 , error =  0.0
--> train minibatch error =  0.12  at iter  156943
-->  8 30300 chunk_18_50000.pkl
--> train minibatch error =  0.22  at iter  156944
-->  8 30350 chunk_18_50000.pkl
training @ iter = 157000 , loss =  0.0141069153324
training @ iter = 157000 , error =  0.0
--> train minibatch error =  0.16  at iter  157009
-->  8 33600 chunk_18_50000.pkl
training @ iter = 157100 , loss =  0.00053928908892
training @ iter = 157100 , error =  0.0
training @ iter = 157200 , loss =  0.00571484817192
training @ iter = 157200 , error =  0.0
training @ iter = 157300 , loss =  0.0040923669003
training @ iter = 157300 , error =  0.0
training @ iter = 157400 , loss =  0.0934325382113
training @ iter = 157400 , error =  0.02
training @ iter = 157500 , loss =  0.00345187191851
training @ iter = 157500 , error =  0.0
training @ iter = 157600 , loss =  0.00250436994247
training @ iter = 157600 , error =  0.0
training @ iter = 157700 , loss =  0.00110245379619
training @ iter = 157700 , error =  0.0
training @ iter = 157800 , loss =  0.0146476086229
training @ iter = 157800 , error =  0.0
training @ iter = 157900 , loss =  0.0437751039863
training @ iter = 157900 , error =  0.02
training @ iter = 158000 , loss =  0.00710555072874
training @ iter = 158000 , error =  0.0
training @ iter = 158100 , loss =  0.0103982081637
training @ iter = 158100 , error =  0.02
training @ iter = 158200 , loss =  0.000657478056382
training @ iter = 158200 , error =  0.0
training @ iter = 158300 , loss =  0.0670812278986
training @ iter = 158300 , error =  0.02
training @ iter = 158400 , loss =  0.0102130584419
training @ iter = 158400 , error =  0.0
training @ iter = 158500 , loss =  0.0144401080906
training @ iter = 158500 , error =  0.02
--> train minibatch error =  0.18  at iter  158519
-->  10 9100 chunk_20_50000.pkl
training @ iter = 158600 , loss =  0.00428499514237
training @ iter = 158600 , error =  0.0
--> train minibatch error =  0.12  at iter  158671
-->  10 16700 chunk_20_50000.pkl
training @ iter = 158700 , loss =  0.0855229347944
training @ iter = 158700 , error =  0.02
training @ iter = 158800 , loss =  0.00301610259339
training @ iter = 158800 , error =  0.0
training @ iter = 158900 , loss =  0.01608431153
training @ iter = 158900 , error =  0.02
training @ iter = 159000 , loss =  0.0145551292226
training @ iter = 159000 , error =  0.0
training @ iter = 159100 , loss =  0.0402744039893
training @ iter = 159100 , error =  0.02
training @ iter = 159200 , loss =  0.0808597505093
training @ iter = 159200 , error =  0.02
training @ iter = 159300 , loss =  0.0699295178056
training @ iter = 159300 , error =  0.02
training @ iter = 159400 , loss =  0.0902531519532
training @ iter = 159400 , error =  0.02
training @ iter = 159500 , loss =  0.0121803507209
training @ iter = 159500 , error =  0.0
training @ iter = 159600 , loss =  0.00166376365814
training @ iter = 159600 , error =  0.0
training @ iter = 159700 , loss =  0.00213703536429
training @ iter = 159700 , error =  0.0
training @ iter = 159800 , loss =  0.00496577145532
training @ iter = 159800 , error =  0.0
training @ iter = 159900 , loss =  0.00513815879822
training @ iter = 159900 , error =  0.0
validation @ iter 160000
epoch 0, iter 160000, train buffer error 0.400000 %
epoch 0, iter 160000, validation loss 0.020654
epoch 0, iter 160000, validation error 0.641000 %
patience before checkBest 230000
patience after checkBest 230000
training @ iter = 160000 , loss =  0.00165718700737
training @ iter = 160000 , error =  0.0
training @ iter = 160100 , loss =  0.00920061208308
training @ iter = 160100 , error =  0.0
training @ iter = 160200 , loss =  0.00887270923704
training @ iter = 160200 , error =  0.0
training @ iter = 160300 , loss =  0.00265930662863
training @ iter = 160300 , error =  0.0
training @ iter = 160400 , loss =  0.0132253132761
training @ iter = 160400 , error =  0.0
training @ iter = 160500 , loss =  0.0178425423801
training @ iter = 160500 , error =  0.0
training @ iter = 160600 , loss =  0.00469572935253
training @ iter = 160600 , error =  0.0
training @ iter = 160700 , loss =  0.00622196542099
training @ iter = 160700 , error =  0.0
training @ iter = 160800 , loss =  0.00181370286737
training @ iter = 160800 , error =  0.0
training @ iter = 160900 , loss =  0.00084883364616
training @ iter = 160900 , error =  0.0
training @ iter = 161000 , loss =  0.0025234054774
training @ iter = 161000 , error =  0.0
training @ iter = 161100 , loss =  0.0646764785051
training @ iter = 161100 , error =  0.02
training @ iter = 161200 , loss =  0.0075714061968
training @ iter = 161200 , error =  0.0
training @ iter = 161300 , loss =  0.00295868748799
training @ iter = 161300 , error =  0.0
training @ iter = 161400 , loss =  0.00537061458454
training @ iter = 161400 , error =  0.0
training @ iter = 161500 , loss =  0.00273874332197
training @ iter = 161500 , error =  0.0
--> train minibatch error =  0.14  at iter  161533
-->  13 9800 chunk_23_50000.pkl
training @ iter = 161600 , loss =  0.00248518865556
training @ iter = 161600 , error =  0.0
training @ iter = 161700 , loss =  0.00327059719712
training @ iter = 161700 , error =  0.0
training @ iter = 161800 , loss =  0.00136835838202
training @ iter = 161800 , error =  0.0
training @ iter = 161900 , loss =  0.000780039583333
training @ iter = 161900 , error =  0.0
training @ iter = 162000 , loss =  0.012154086493
training @ iter = 162000 , error =  0.0
training @ iter = 162100 , loss =  0.00452515482903
training @ iter = 162100 , error =  0.0
training @ iter = 162200 , loss =  0.00875183660537
training @ iter = 162200 , error =  0.0
training @ iter = 162300 , loss =  0.00646557100117
training @ iter = 162300 , error =  0.0
training @ iter = 162400 , loss =  0.00174122152384
training @ iter = 162400 , error =  0.0
training @ iter = 162500 , loss =  0.00191063131206
training @ iter = 162500 , error =  0.0
training @ iter = 162600 , loss =  0.00522188143805
training @ iter = 162600 , error =  0.0
training @ iter = 162700 , loss =  0.00175036012661
training @ iter = 162700 , error =  0.0
training @ iter = 162800 , loss =  0.00168709771242
training @ iter = 162800 , error =  0.0
training @ iter = 162900 , loss =  0.00806662719697
training @ iter = 162900 , error =  0.0
training @ iter = 163000 , loss =  0.00140382885002
training @ iter = 163000 , error =  0.0
training @ iter = 163100 , loss =  0.00843197945505
training @ iter = 163100 , error =  0.0
training @ iter = 163200 , loss =  0.00809152424335
training @ iter = 163200 , error =  0.02
training @ iter = 163300 , loss =  0.00852920208126
training @ iter = 163300 , error =  0.0
training @ iter = 163400 , loss =  0.0238710660487
training @ iter = 163400 , error =  0.0
training @ iter = 163500 , loss =  0.00241409335285
training @ iter = 163500 , error =  0.0
training @ iter = 163600 , loss =  0.00174833764322
training @ iter = 163600 , error =  0.0
training @ iter = 163700 , loss =  0.0010166647844
training @ iter = 163700 , error =  0.0
training @ iter = 163800 , loss =  0.0119900014251
training @ iter = 163800 , error =  0.0
training @ iter = 163900 , loss =  0.127092272043
training @ iter = 163900 , error =  0.02
training @ iter = 164000 , loss =  0.0220390055329
training @ iter = 164000 , error =  0.02
training @ iter = 164100 , loss =  0.00614747544751
training @ iter = 164100 , error =  0.0
training @ iter = 164200 , loss =  0.000781456823461
training @ iter = 164200 , error =  0.0
training @ iter = 164300 , loss =  0.00127430621069
training @ iter = 164300 , error =  0.0
training @ iter = 164400 , loss =  0.0736011788249
training @ iter = 164400 , error =  0.02
training @ iter = 164500 , loss =  0.00530945183709
training @ iter = 164500 , error =  0.0
training @ iter = 164600 , loss =  0.00101790914778
training @ iter = 164600 , error =  0.0
training @ iter = 164700 , loss =  0.0155681334436
training @ iter = 164700 , error =  0.0
training @ iter = 164800 , loss =  0.0164723265916
training @ iter = 164800 , error =  0.0
training @ iter = 164900 , loss =  0.0254153702408
training @ iter = 164900 , error =  0.0
training @ iter = 165000 , loss =  0.00065906974487
training @ iter = 165000 , error =  0.0
training @ iter = 165100 , loss =  0.00143019552343
training @ iter = 165100 , error =  0.0
training @ iter = 165200 , loss =  0.000708192586899
training @ iter = 165200 , error =  0.0
training @ iter = 165300 , loss =  0.00159371132031
training @ iter = 165300 , error =  0.0
--> train minibatch error =  0.14  at iter  165325
-->  16 49400 chunk_26_50000.pkl
training @ iter = 165400 , loss =  0.00423483923078
training @ iter = 165400 , error =  0.0
training @ iter = 165500 , loss =  0.0123051153496
training @ iter = 165500 , error =  0.0
training @ iter = 165600 , loss =  0.0037991211284
training @ iter = 165600 , error =  0.0
training @ iter = 165700 , loss =  0.0035117524676
training @ iter = 165700 , error =  0.0
training @ iter = 165800 , loss =  0.00338425510563
training @ iter = 165800 , error =  0.0
training @ iter = 165900 , loss =  0.00302013824694
training @ iter = 165900 , error =  0.0
training @ iter = 166000 , loss =  0.00224740151316
training @ iter = 166000 , error =  0.0
training @ iter = 166100 , loss =  0.136273682117
training @ iter = 166100 , error =  0.02
training @ iter = 166200 , loss =  0.00252874637954
training @ iter = 166200 , error =  0.0
training @ iter = 166300 , loss =  0.00626429449767
training @ iter = 166300 , error =  0.0
training @ iter = 166400 , loss =  0.0293060094118
training @ iter = 166400 , error =  0.02
training @ iter = 166500 , loss =  0.00496454723179
training @ iter = 166500 , error =  0.0
training @ iter = 166600 , loss =  0.00643573421985
training @ iter = 166600 , error =  0.0
training @ iter = 166700 , loss =  0.00862487684935
training @ iter = 166700 , error =  0.0
training @ iter = 166800 , loss =  0.122862569988
training @ iter = 166800 , error =  0.04
training @ iter = 166900 , loss =  0.00193902035244
training @ iter = 166900 , error =  0.0
training @ iter = 167000 , loss =  0.0110167860985
training @ iter = 167000 , error =  0.0
ERROR:  /home/shared/Fields_12-2015/chunks_feat_50000/chunks_train/chunk_28_50000.pkl  has  4  candidates.
training @ iter = 167100 , loss =  0.00426758825779
training @ iter = 167100 , error =  0.0
training @ iter = 167200 , loss =  0.012701895088
training @ iter = 167200 , error =  0.0
training @ iter = 167300 , loss =  0.000676698982716
training @ iter = 167300 , error =  0.0
training @ iter = 167400 , loss =  0.00181907298975
training @ iter = 167400 , error =  0.0
training @ iter = 167500 , loss =  0.045269086957
training @ iter = 167500 , error =  0.02
training @ iter = 167600 , loss =  0.00223655137233
training @ iter = 167600 , error =  0.0
training @ iter = 167700 , loss =  0.00893030129373
training @ iter = 167700 , error =  0.0
training @ iter = 167800 , loss =  0.0631040260196
training @ iter = 167800 , error =  0.02
training @ iter = 167900 , loss =  0.00325928698294
training @ iter = 167900 , error =  0.0
training @ iter = 168000 , loss =  0.00101605639793
training @ iter = 168000 , error =  0.0
training @ iter = 168100 , loss =  0.000627939822152
training @ iter = 168100 , error =  0.0
--> train minibatch error =  0.28  at iter  168178
-->  20 5900 chunk_5_50000.pkl
--> train minibatch error =  0.14  at iter  168179
-->  20 5950 chunk_5_50000.pkl
training @ iter = 168200 , loss =  0.0543958954513
training @ iter = 168200 , error =  0.02
training @ iter = 168300 , loss =  0.0188667457551
training @ iter = 168300 , error =  0.0
training @ iter = 168400 , loss =  0.0455797463655
training @ iter = 168400 , error =  0.02
training @ iter = 168500 , loss =  0.00250237761065
training @ iter = 168500 , error =  0.0
training @ iter = 168600 , loss =  0.00161442940589
training @ iter = 168600 , error =  0.0
training @ iter = 168700 , loss =  0.0295035261661
training @ iter = 168700 , error =  0.02
training @ iter = 168800 , loss =  0.00152153579984
training @ iter = 168800 , error =  0.0
training @ iter = 168900 , loss =  0.000971641391516
training @ iter = 168900 , error =  0.0
training @ iter = 169000 , loss =  0.00776027701795
training @ iter = 169000 , error =  0.0
training @ iter = 169100 , loss =  0.176674693823
training @ iter = 169100 , error =  0.02
training @ iter = 169200 , loss =  0.212949678302
training @ iter = 169200 , error =  0.04
training @ iter = 169300 , loss =  0.0516857281327
training @ iter = 169300 , error =  0.02
training @ iter = 169400 , loss =  0.021567363292
training @ iter = 169400 , error =  0.0
training @ iter = 169500 , loss =  0.00628583785146
training @ iter = 169500 , error =  0.0
training @ iter = 169600 , loss =  0.0016692718491
training @ iter = 169600 , error =  0.0
training @ iter = 169700 , loss =  0.00244856718928
training @ iter = 169700 , error =  0.0
training @ iter = 169800 , loss =  0.00169944565278
training @ iter = 169800 , error =  0.0
training @ iter = 169900 , loss =  0.00187619240023
training @ iter = 169900 , error =  0.0
validation @ iter 170000
epoch 0, iter 170000, train buffer error 0.400000 %
epoch 0, iter 170000, validation loss 0.020603
epoch 0, iter 170000, validation error 0.628000 %
patience before checkBest 230000
patience after checkBest 230000
training @ iter = 170000 , loss =  0.00260979216546
training @ iter = 170000 , error =  0.0
training @ iter = 170100 , loss =  0.0118224676698
training @ iter = 170100 , error =  0.0
training @ iter = 170200 , loss =  0.118752717972
training @ iter = 170200 , error =  0.02
training @ iter = 170300 , loss =  0.0022980934009
training @ iter = 170300 , error =  0.0
training @ iter = 170400 , loss =  0.00674020638689
training @ iter = 170400 , error =  0.0
training @ iter = 170500 , loss =  0.0212123971432
training @ iter = 170500 , error =  0.0
training @ iter = 170600 , loss =  0.00357710011303
training @ iter = 170600 , error =  0.0
--> train minibatch error =  0.12  at iter  170679
-->  22 30950 chunk_7_50000.pkl
training @ iter = 170700 , loss =  0.00336809805594
training @ iter = 170700 , error =  0.0
training @ iter = 170800 , loss =  0.00237172609195
training @ iter = 170800 , error =  0.0
training @ iter = 170900 , loss =  0.0134716955945
training @ iter = 170900 , error =  0.0
training @ iter = 171000 , loss =  0.0119549678639
training @ iter = 171000 , error =  0.02
training @ iter = 171100 , loss =  0.00440882425755
training @ iter = 171100 , error =  0.0
training @ iter = 171200 , loss =  0.00245379982516
training @ iter = 171200 , error =  0.0
training @ iter = 171300 , loss =  0.00282295863144
training @ iter = 171300 , error =  0.0
training @ iter = 171400 , loss =  0.00634143967181
training @ iter = 171400 , error =  0.0
training @ iter = 171500 , loss =  0.00140218704473
training @ iter = 171500 , error =  0.0
training @ iter = 171600 , loss =  0.0145526519045
training @ iter = 171600 , error =  0.0
training @ iter = 171700 , loss =  0.0154249714687
training @ iter = 171700 , error =  0.06
training @ iter = 171800 , loss =  0.00116863742005
training @ iter = 171800 , error =  0.0
training @ iter = 171900 , loss =  0.0524199195206
training @ iter = 171900 , error =  0.02
training @ iter = 172000 , loss =  0.0122911930084
training @ iter = 172000 , error =  0.0
training @ iter = 172100 , loss =  0.00490023987368
training @ iter = 172100 , error =  0.0
training @ iter = 172200 , loss =  0.00548316724598
training @ iter = 172200 , error =  0.0
training @ iter = 172300 , loss =  0.000921273371205
training @ iter = 172300 , error =  0.0
training @ iter = 172400 , loss =  0.0602189265192
training @ iter = 172400 , error =  0.02
training @ iter = 172500 , loss =  0.0340487807989
training @ iter = 172500 , error =  0.02
training @ iter = 172600 , loss =  0.0119943311438
training @ iter = 172600 , error =  0.0
training @ iter = 172700 , loss =  0.101811558008
training @ iter = 172700 , error =  0.06
--> train minibatch error =  0.22  at iter  172754
-->  24 34700 chunk_9_50000.pkl
--> train minibatch error =  0.18  at iter  172755
-->  24 34750 chunk_9_50000.pkl
--> train minibatch error =  0.18  at iter  172757
-->  24 34850 chunk_9_50000.pkl
training @ iter = 172800 , loss =  0.012109563686
training @ iter = 172800 , error =  0.0
training @ iter = 172900 , loss =  0.000837398751173
training @ iter = 172900 , error =  0.0
training @ iter = 173000 , loss =  0.0335513912141
training @ iter = 173000 , error =  0.02
Epoch  7 , iteration  173061 training @ iter = 173100 , loss =  0.159076973796
training @ iter = 173100 , error =  0.04
training @ iter = 173200 , loss =  0.00161995203234
training @ iter = 173200 , error =  0.0
training @ iter = 173300 , loss =  0.00656166812405
training @ iter = 173300 , error =  0.0
training @ iter = 173400 , loss =  0.0220542103052
training @ iter = 173400 , error =  0.02
training @ iter = 173500 , loss =  0.0626739859581
training @ iter = 173500 , error =  0.02
training @ iter = 173600 , loss =  0.00209703762084
training @ iter = 173600 , error =  0.0
training @ iter = 173700 , loss =  0.108985394239
training @ iter = 173700 , error =  0.04
training @ iter = 173800 , loss =  0.00217852834612
training @ iter = 173800 , error =  0.0
training @ iter = 173900 , loss =  0.0197047442198
training @ iter = 173900 , error =  0.0
training @ iter = 174000 , loss =  0.106723614037
training @ iter = 174000 , error =  0.04
training @ iter = 174100 , loss =  0.000846487411764
training @ iter = 174100 , error =  0.0
training @ iter = 174200 , loss =  0.00255819479935
training @ iter = 174200 , error =  0.0
training @ iter = 174300 , loss =  0.0354168303311
training @ iter = 174300 , error =  0.0
--> train minibatch error =  0.12  at iter  174383
-->  1 16150 chunk_11_50000.pkl
--> train minibatch error =  0.12  at iter  174386
-->  1 16300 chunk_11_50000.pkl
training @ iter = 174400 , loss =  0.16930423677
training @ iter = 174400 , error =  0.04
training @ iter = 174500 , loss =  0.106876038015
training @ iter = 174500 , error =  0.02
training @ iter = 174600 , loss =  0.159014999866
training @ iter = 174600 , error =  0.04
training @ iter = 174700 , loss =  0.000775875465479
training @ iter = 174700 , error =  0.0
training @ iter = 174800 , loss =  0.00103968009353
training @ iter = 174800 , error =  0.0
training @ iter = 174900 , loss =  0.00520644010976
training @ iter = 174900 , error =  0.0
Saving @ iter  175000
training @ iter = 175000 , loss =  0.00472081126645
training @ iter = 175000 , error =  0.0
training @ iter = 175100 , loss =  0.000916645105463
training @ iter = 175100 , error =  0.0
training @ iter = 175200 , loss =  0.00557202566415
training @ iter = 175200 , error =  0.0
training @ iter = 175300 , loss =  0.000643085979391
training @ iter = 175300 , error =  0.0
training @ iter = 175400 , loss =  0.00520786270499
training @ iter = 175400 , error =  0.0
training @ iter = 175500 , loss =  0.00160294142552
training @ iter = 175500 , error =  0.0
training @ iter = 175600 , loss =  0.0924525558949
training @ iter = 175600 , error =  0.02
training @ iter = 175700 , loss =  0.00652283290401
training @ iter = 175700 , error =  0.0
training @ iter = 175800 , loss =  0.125583708286
training @ iter = 175800 , error =  0.02
training @ iter = 175900 , loss =  0.00278993137181
training @ iter = 175900 , error =  0.0
training @ iter = 176000 , loss =  0.00207404908724
training @ iter = 176000 , error =  0.0
training @ iter = 176100 , loss =  0.000713372370228
training @ iter = 176100 , error =  0.0
training @ iter = 176200 , loss =  0.0231705587357
training @ iter = 176200 , error =  0.02
training @ iter = 176300 , loss =  0.0305052623153
training @ iter = 176300 , error =  0.02
training @ iter = 176400 , loss =  0.124023169279
training @ iter = 176400 , error =  0.06
training @ iter = 176500 , loss =  0.00157192617189
training @ iter = 176500 , error =  0.0
training @ iter = 176600 , loss =  0.00397952180356
training @ iter = 176600 , error =  0.0
training @ iter = 176700 , loss =  0.00727413641289
training @ iter = 176700 , error =  0.0
--> train minibatch error =  0.14  at iter  176702
-->  3 32100 chunk_13_50000.pkl
training @ iter = 176800 , loss =  0.00214755139314
training @ iter = 176800 , error =  0.0
training @ iter = 176900 , loss =  0.00305192242377
training @ iter = 176900 , error =  0.0
training @ iter = 177000 , loss =  0.0260839946568
training @ iter = 177000 , error =  0.0
training @ iter = 177100 , loss =  0.00314514362253
training @ iter = 177100 , error =  0.0
training @ iter = 177200 , loss =  0.00931780785322
training @ iter = 177200 , error =  0.0
training @ iter = 177300 , loss =  0.00581107893959
training @ iter = 177300 , error =  0.0
training @ iter = 177400 , loss =  0.00198822794482
training @ iter = 177400 , error =  0.0
training @ iter = 177500 , loss =  0.0181739199907
training @ iter = 177500 , error =  0.02
training @ iter = 177600 , loss =  0.00260474416427
training @ iter = 177600 , error =  0.0
training @ iter = 177700 , loss =  0.125097081065
training @ iter = 177700 , error =  0.02
training @ iter = 177800 , loss =  0.0016656256048
training @ iter = 177800 , error =  0.0
training @ iter = 177900 , loss =  0.00172366038896
training @ iter = 177900 , error =  0.0
training @ iter = 178000 , loss =  0.0336554050446
training @ iter = 178000 , error =  0.0
training @ iter = 178100 , loss =  0.00610489863902
training @ iter = 178100 , error =  0.0
training @ iter = 178200 , loss =  0.0027196558658
training @ iter = 178200 , error =  0.0
training @ iter = 178300 , loss =  0.00592332519591
training @ iter = 178300 , error =  0.0
training @ iter = 178400 , loss =  0.00217178999446
training @ iter = 178400 , error =  0.0
training @ iter = 178500 , loss =  0.00102494750172
training @ iter = 178500 , error =  0.0
training @ iter = 178600 , loss =  0.00179787899833
training @ iter = 178600 , error =  0.0
training @ iter = 178700 , loss =  0.000571726181079
training @ iter = 178700 , error =  0.0
training @ iter = 178800 , loss =  0.0234363693744
training @ iter = 178800 , error =  0.0
training @ iter = 178900 , loss =  0.00360564957373
training @ iter = 178900 , error =  0.0
training @ iter = 179000 , loss =  0.00271203229204
training @ iter = 179000 , error =  0.0
training @ iter = 179100 , loss =  0.000620476377662
training @ iter = 179100 , error =  0.0
training @ iter = 179200 , loss =  0.0181033499539
training @ iter = 179200 , error =  0.02
training @ iter = 179300 , loss =  0.0101726539433
training @ iter = 179300 , error =  0.0
training @ iter = 179400 , loss =  0.0337684638798
training @ iter = 179400 , error =  0.02
training @ iter = 179500 , loss =  0.00693207839504
training @ iter = 179500 , error =  0.0
training @ iter = 179600 , loss =  0.00194265728351
training @ iter = 179600 , error =  0.0
training @ iter = 179700 , loss =  0.100016534328
training @ iter = 179700 , error =  0.04
training @ iter = 179800 , loss =  0.0147086950019
training @ iter = 179800 , error =  0.02
training @ iter = 179900 , loss =  0.00495937094092
training @ iter = 179900 , error =  0.0
validation @ iter 180000
epoch 0, iter 180000, train buffer error 0.600000 %
epoch 0, iter 180000, validation loss 0.020059
epoch 0, iter 180000, validation error 0.605000 %
patience before checkBest 230000
patience after checkBest 230000
training @ iter = 180000 , loss =  0.00223896326497
training @ iter = 180000 , error =  0.0
training @ iter = 180100 , loss =  0.06488635391
training @ iter = 180100 , error =  0.02
training @ iter = 180200 , loss =  0.00870425719768
training @ iter = 180200 , error =  0.0
training @ iter = 180300 , loss =  0.00568817136809
training @ iter = 180300 , error =  0.0
training @ iter = 180400 , loss =  0.0400661788881
training @ iter = 180400 , error =  0.02
training @ iter = 180500 , loss =  0.0055646491237
training @ iter = 180500 , error =  0.0
training @ iter = 180600 , loss =  0.00178765913006
training @ iter = 180600 , error =  0.0
training @ iter = 180700 , loss =  0.00987151544541
training @ iter = 180700 , error =  0.0
--> train minibatch error =  0.18  at iter  180727
-->  7 33350 chunk_17_50000.pkl
training @ iter = 180800 , loss =  0.00165790854953
training @ iter = 180800 , error =  0.0
training @ iter = 180900 , loss =  0.00906818546355
training @ iter = 180900 , error =  0.0
training @ iter = 181000 , loss =  0.0307332128286
training @ iter = 181000 , error =  0.02
training @ iter = 181100 , loss =  0.00404459051788
training @ iter = 181100 , error =  0.0
training @ iter = 181200 , loss =  0.0520003847778
training @ iter = 181200 , error =  0.04
training @ iter = 181300 , loss =  0.0402496531606
training @ iter = 181300 , error =  0.02
training @ iter = 181400 , loss =  0.00686694309115
training @ iter = 181400 , error =  0.0
training @ iter = 181500 , loss =  0.000999484327622
training @ iter = 181500 , error =  0.0
training @ iter = 181600 , loss =  0.0435746014118
training @ iter = 181600 , error =  0.02
--> train minibatch error =  0.12  at iter  181666
-->  8 30300 chunk_18_50000.pkl
--> train minibatch error =  0.16  at iter  181667
-->  8 30350 chunk_18_50000.pkl
--> train minibatch error =  0.16  at iter  181668
-->  8 30400 chunk_18_50000.pkl
training @ iter = 181700 , loss =  0.00260835676454
training @ iter = 181700 , error =  0.0
--> train minibatch error =  0.16  at iter  181732
-->  8 33600 chunk_18_50000.pkl
training @ iter = 181800 , loss =  0.00342531781644
training @ iter = 181800 , error =  0.0
training @ iter = 181900 , loss =  0.00465075019747
training @ iter = 181900 , error =  0.0
training @ iter = 182000 , loss =  0.001035887748
training @ iter = 182000 , error =  0.0
training @ iter = 182100 , loss =  0.0317125171423
training @ iter = 182100 , error =  0.02
training @ iter = 182200 , loss =  0.0282853916287
training @ iter = 182200 , error =  0.02
training @ iter = 182300 , loss =  0.0221132747829
training @ iter = 182300 , error =  0.0
training @ iter = 182400 , loss =  0.0416464433074
training @ iter = 182400 , error =  0.0
training @ iter = 182500 , loss =  0.00380451441742
training @ iter = 182500 , error =  0.0
training @ iter = 182600 , loss =  0.0370581261814
training @ iter = 182600 , error =  0.02
training @ iter = 182700 , loss =  0.00388198252767
training @ iter = 182700 , error =  0.0
training @ iter = 182800 , loss =  0.00207293988205
training @ iter = 182800 , error =  0.0
training @ iter = 182900 , loss =  0.00159085798077
training @ iter = 182900 , error =  0.0
training @ iter = 183000 , loss =  0.0367729514837
training @ iter = 183000 , error =  0.06
training @ iter = 183100 , loss =  0.00648807408288
training @ iter = 183100 , error =  0.0
training @ iter = 183200 , loss =  0.0421211197972
training @ iter = 183200 , error =  0.02
--> train minibatch error =  0.18  at iter  183242
-->  10 9100 chunk_20_50000.pkl
training @ iter = 183300 , loss =  0.00123562931549
training @ iter = 183300 , error =  0.0
--> train minibatch error =  0.12  at iter  183394
-->  10 16700 chunk_20_50000.pkl
training @ iter = 183400 , loss =  0.00939648598433
training @ iter = 183400 , error =  0.0
training @ iter = 183500 , loss =  0.00389684550464
training @ iter = 183500 , error =  0.0
training @ iter = 183600 , loss =  0.0107423905283
training @ iter = 183600 , error =  0.0
training @ iter = 183700 , loss =  0.00168263132218
training @ iter = 183700 , error =  0.0
training @ iter = 183800 , loss =  0.00287501537241
training @ iter = 183800 , error =  0.0
training @ iter = 183900 , loss =  0.00152990792412
training @ iter = 183900 , error =  0.0
training @ iter = 184000 , loss =  0.00398899614811
training @ iter = 184000 , error =  0.0
training @ iter = 184100 , loss =  0.00205462658778
training @ iter = 184100 , error =  0.0
training @ iter = 184200 , loss =  0.00362767931074
training @ iter = 184200 , error =  0.0
training @ iter = 184300 , loss =  0.00181014672853
training @ iter = 184300 , error =  0.0
training @ iter = 184400 , loss =  0.020307643339
training @ iter = 184400 , error =  0.0
training @ iter = 184500 , loss =  0.000551413511857
training @ iter = 184500 , error =  0.0
training @ iter = 184600 , loss =  0.0536288358271
training @ iter = 184600 , error =  0.04
--> train minibatch error =  0.12  at iter  184663
-->  11 30150 chunk_21_50000.pkl
training @ iter = 184700 , loss =  0.0069882068783
training @ iter = 184700 , error =  0.0
training @ iter = 184800 , loss =  0.00109508587047
training @ iter = 184800 , error =  0.0
training @ iter = 184900 , loss =  0.00139056448825
training @ iter = 184900 , error =  0.0
training @ iter = 185000 , loss =  0.0118490215391
training @ iter = 185000 , error =  0.0
--> train minibatch error =  0.12  at iter  185075
-->  12 750 chunk_22_50000.pkl
training @ iter = 185100 , loss =  0.00208029896021
training @ iter = 185100 , error =  0.0
training @ iter = 185200 , loss =  0.00450041005388
training @ iter = 185200 , error =  0.0
training @ iter = 185300 , loss =  0.0100080324337
training @ iter = 185300 , error =  0.0
training @ iter = 185400 , loss =  0.00771961826831
training @ iter = 185400 , error =  0.0
training @ iter = 185500 , loss =  0.00076829676982
training @ iter = 185500 , error =  0.0
training @ iter = 185600 , loss =  0.00118269759696
training @ iter = 185600 , error =  0.0
training @ iter = 185700 , loss =  0.001815408119
training @ iter = 185700 , error =  0.0
training @ iter = 185800 , loss =  0.00188456848264
training @ iter = 185800 , error =  0.0
training @ iter = 185900 , loss =  0.0197804197669
training @ iter = 185900 , error =  0.02
training @ iter = 186000 , loss =  0.017610071227
training @ iter = 186000 , error =  0.02
training @ iter = 186100 , loss =  0.00388208264485
training @ iter = 186100 , error =  0.0
training @ iter = 186200 , loss =  0.252664983273
training @ iter = 186200 , error =  0.06
--> train minibatch error =  0.14  at iter  186256
-->  13 9800 chunk_23_50000.pkl
training @ iter = 186300 , loss =  0.0466259494424
training @ iter = 186300 , error =  0.02
training @ iter = 186400 , loss =  0.000775364693254
training @ iter = 186400 , error =  0.0
training @ iter = 186500 , loss =  0.0600557811558
training @ iter = 186500 , error =  0.02
training @ iter = 186600 , loss =  0.0180668346584
training @ iter = 186600 , error =  0.0
training @ iter = 186700 , loss =  0.117024734616
training @ iter = 186700 , error =  0.02
training @ iter = 186800 , loss =  0.00800733361393
training @ iter = 186800 , error =  0.0
training @ iter = 186900 , loss =  0.00117757031694
training @ iter = 186900 , error =  0.0
training @ iter = 187000 , loss =  0.15678858757
training @ iter = 187000 , error =  0.02
training @ iter = 187100 , loss =  0.0346800237894
training @ iter = 187100 , error =  0.02
training @ iter = 187200 , loss =  0.00117503141519
training @ iter = 187200 , error =  0.0
training @ iter = 187300 , loss =  0.0453455783427
training @ iter = 187300 , error =  0.02
training @ iter = 187400 , loss =  0.0160987973213
training @ iter = 187400 , error =  0.0
training @ iter = 187500 , loss =  0.00817315001041
training @ iter = 187500 , error =  0.0
training @ iter = 187600 , loss =  0.00203593284823
training @ iter = 187600 , error =  0.0
training @ iter = 187700 , loss =  0.000850032141898
training @ iter = 187700 , error =  0.0
training @ iter = 187800 , loss =  0.0221488289535
training @ iter = 187800 , error =  0.02
training @ iter = 187900 , loss =  0.0172557812184
training @ iter = 187900 , error =  0.0
training @ iter = 188000 , loss =  0.0128857446834
training @ iter = 188000 , error =  0.0
training @ iter = 188100 , loss =  0.00576675729826
training @ iter = 188100 , error =  0.0
training @ iter = 188200 , loss =  0.0100002642721
training @ iter = 188200 , error =  0.0
training @ iter = 188300 , loss =  0.00548033602536
training @ iter = 188300 , error =  0.0
training @ iter = 188400 , loss =  0.00162906665355
training @ iter = 188400 , error =  0.0
training @ iter = 188500 , loss =  0.0123975360766
training @ iter = 188500 , error =  0.0
training @ iter = 188600 , loss =  0.00102325330954
training @ iter = 188600 , error =  0.0
training @ iter = 188700 , loss =  0.00472917873412
training @ iter = 188700 , error =  0.0
training @ iter = 188800 , loss =  0.00384567887522
training @ iter = 188800 , error =  0.0
training @ iter = 188900 , loss =  0.000916934164707
training @ iter = 188900 , error =  0.0
training @ iter = 189000 , loss =  0.0150036001578
training @ iter = 189000 , error =  0.0
training @ iter = 189100 , loss =  0.000765129167121
training @ iter = 189100 , error =  0.0
training @ iter = 189200 , loss =  0.00105156039353
training @ iter = 189200 , error =  0.0
training @ iter = 189300 , loss =  0.00337942899205
training @ iter = 189300 , error =  0.0
training @ iter = 189400 , loss =  0.023445693776
training @ iter = 189400 , error =  0.0
training @ iter = 189500 , loss =  0.00385617325082
training @ iter = 189500 , error =  0.0
training @ iter = 189600 , loss =  0.0110092572868
training @ iter = 189600 , error =  0.02
training @ iter = 189700 , loss =  0.00103548669722
training @ iter = 189700 , error =  0.0
training @ iter = 189800 , loss =  0.0593001395464
training @ iter = 189800 , error =  0.02
training @ iter = 189900 , loss =  0.0017701551551
training @ iter = 189900 , error =  0.0
validation @ iter 190000
epoch 0, iter 190000, train buffer error 0.100000 %
epoch 0, iter 190000, validation loss 0.020404
epoch 0, iter 190000, validation error 0.615000 %
patience before checkBest 230000
patience after checkBest 230000
training @ iter = 190000 , loss =  0.0500673055649
training @ iter = 190000 , error =  0.02
--> train minibatch error =  0.14  at iter  190048
-->  16 49400 chunk_26_50000.pkl
training @ iter = 190100 , loss =  0.00261382875033
training @ iter = 190100 , error =  0.0
training @ iter = 190200 , loss =  0.00236738915555
training @ iter = 190200 , error =  0.0
training @ iter = 190300 , loss =  0.001383776078
training @ iter = 190300 , error =  0.0
training @ iter = 190400 , loss =  0.000393830327084
training @ iter = 190400 , error =  0.0
training @ iter = 190500 , loss =  0.00612776121125
training @ iter = 190500 , error =  0.0
training @ iter = 190600 , loss =  0.0139721445739
training @ iter = 190600 , error =  0.0
training @ iter = 190700 , loss =  0.00896455068141
training @ iter = 190700 , error =  0.0
training @ iter = 190800 , loss =  0.0235963873565
training @ iter = 190800 , error =  0.0
training @ iter = 190900 , loss =  0.0263817645609
training @ iter = 190900 , error =  0.0
training @ iter = 191000 , loss =  0.014246228151
training @ iter = 191000 , error =  0.0
training @ iter = 191100 , loss =  0.0728045105934
training @ iter = 191100 , error =  0.02
training @ iter = 191200 , loss =  0.00274807075039
training @ iter = 191200 , error =  0.0
training @ iter = 191300 , loss =  0.155690848827
training @ iter = 191300 , error =  0.02
training @ iter = 191400 , loss =  0.0210702903569
training @ iter = 191400 , error =  0.0
training @ iter = 191500 , loss =  0.00936704128981
training @ iter = 191500 , error =  0.0
training @ iter = 191600 , loss =  0.00900351163
training @ iter = 191600 , error =  0.0
training @ iter = 191700 , loss =  0.00481515005231
training @ iter = 191700 , error =  0.0
ERROR:  /home/shared/Fields_12-2015/chunks_feat_50000/chunks_train/chunk_28_50000.pkl  has  4  candidates.
training @ iter = 191800 , loss =  0.024213001132
training @ iter = 191800 , error =  0.0
training @ iter = 191900 , loss =  0.00708806235343
training @ iter = 191900 , error =  0.0
training @ iter = 192000 , loss =  0.00277835899033
training @ iter = 192000 , error =  0.0
training @ iter = 192100 , loss =  0.0152008412406
training @ iter = 192100 , error =  0.0
training @ iter = 192200 , loss =  0.00583938602358
training @ iter = 192200 , error =  0.0
training @ iter = 192300 , loss =  0.0227347780019
training @ iter = 192300 , error =  0.0
training @ iter = 192400 , loss =  0.0224158708006
training @ iter = 192400 , error =  0.0
training @ iter = 192500 , loss =  0.00142597360536
training @ iter = 192500 , error =  0.0
training @ iter = 192600 , loss =  0.00107422110159
training @ iter = 192600 , error =  0.0
training @ iter = 192700 , loss =  0.00245792930946
training @ iter = 192700 , error =  0.0
training @ iter = 192800 , loss =  0.0112337172031
training @ iter = 192800 , error =  0.0
training @ iter = 192900 , loss =  0.00708062108606
training @ iter = 192900 , error =  0.0
--> train minibatch error =  0.24  at iter  192901
-->  20 5900 chunk_5_50000.pkl
--> train minibatch error =  0.16  at iter  192902
-->  20 5950 chunk_5_50000.pkl
training @ iter = 193000 , loss =  0.0108521571383
training @ iter = 193000 , error =  0.0
training @ iter = 193100 , loss =  0.005333380308
training @ iter = 193100 , error =  0.0
training @ iter = 193200 , loss =  0.00540263345465
training @ iter = 193200 , error =  0.0
training @ iter = 193300 , loss =  0.0114836869761
training @ iter = 193300 , error =  0.0
training @ iter = 193400 , loss =  0.000556794693694
training @ iter = 193400 , error =  0.0
training @ iter = 193500 , loss =  0.032537356019
training @ iter = 193500 , error =  0.0
training @ iter = 193600 , loss =  0.00729070324451
training @ iter = 193600 , error =  0.0
training @ iter = 193700 , loss =  0.00180408579763
training @ iter = 193700 , error =  0.0
training @ iter = 193800 , loss =  0.0466918610036
training @ iter = 193800 , error =  0.02
training @ iter = 193900 , loss =  0.0405100435019
training @ iter = 193900 , error =  0.02
training @ iter = 194000 , loss =  0.00318720308132
training @ iter = 194000 , error =  0.0
training @ iter = 194100 , loss =  0.00086445332272
training @ iter = 194100 , error =  0.0
training @ iter = 194200 , loss =  0.102746464312
training @ iter = 194200 , error =  0.06
training @ iter = 194300 , loss =  0.0200584027916
training @ iter = 194300 , error =  0.02
training @ iter = 194400 , loss =  0.00364339118823
training @ iter = 194400 , error =  0.0
training @ iter = 194500 , loss =  0.00753497285768
training @ iter = 194500 , error =  0.0
training @ iter = 194600 , loss =  0.000744672550354
training @ iter = 194600 , error =  0.0
training @ iter = 194700 , loss =  0.00277251005173
training @ iter = 194700 , error =  0.0
training @ iter = 194800 , loss =  0.0675449669361
training @ iter = 194800 , error =  0.02
training @ iter = 194900 , loss =  0.0412490218878
training @ iter = 194900 , error =  0.02
training @ iter = 195000 , loss =  0.00155722443014
training @ iter = 195000 , error =  0.0
training @ iter = 195100 , loss =  0.00163654808421
training @ iter = 195100 , error =  0.0
training @ iter = 195200 , loss =  0.00567002547905
training @ iter = 195200 , error =  0.0
training @ iter = 195300 , loss =  0.0229581482708
training @ iter = 195300 , error =  0.0
training @ iter = 195400 , loss =  0.0164056681097
training @ iter = 195400 , error =  0.0
--> train minibatch error =  0.12  at iter  195402
-->  22 30950 chunk_7_50000.pkl
training @ iter = 195500 , loss =  0.0133549496531
training @ iter = 195500 , error =  0.0
training @ iter = 195600 , loss =  0.00576261384413
training @ iter = 195600 , error =  0.0
training @ iter = 195700 , loss =  0.000926506530959
training @ iter = 195700 , error =  0.0
training @ iter = 195800 , loss =  0.0056463717483
training @ iter = 195800 , error =  0.0
training @ iter = 195900 , loss =  0.00818198453635
training @ iter = 195900 , error =  0.0
training @ iter = 196000 , loss =  0.0051102489233
training @ iter = 196000 , error =  0.0
training @ iter = 196100 , loss =  0.00820349343121
training @ iter = 196100 , error =  0.0
training @ iter = 196200 , loss =  0.000735047913622
training @ iter = 196200 , error =  0.0
--> train minibatch error =  0.12  at iter  196211
-->  23 21400 chunk_8_50000.pkl
training @ iter = 196300 , loss =  0.364102751017
training @ iter = 196300 , error =  0.1
training @ iter = 196400 , loss =  0.00482397573069
training @ iter = 196400 , error =  0.0
--> train minibatch error =  0.12  at iter  196421
-->  23 31900 chunk_8_50000.pkl
training @ iter = 196500 , loss =  0.0208825655282
training @ iter = 196500 , error =  0.0
training @ iter = 196600 , loss =  0.00107938970905
training @ iter = 196600 , error =  0.0
training @ iter = 196700 , loss =  0.00933141075075
training @ iter = 196700 , error =  0.0
training @ iter = 196800 , loss =  0.000940127647482
training @ iter = 196800 , error =  0.0
training @ iter = 196900 , loss =  0.00536196213216
training @ iter = 196900 , error =  0.0
training @ iter = 197000 , loss =  0.00620944937691
training @ iter = 197000 , error =  0.0
training @ iter = 197100 , loss =  0.0190704911947
training @ iter = 197100 , error =  0.0
training @ iter = 197200 , loss =  0.00283235125244
training @ iter = 197200 , error =  0.0
training @ iter = 197300 , loss =  0.0191981904209
training @ iter = 197300 , error =  0.0
training @ iter = 197400 , loss =  0.00184225349221
training @ iter = 197400 , error =  0.0
--> train minibatch error =  0.22  at iter  197477
-->  24 34700 chunk_9_50000.pkl
--> train minibatch error =  0.18  at iter  197478
-->  24 34750 chunk_9_50000.pkl
--> train minibatch error =  0.12  at iter  197480
-->  24 34850 chunk_9_50000.pkl
training @ iter = 197500 , loss =  0.00778848491609
training @ iter = 197500 , error =  0.0
training @ iter = 197600 , loss =  0.00266899447888
training @ iter = 197600 , error =  0.0
training @ iter = 197700 , loss =  0.00206722388975
training @ iter = 197700 , error =  0.0
Epoch  8 , iteration  197784 training @ iter = 197800 , loss =  0.0118414163589
training @ iter = 197800 , error =  0.0
training @ iter = 197900 , loss =  0.00409309985116
training @ iter = 197900 , error =  0.0
training @ iter = 198000 , loss =  0.0048133675009
training @ iter = 198000 , error =  0.0
training @ iter = 198100 , loss =  0.00835663452744
training @ iter = 198100 , error =  0.0
training @ iter = 198200 , loss =  0.00174101034645
training @ iter = 198200 , error =  0.0
training @ iter = 198300 , loss =  0.00122176541481
training @ iter = 198300 , error =  0.0
--> train minibatch error =  0.14  at iter  198364
-->  0 29050 chunk_10_50000.pkl
training @ iter = 198400 , loss =  0.000450264225947
training @ iter = 198400 , error =  0.0
training @ iter = 198500 , loss =  0.00395549274981
training @ iter = 198500 , error =  0.0
training @ iter = 198600 , loss =  0.0435526259243
training @ iter = 198600 , error =  0.02
training @ iter = 198700 , loss =  0.00355387339368
training @ iter = 198700 , error =  0.0
training @ iter = 198800 , loss =  0.00392185151577
training @ iter = 198800 , error =  0.0
training @ iter = 198900 , loss =  0.00281177391298
training @ iter = 198900 , error =  0.0
training @ iter = 199000 , loss =  0.00380587461405
training @ iter = 199000 , error =  0.0
training @ iter = 199100 , loss =  0.00279551534913
training @ iter = 199100 , error =  0.0
--> train minibatch error =  0.12  at iter  199106
-->  1 16150 chunk_11_50000.pkl
training @ iter = 199200 , loss =  0.00158713292331
training @ iter = 199200 , error =  0.0
training @ iter = 199300 , loss =  0.00112859276123
training @ iter = 199300 , error =  0.0
training @ iter = 199400 , loss =  0.00137427006848
training @ iter = 199400 , error =  0.0
training @ iter = 199500 , loss =  0.00879486370832
training @ iter = 199500 , error =  0.0
training @ iter = 199600 , loss =  0.0017287528608
training @ iter = 199600 , error =  0.0
training @ iter = 199700 , loss =  0.0268333368003
training @ iter = 199700 , error =  0.02
training @ iter = 199800 , loss =  0.00313309789635
training @ iter = 199800 , error =  0.0
training @ iter = 199900 , loss =  0.0286769419909
training @ iter = 199900 , error =  0.0
Saving @ iter  200000
Learning rate:  0.01
validation @ iter 200000
epoch 0, iter 200000, train buffer error 0.300000 %
epoch 0, iter 200000, validation loss 0.019843
epoch 0, iter 200000, validation error 0.624000 %
patience before checkBest 230000
patience after checkBest 230000
training @ iter = 200000 , loss =  0.00164008408319
training @ iter = 200000 , error =  0.0
training @ iter = 200100 , loss =  0.0240345168859
training @ iter = 200100 , error =  0.02
training @ iter = 200200 , loss =  0.00187539320905
training @ iter = 200200 , error =  0.0
training @ iter = 200300 , loss =  0.122970677912
training @ iter = 200300 , error =  0.02
training @ iter = 200400 , loss =  0.0293417889625
training @ iter = 200400 , error =  0.0
training @ iter = 200500 , loss =  0.000660187157337
training @ iter = 200500 , error =  0.0
training @ iter = 200600 , loss =  0.0145749971271
training @ iter = 200600 , error =  0.0
training @ iter = 200700 , loss =  0.0164759084582
training @ iter = 200700 , error =  0.0
training @ iter = 200800 , loss =  0.0221805050969
training @ iter = 200800 , error =  0.02
training @ iter = 200900 , loss =  0.00152286945377
training @ iter = 200900 , error =  0.0
training @ iter = 201000 , loss =  0.000838646141347
training @ iter = 201000 , error =  0.0
training @ iter = 201100 , loss =  0.0101401284337
training @ iter = 201100 , error =  0.0
training @ iter = 201200 , loss =  0.00421143975109
training @ iter = 201200 , error =  0.0
training @ iter = 201300 , loss =  0.00309011270292
training @ iter = 201300 , error =  0.0
training @ iter = 201400 , loss =  0.00292902789079
training @ iter = 201400 , error =  0.0
training @ iter = 201500 , loss =  0.0234009195119
training @ iter = 201500 , error =  0.02
training @ iter = 201600 , loss =  0.00419054878876
training @ iter = 201600 , error =  0.0
training @ iter = 201700 , loss =  0.00346572045237
training @ iter = 201700 , error =  0.0
training @ iter = 201800 , loss =  0.0116954399273
training @ iter = 201800 , error =  0.0
training @ iter = 201900 , loss =  0.0925316885114
training @ iter = 201900 , error =  0.06
training @ iter = 202000 , loss =  0.00140191870742
training @ iter = 202000 , error =  0.0
training @ iter = 202100 , loss =  0.00336829479784
training @ iter = 202100 , error =  0.0
training @ iter = 202200 , loss =  0.0628891140223
training @ iter = 202200 , error =  0.02
training @ iter = 202300 , loss =  0.00449915090576
training @ iter = 202300 , error =  0.0
training @ iter = 202400 , loss =  0.213309854269
training @ iter = 202400 , error =  0.04
training @ iter = 202500 , loss =  0.11535038054
training @ iter = 202500 , error =  0.04
training @ iter = 202600 , loss =  0.00344234984368
training @ iter = 202600 , error =  0.0
training @ iter = 202700 , loss =  0.0423819869757
training @ iter = 202700 , error =  0.02
training @ iter = 202800 , loss =  0.00231824396178
training @ iter = 202800 , error =  0.0
training @ iter = 202900 , loss =  0.00406586751342
training @ iter = 202900 , error =  0.0
training @ iter = 203000 , loss =  0.00261375913396
training @ iter = 203000 , error =  0.0
training @ iter = 203100 , loss =  0.00154346984345
training @ iter = 203100 , error =  0.0
training @ iter = 203200 , loss =  0.0210696719587
training @ iter = 203200 , error =  0.0
training @ iter = 203300 , loss =  0.0394478179514
training @ iter = 203300 , error =  0.02
training @ iter = 203400 , loss =  0.0218122061342
training @ iter = 203400 , error =  0.02
training @ iter = 203500 , loss =  0.00189961749129
training @ iter = 203500 , error =  0.0
training @ iter = 203600 , loss =  0.0287015028298
training @ iter = 203600 , error =  0.02
training @ iter = 203700 , loss =  0.00420802040026
training @ iter = 203700 , error =  0.0
training @ iter = 203800 , loss =  0.00312225962989
training @ iter = 203800 , error =  0.0
training @ iter = 203900 , loss =  0.000857500708662
training @ iter = 203900 , error =  0.0
training @ iter = 204000 , loss =  0.0739421248436
training @ iter = 204000 , error =  0.02
training @ iter = 204100 , loss =  0.00245152926072
training @ iter = 204100 , error =  0.0
training @ iter = 204200 , loss =  0.00191434042063
training @ iter = 204200 , error =  0.0
training @ iter = 204300 , loss =  0.00181163102388
training @ iter = 204300 , error =  0.0
training @ iter = 204400 , loss =  0.00207995693199
training @ iter = 204400 , error =  0.0
training @ iter = 204500 , loss =  0.00684841768816
training @ iter = 204500 , error =  0.0
training @ iter = 204600 , loss =  0.000994203961454
training @ iter = 204600 , error =  0.0
training @ iter = 204700 , loss =  0.00279382336885
training @ iter = 204700 , error =  0.0
training @ iter = 204800 , loss =  0.00399354239926
training @ iter = 204800 , error =  0.0
training @ iter = 204900 , loss =  0.306787520647
training @ iter = 204900 , error =  0.04
training @ iter = 205000 , loss =  0.00364125706255
training @ iter = 205000 , error =  0.0
training @ iter = 205100 , loss =  0.00561834825203
training @ iter = 205100 , error =  0.0
training @ iter = 205200 , loss =  0.0515061616898
training @ iter = 205200 , error =  0.02
training @ iter = 205300 , loss =  0.00302908779122
training @ iter = 205300 , error =  0.0
training @ iter = 205400 , loss =  0.0302166957408
training @ iter = 205400 , error =  0.02
--> train minibatch error =  0.18  at iter  205450
-->  7 33350 chunk_17_50000.pkl
training @ iter = 205500 , loss =  0.00602063117549
training @ iter = 205500 , error =  0.0
training @ iter = 205600 , loss =  0.00829114299268
training @ iter = 205600 , error =  0.0
training @ iter = 205700 , loss =  0.00828834250569
training @ iter = 205700 , error =  0.0
training @ iter = 205800 , loss =  0.0455735884607
training @ iter = 205800 , error =  0.02
--> train minibatch error =  0.12  at iter  205878
-->  8 4750 chunk_18_50000.pkl
training @ iter = 205900 , loss =  0.00519561907277
training @ iter = 205900 , error =  0.0
training @ iter = 206000 , loss =  0.0066254758276
training @ iter = 206000 , error =  0.0
training @ iter = 206100 , loss =  0.0234725251794
training @ iter = 206100 , error =  0.0
training @ iter = 206200 , loss =  0.127970784903
training @ iter = 206200 , error =  0.02
training @ iter = 206300 , loss =  0.0920135751367
training @ iter = 206300 , error =  0.02
--> train minibatch error =  0.12  at iter  206389
-->  8 30300 chunk_18_50000.pkl
--> train minibatch error =  0.24  at iter  206390
-->  8 30350 chunk_18_50000.pkl
training @ iter = 206400 , loss =  0.0130158821121
training @ iter = 206400 , error =  0.0
--> train minibatch error =  0.14  at iter  206455
-->  8 33600 chunk_18_50000.pkl
training @ iter = 206500 , loss =  0.00887617561966
training @ iter = 206500 , error =  0.0
training @ iter = 206600 , loss =  0.00186406378634
training @ iter = 206600 , error =  0.0
training @ iter = 206700 , loss =  0.114675804973
training @ iter = 206700 , error =  0.04
training @ iter = 206800 , loss =  0.0461920313537
training @ iter = 206800 , error =  0.02
training @ iter = 206900 , loss =  0.00759012065828
training @ iter = 206900 , error =  0.0
training @ iter = 207000 , loss =  0.000879320257809
training @ iter = 207000 , error =  0.0
training @ iter = 207100 , loss =  0.0280657559633
training @ iter = 207100 , error =  0.02
training @ iter = 207200 , loss =  0.00301432725973
training @ iter = 207200 , error =  0.0
training @ iter = 207300 , loss =  0.0257090386003
training @ iter = 207300 , error =  0.0
training @ iter = 207400 , loss =  0.0437267385423
training @ iter = 207400 , error =  0.02
training @ iter = 207500 , loss =  0.0012470461661
training @ iter = 207500 , error =  0.0
training @ iter = 207600 , loss =  0.00359980156645
training @ iter = 207600 , error =  0.0
training @ iter = 207700 , loss =  0.00380527670495
training @ iter = 207700 , error =  0.0
training @ iter = 207800 , loss =  0.00359450280666
training @ iter = 207800 , error =  0.0
training @ iter = 207900 , loss =  0.0454979948699
training @ iter = 207900 , error =  0.02
--> train minibatch error =  0.18  at iter  207965
-->  10 9100 chunk_20_50000.pkl
training @ iter = 208000 , loss =  0.00873572845012
training @ iter = 208000 , error =  0.0
training @ iter = 208100 , loss =  0.0220431704074
training @ iter = 208100 , error =  0.02
--> train minibatch error =  0.12  at iter  208117
-->  10 16700 chunk_20_50000.pkl
training @ iter = 208200 , loss =  0.0044303489849
training @ iter = 208200 , error =  0.0
training @ iter = 208300 , loss =  0.018140591681
training @ iter = 208300 , error =  0.0
training @ iter = 208400 , loss =  0.00120583816897
training @ iter = 208400 , error =  0.0
training @ iter = 208500 , loss =  0.0525175705552
training @ iter = 208500 , error =  0.02
training @ iter = 208600 , loss =  0.00708643812686
training @ iter = 208600 , error =  0.0
training @ iter = 208700 , loss =  0.0142935262993
training @ iter = 208700 , error =  0.0
training @ iter = 208800 , loss =  0.00318573927507
training @ iter = 208800 , error =  0.0
training @ iter = 208900 , loss =  0.00211140909232
training @ iter = 208900 , error =  0.0
training @ iter = 209000 , loss =  0.00484426598996
training @ iter = 209000 , error =  0.0
training @ iter = 209100 , loss =  0.000919002166484
training @ iter = 209100 , error =  0.0
training @ iter = 209200 , loss =  0.00730852084234
training @ iter = 209200 , error =  0.0
training @ iter = 209300 , loss =  0.00191619014367
training @ iter = 209300 , error =  0.0
--> train minibatch error =  0.12  at iter  209386
-->  11 30150 chunk_21_50000.pkl
training @ iter = 209400 , loss =  0.00368916033767
training @ iter = 209400 , error =  0.0
training @ iter = 209500 , loss =  0.00444035418332
training @ iter = 209500 , error =  0.0
training @ iter = 209600 , loss =  0.00222929543816
training @ iter = 209600 , error =  0.0
training @ iter = 209700 , loss =  0.00458619883284
training @ iter = 209700 , error =  0.0
training @ iter = 209800 , loss =  0.0261783115566
training @ iter = 209800 , error =  0.0
training @ iter = 209900 , loss =  0.00393271259964
training @ iter = 209900 , error =  0.0
validation @ iter 210000
epoch 0, iter 210000, train buffer error 0.900000 %
epoch 0, iter 210000, validation loss 0.018982
epoch 0, iter 210000, validation error 0.576000 %
patience before checkBest 230000
Patience =  310000
patience after checkBest 310000
training @ iter = 210000 , loss =  0.0498416051269
training @ iter = 210000 , error =  0.0
training @ iter = 210100 , loss =  0.0147453285754
training @ iter = 210100 , error =  0.0
training @ iter = 210200 , loss =  0.000553680351004
training @ iter = 210200 , error =  0.0
training @ iter = 210300 , loss =  0.00450048968196
training @ iter = 210300 , error =  0.0
training @ iter = 210400 , loss =  0.00329959066585
training @ iter = 210400 , error =  0.0
training @ iter = 210500 , loss =  0.0363390408456
training @ iter = 210500 , error =  0.02
training @ iter = 210600 , loss =  0.00244563841261
training @ iter = 210600 , error =  0.0
training @ iter = 210700 , loss =  0.00103230553214
training @ iter = 210700 , error =  0.0
training @ iter = 210800 , loss =  0.00501629849896
training @ iter = 210800 , error =  0.0
training @ iter = 210900 , loss =  0.00123434595298
training @ iter = 210900 , error =  0.0
--> train minibatch error =  0.12  at iter  210979
-->  13 9800 chunk_23_50000.pkl
training @ iter = 211000 , loss =  0.00712673319504
training @ iter = 211000 , error =  0.0
training @ iter = 211100 , loss =  0.0333459489048
training @ iter = 211100 , error =  0.0
training @ iter = 211200 , loss =  0.00151209766045
training @ iter = 211200 , error =  0.0
training @ iter = 211300 , loss =  0.0432728044689
training @ iter = 211300 , error =  0.0
training @ iter = 211400 , loss =  0.0014850597363
training @ iter = 211400 , error =  0.0
training @ iter = 211500 , loss =  0.000719092320651
training @ iter = 211500 , error =  0.0
training @ iter = 211600 , loss =  0.00219715596177
training @ iter = 211600 , error =  0.0
training @ iter = 211700 , loss =  0.155155852437
training @ iter = 211700 , error =  0.04
training @ iter = 211800 , loss =  0.000848226831295
training @ iter = 211800 , error =  0.0
training @ iter = 211900 , loss =  0.00415368098766
training @ iter = 211900 , error =  0.0
training @ iter = 212000 , loss =  0.0071716196835
training @ iter = 212000 , error =  0.0
training @ iter = 212100 , loss =  0.00327784684487
training @ iter = 212100 , error =  0.0
training @ iter = 212200 , loss =  0.00175818090793
training @ iter = 212200 , error =  0.0
training @ iter = 212300 , loss =  0.202286317945
training @ iter = 212300 , error =  0.04
training @ iter = 212400 , loss =  0.00184978172183
training @ iter = 212400 , error =  0.0
training @ iter = 212500 , loss =  0.083624869585
training @ iter = 212500 , error =  0.02
training @ iter = 212600 , loss =  0.0942598730326
training @ iter = 212600 , error =  0.02
training @ iter = 212700 , loss =  0.0175018552691
training @ iter = 212700 , error =  0.02
training @ iter = 212800 , loss =  0.000926495646127
training @ iter = 212800 , error =  0.0
training @ iter = 212900 , loss =  0.00763286603615
training @ iter = 212900 , error =  0.0
training @ iter = 213000 , loss =  0.127544939518
training @ iter = 213000 , error =  0.02
training @ iter = 213100 , loss =  0.0048818346113
training @ iter = 213100 , error =  0.0
training @ iter = 213200 , loss =  0.00108574132901
training @ iter = 213200 , error =  0.0
training @ iter = 213300 , loss =  0.00375263323076
training @ iter = 213300 , error =  0.0
training @ iter = 213400 , loss =  0.0124324345961
training @ iter = 213400 , error =  0.0
training @ iter = 213500 , loss =  0.00572193367407
training @ iter = 213500 , error =  0.0
training @ iter = 213600 , loss =  0.00759655097499
training @ iter = 213600 , error =  0.0
training @ iter = 213700 , loss =  0.00278727314435
training @ iter = 213700 , error =  0.0
training @ iter = 213800 , loss =  0.00308227073401
training @ iter = 213800 , error =  0.0
training @ iter = 213900 , loss =  0.00045865989523
training @ iter = 213900 , error =  0.0
training @ iter = 214000 , loss =  0.000954249349888
training @ iter = 214000 , error =  0.0
training @ iter = 214100 , loss =  0.00368285924196
training @ iter = 214100 , error =  0.0
training @ iter = 214200 , loss =  0.0083829946816
training @ iter = 214200 , error =  0.0
training @ iter = 214300 , loss =  0.0055153532885
training @ iter = 214300 , error =  0.0
training @ iter = 214400 , loss =  0.0934220403433
training @ iter = 214400 , error =  0.02
training @ iter = 214500 , loss =  0.00288848928176
training @ iter = 214500 , error =  0.0
training @ iter = 214600 , loss =  0.00461042346433
training @ iter = 214600 , error =  0.0
training @ iter = 214700 , loss =  0.00227904715575
training @ iter = 214700 , error =  0.0
--> train minibatch error =  0.14  at iter  214771
-->  16 49400 chunk_26_50000.pkl
training @ iter = 214800 , loss =  0.00313849444501
training @ iter = 214800 , error =  0.0
training @ iter = 214900 , loss =  0.0215556807816
training @ iter = 214900 , error =  0.0
training @ iter = 215000 , loss =  0.00171129556838
training @ iter = 215000 , error =  0.0
training @ iter = 215100 , loss =  0.00636343704537
training @ iter = 215100 , error =  0.0
training @ iter = 215200 , loss =  0.00236822431907
training @ iter = 215200 , error =  0.0
training @ iter = 215300 , loss =  0.0454202443361
training @ iter = 215300 , error =  0.02
training @ iter = 215400 , loss =  0.167762130499
training @ iter = 215400 , error =  0.02
training @ iter = 215500 , loss =  0.00288789044134
training @ iter = 215500 , error =  0.0
training @ iter = 215600 , loss =  0.0017758795293
training @ iter = 215600 , error =  0.0
training @ iter = 215700 , loss =  0.00136405648664
training @ iter = 215700 , error =  0.0
training @ iter = 215800 , loss =  0.00411036005244
training @ iter = 215800 , error =  0.0
training @ iter = 215900 , loss =  0.00379569502547
training @ iter = 215900 , error =  0.0
training @ iter = 216000 , loss =  0.00572885852307
training @ iter = 216000 , error =  0.0
training @ iter = 216100 , loss =  0.00748551264405
training @ iter = 216100 , error =  0.0
training @ iter = 216200 , loss =  0.00135179085191
training @ iter = 216200 , error =  0.0
training @ iter = 216300 , loss =  0.0011532966746
training @ iter = 216300 , error =  0.0
training @ iter = 216400 , loss =  0.0681789666414
training @ iter = 216400 , error =  0.02
training @ iter = 216500 , loss =  0.0069624055177
training @ iter = 216500 , error =  0.0
ERROR:  /home/shared/Fields_12-2015/chunks_feat_50000/chunks_train/chunk_28_50000.pkl  has  4  candidates.
training @ iter = 216600 , loss =  0.0474909245968
training @ iter = 216600 , error =  0.02
training @ iter = 216700 , loss =  0.00107259105425
training @ iter = 216700 , error =  0.0
training @ iter = 216800 , loss =  0.102133795619
training @ iter = 216800 , error =  0.02
training @ iter = 216900 , loss =  0.0159426350147
training @ iter = 216900 , error =  0.0
training @ iter = 217000 , loss =  0.167244836688
training @ iter = 217000 , error =  0.04
training @ iter = 217100 , loss =  0.0291337426752
training @ iter = 217100 , error =  0.0
training @ iter = 217200 , loss =  0.00780297582969
training @ iter = 217200 , error =  0.0
training @ iter = 217300 , loss =  0.00365594099276
training @ iter = 217300 , error =  0.0
training @ iter = 217400 , loss =  0.00213760347106
training @ iter = 217400 , error =  0.0
training @ iter = 217500 , loss =  0.00338599621318
training @ iter = 217500 , error =  0.0
training @ iter = 217600 , loss =  0.0600046440959
training @ iter = 217600 , error =  0.02
--> train minibatch error =  0.26  at iter  217624
-->  20 5900 chunk_5_50000.pkl
--> train minibatch error =  0.16  at iter  217625
-->  20 5950 chunk_5_50000.pkl
training @ iter = 217700 , loss =  0.171560198069
training @ iter = 217700 , error =  0.02
training @ iter = 217800 , loss =  0.0343827866018
training @ iter = 217800 , error =  0.0
training @ iter = 217900 , loss =  0.00831468496472
training @ iter = 217900 , error =  0.0
training @ iter = 218000 , loss =  0.00109493872151
training @ iter = 218000 , error =  0.0
training @ iter = 218100 , loss =  0.00281630340032
training @ iter = 218100 , error =  0.0
training @ iter = 218200 , loss =  0.0180070288479
training @ iter = 218200 , error =  0.0
training @ iter = 218300 , loss =  0.173240512609
training @ iter = 218300 , error =  0.02
training @ iter = 218400 , loss =  0.00661180494353
training @ iter = 218400 , error =  0.0
training @ iter = 218500 , loss =  0.0370976813138
training @ iter = 218500 , error =  0.02
--> train minibatch error =  0.12  at iter  218592
-->  21 4300 chunk_6_50000.pkl
training @ iter = 218600 , loss =  0.0099184140563
training @ iter = 218600 , error =  0.0
training @ iter = 218700 , loss =  0.0323832929134
training @ iter = 218700 , error =  0.02
training @ iter = 218800 , loss =  0.000450664549135
training @ iter = 218800 , error =  0.0
training @ iter = 218900 , loss =  0.00616216054186
training @ iter = 218900 , error =  0.0
training @ iter = 219000 , loss =  0.00825064163655
training @ iter = 219000 , error =  0.0
training @ iter = 219100 , loss =  0.00130027276464
training @ iter = 219100 , error =  0.0
training @ iter = 219200 , loss =  0.00177588080987
training @ iter = 219200 , error =  0.0
training @ iter = 219300 , loss =  0.00469652516767
training @ iter = 219300 , error =  0.0
training @ iter = 219400 , loss =  0.0874235257506
training @ iter = 219400 , error =  0.02
training @ iter = 219500 , loss =  0.00587718980387
training @ iter = 219500 , error =  0.0
training @ iter = 219600 , loss =  0.0154589870945
training @ iter = 219600 , error =  0.0
training @ iter = 219700 , loss =  0.11578451097
training @ iter = 219700 , error =  0.02
training @ iter = 219800 , loss =  0.0311329290271
training @ iter = 219800 , error =  0.02
training @ iter = 219900 , loss =  0.00754633918405
training @ iter = 219900 , error =  0.0
validation @ iter 220000
epoch 0, iter 220000, train buffer error 0.100000 %
epoch 0, iter 220000, validation loss 0.018940
epoch 0, iter 220000, validation error 0.574000 %
patience before checkBest 310000
patience after checkBest 310000
training @ iter = 220000 , loss =  0.006726202555
training @ iter = 220000 , error =  0.0
training @ iter = 220100 , loss =  0.000926068052649
training @ iter = 220100 , error =  0.0
--> train minibatch error =  0.12  at iter  220125
-->  22 30950 chunk_7_50000.pkl
training @ iter = 220200 , loss =  0.0063185095787
training @ iter = 220200 , error =  0.0
training @ iter = 220300 , loss =  0.00648642843589
training @ iter = 220300 , error =  0.0
training @ iter = 220400 , loss =  0.0427586920559
training @ iter = 220400 , error =  0.0
training @ iter = 220500 , loss =  0.000834531558212
training @ iter = 220500 , error =  0.0
training @ iter = 220600 , loss =  0.00882763043046
training @ iter = 220600 , error =  0.0
training @ iter = 220700 , loss =  0.00506522413343
training @ iter = 220700 , error =  0.0
training @ iter = 220800 , loss =  0.000844852300361
training @ iter = 220800 , error =  0.0
training @ iter = 220900 , loss =  0.000971586385276
training @ iter = 220900 , error =  0.0
training @ iter = 221000 , loss =  0.00981433782727
training @ iter = 221000 , error =  0.0
training @ iter = 221100 , loss =  0.00113269907888
training @ iter = 221100 , error =  0.0
--> train minibatch error =  0.14  at iter  221144
-->  23 31900 chunk_8_50000.pkl
training @ iter = 221200 , loss =  0.0348032563925
training @ iter = 221200 , error =  0.0
training @ iter = 221300 , loss =  0.00482478365302
training @ iter = 221300 , error =  0.0
training @ iter = 221400 , loss =  0.00181495817378
training @ iter = 221400 , error =  0.0
training @ iter = 221500 , loss =  0.0135718444362
training @ iter = 221500 , error =  0.02
training @ iter = 221600 , loss =  0.0392813421786
training @ iter = 221600 , error =  0.02
training @ iter = 221700 , loss =  0.00274531077594
training @ iter = 221700 , error =  0.0
training @ iter = 221800 , loss =  0.00120798696298
training @ iter = 221800 , error =  0.0
training @ iter = 221900 , loss =  0.00142149243038
training @ iter = 221900 , error =  0.0
training @ iter = 222000 , loss =  0.0015412166249
training @ iter = 222000 , error =  0.0
training @ iter = 222100 , loss =  0.0185358095914
training @ iter = 222100 , error =  0.0
training @ iter = 222200 , loss =  0.651502668858
training @ iter = 222200 , error =  0.22
--> train minibatch error =  0.22  at iter  222200
-->  24 34700 chunk_9_50000.pkl
--> train minibatch error =  0.2  at iter  222201
-->  24 34750 chunk_9_50000.pkl
training @ iter = 222300 , loss =  0.00108255504165
training @ iter = 222300 , error =  0.0
training @ iter = 222400 , loss =  0.00214680703357
training @ iter = 222400 , error =  0.0
training @ iter = 222500 , loss =  0.00955468881875
training @ iter = 222500 , error =  0.0
Epoch  9 , iteration  222507 training @ iter = 222600 , loss =  0.0285821929574
training @ iter = 222600 , error =  0.02
training @ iter = 222700 , loss =  0.00373898888938
training @ iter = 222700 , error =  0.0
training @ iter = 222800 , loss =  0.0819058641791
training @ iter = 222800 , error =  0.02
training @ iter = 222900 , loss =  0.00149238528684
training @ iter = 222900 , error =  0.0
training @ iter = 223000 , loss =  0.00449273176491
training @ iter = 223000 , error =  0.0
training @ iter = 223100 , loss =  0.00175870524254
training @ iter = 223100 , error =  0.0
training @ iter = 223200 , loss =  0.00395711325109
training @ iter = 223200 , error =  0.0
training @ iter = 223300 , loss =  0.0444034337997
training @ iter = 223300 , error =  0.02
training @ iter = 223400 , loss =  0.000629851827398
training @ iter = 223400 , error =  0.0
training @ iter = 223500 , loss =  0.00304805929773
training @ iter = 223500 , error =  0.0
training @ iter = 223600 , loss =  0.0652869567275
training @ iter = 223600 , error =  0.02
training @ iter = 223700 , loss =  0.0061986814253
training @ iter = 223700 , error =  0.0
training @ iter = 223800 , loss =  0.00289825466461
training @ iter = 223800 , error =  0.0
training @ iter = 223900 , loss =  0.00125966954511
training @ iter = 223900 , error =  0.0
training @ iter = 224000 , loss =  0.0532025061548
training @ iter = 224000 , error =  0.02
training @ iter = 224100 , loss =  0.00125479022972
training @ iter = 224100 , error =  0.0
training @ iter = 224200 , loss =  0.0579785220325
training @ iter = 224200 , error =  0.02
training @ iter = 224300 , loss =  0.00883814506233
training @ iter = 224300 , error =  0.0
training @ iter = 224400 , loss =  0.0145964315161
training @ iter = 224400 , error =  0.0
training @ iter = 224500 , loss =  0.00295712170191
training @ iter = 224500 , error =  0.0
training @ iter = 224600 , loss =  0.00170122925192
training @ iter = 224600 , error =  0.0
training @ iter = 224700 , loss =  0.00520995026454
training @ iter = 224700 , error =  0.0
training @ iter = 224800 , loss =  0.0116787459701
training @ iter = 224800 , error =  0.0
training @ iter = 224900 , loss =  0.00298335799016
training @ iter = 224900 , error =  0.0
Saving @ iter  225000
training @ iter = 225000 , loss =  0.00272123375908
training @ iter = 225000 , error =  0.0
training @ iter = 225100 , loss =  0.00514377048239
training @ iter = 225100 , error =  0.0
training @ iter = 225200 , loss =  0.00113347056322
training @ iter = 225200 , error =  0.0
training @ iter = 225300 , loss =  0.00159860041458
training @ iter = 225300 , error =  0.0
training @ iter = 225400 , loss =  0.00444408506155
training @ iter = 225400 , error =  0.0
training @ iter = 225500 , loss =  0.0062535405159
training @ iter = 225500 , error =  0.0
training @ iter = 225600 , loss =  0.00355833303183
training @ iter = 225600 , error =  0.0
training @ iter = 225700 , loss =  0.000725864607375
training @ iter = 225700 , error =  0.0
training @ iter = 225800 , loss =  0.00797526910901
training @ iter = 225800 , error =  0.0
training @ iter = 225900 , loss =  0.000915892131161
training @ iter = 225900 , error =  0.0
training @ iter = 226000 , loss =  0.0021006797906
training @ iter = 226000 , error =  0.0
training @ iter = 226100 , loss =  0.002236234257
training @ iter = 226100 , error =  0.0
training @ iter = 226200 , loss =  0.0290133859962
training @ iter = 226200 , error =  0.0
training @ iter = 226300 , loss =  0.000584502588026
training @ iter = 226300 , error =  0.0
training @ iter = 226400 , loss =  0.00445064110681
training @ iter = 226400 , error =  0.0
training @ iter = 226500 , loss =  0.0243942923844
training @ iter = 226500 , error =  0.02
training @ iter = 226600 , loss =  0.130622059107
training @ iter = 226600 , error =  0.02
training @ iter = 226700 , loss =  0.00211703008972
training @ iter = 226700 , error =  0.0
training @ iter = 226800 , loss =  0.000835395767353
training @ iter = 226800 , error =  0.0
training @ iter = 226900 , loss =  0.0544315129519
training @ iter = 226900 , error =  0.02
training @ iter = 227000 , loss =  0.00578188896179
training @ iter = 227000 , error =  0.0
training @ iter = 227100 , loss =  0.00150672381278
training @ iter = 227100 , error =  0.0
training @ iter = 227200 , loss =  0.00147210597061
training @ iter = 227200 , error =  0.0
training @ iter = 227300 , loss =  0.00191827386152
training @ iter = 227300 , error =  0.0
training @ iter = 227400 , loss =  0.00628993846476
training @ iter = 227400 , error =  0.0
training @ iter = 227500 , loss =  0.0627866834402
training @ iter = 227500 , error =  0.02
training @ iter = 227600 , loss =  0.0318450108171
training @ iter = 227600 , error =  0.02
training @ iter = 227700 , loss =  0.00183380430099
training @ iter = 227700 , error =  0.0
training @ iter = 227800 , loss =  0.000711854081601
training @ iter = 227800 , error =  0.0
training @ iter = 227900 , loss =  0.00456000538543
training @ iter = 227900 , error =  0.0
training @ iter = 228000 , loss =  0.00307442061603
training @ iter = 228000 , error =  0.0
training @ iter = 228100 , loss =  0.00192814541515
training @ iter = 228100 , error =  0.0
training @ iter = 228200 , loss =  0.000736699556001
training @ iter = 228200 , error =  0.0
training @ iter = 228300 , loss =  0.0699392184615
training @ iter = 228300 , error =  0.02
training @ iter = 228400 , loss =  0.00510894320905
training @ iter = 228400 , error =  0.0
training @ iter = 228500 , loss =  0.0156077854335
training @ iter = 228500 , error =  0.0
training @ iter = 228600 , loss =  0.00898298993707
training @ iter = 228600 , error =  0.0
training @ iter = 228700 , loss =  0.180867418647
training @ iter = 228700 , error =  0.04
training @ iter = 228800 , loss =  0.000929582573008
training @ iter = 228800 , error =  0.0
training @ iter = 228900 , loss =  0.0131896445528
training @ iter = 228900 , error =  0.0
training @ iter = 229000 , loss =  0.00192212255206
training @ iter = 229000 , error =  0.0
training @ iter = 229100 , loss =  0.0043589649722
training @ iter = 229100 , error =  0.0
training @ iter = 229200 , loss =  0.00279678287916
training @ iter = 229200 , error =  0.0
training @ iter = 229300 , loss =  0.00462412275374
training @ iter = 229300 , error =  0.0
training @ iter = 229400 , loss =  0.000504583062138
training @ iter = 229400 , error =  0.0
training @ iter = 229500 , loss =  0.00223511806689
training @ iter = 229500 , error =  0.0
training @ iter = 229600 , loss =  0.0333809964359
training @ iter = 229600 , error =  0.02
training @ iter = 229700 , loss =  0.0592542439699
training @ iter = 229700 , error =  0.02
training @ iter = 229800 , loss =  0.00575544638559
training @ iter = 229800 , error =  0.0
training @ iter = 229900 , loss =  0.0250281337649
training @ iter = 229900 , error =  0.0
validation @ iter 230000
epoch 0, iter 230000, train buffer error 0.300000 %
epoch 0, iter 230000, validation loss 0.018950
epoch 0, iter 230000, validation error 0.563000 %
patience before checkBest 310000
Patience =  330000
patience after checkBest 330000
training @ iter = 230000 , loss =  0.0489648245275
training @ iter = 230000 , error =  0.04
training @ iter = 230100 , loss =  0.0998533889651
training @ iter = 230100 , error =  0.02
--> train minibatch error =  0.18  at iter  230173
-->  7 33350 chunk_17_50000.pkl
training @ iter = 230200 , loss =  0.00965209770948
training @ iter = 230200 , error =  0.0
training @ iter = 230300 , loss =  0.0156371649355
training @ iter = 230300 , error =  0.0
training @ iter = 230400 , loss =  0.334612667561
training @ iter = 230400 , error =  0.1
training @ iter = 230500 , loss =  0.00202286802232
training @ iter = 230500 , error =  0.0
training @ iter = 230600 , loss =  0.0742437168956
training @ iter = 230600 , error =  0.02
--> train minibatch error =  0.12  at iter  230601
-->  8 4750 chunk_18_50000.pkl
training @ iter = 230700 , loss =  0.0076127438806
training @ iter = 230700 , error =  0.0
training @ iter = 230800 , loss =  0.00128514261451
training @ iter = 230800 , error =  0.0
training @ iter = 230900 , loss =  0.0101170670241
training @ iter = 230900 , error =  0.0
training @ iter = 231000 , loss =  0.238535314798
training @ iter = 231000 , error =  0.06
training @ iter = 231100 , loss =  0.00352819263935
training @ iter = 231100 , error =  0.0
--> train minibatch error =  0.26  at iter  231113
-->  8 30350 chunk_18_50000.pkl
--> train minibatch error =  0.14  at iter  231178
-->  8 33600 chunk_18_50000.pkl
training @ iter = 231200 , loss =  0.0665817707777
training @ iter = 231200 , error =  0.02
training @ iter = 231300 , loss =  0.00484066084027
training @ iter = 231300 , error =  0.0
training @ iter = 231400 , loss =  0.0023825627286
training @ iter = 231400 , error =  0.0
training @ iter = 231500 , loss =  0.00782597530633
training @ iter = 231500 , error =  0.0
training @ iter = 231600 , loss =  0.00376304262318
training @ iter = 231600 , error =  0.0
training @ iter = 231700 , loss =  0.00137823412661
training @ iter = 231700 , error =  0.0
training @ iter = 231800 , loss =  0.00101391633507
training @ iter = 231800 , error =  0.0
training @ iter = 231900 , loss =  0.00549422996119
training @ iter = 231900 , error =  0.0
training @ iter = 232000 , loss =  0.00330041348934
training @ iter = 232000 , error =  0.0
training @ iter = 232100 , loss =  0.00420388393104
training @ iter = 232100 , error =  0.0
training @ iter = 232200 , loss =  0.000607602996752
training @ iter = 232200 , error =  0.0
training @ iter = 232300 , loss =  0.0183905344456
training @ iter = 232300 , error =  0.0
training @ iter = 232400 , loss =  0.0396704301238
training @ iter = 232400 , error =  0.0
training @ iter = 232500 , loss =  0.0131906829774
training @ iter = 232500 , error =  0.0
training @ iter = 232600 , loss =  0.00718334689736
training @ iter = 232600 , error =  0.0
--> train minibatch error =  0.18  at iter  232688
-->  10 9100 chunk_20_50000.pkl
training @ iter = 232700 , loss =  0.00381103041582
training @ iter = 232700 , error =  0.0
training @ iter = 232800 , loss =  0.000852949975524
training @ iter = 232800 , error =  0.0
--> train minibatch error =  0.12  at iter  232840
-->  10 16700 chunk_20_50000.pkl
training @ iter = 232900 , loss =  0.0362068302929
training @ iter = 232900 , error =  0.0
training @ iter = 233000 , loss =  0.0106078516692
training @ iter = 233000 , error =  0.0
training @ iter = 233100 , loss =  0.00273026758805
training @ iter = 233100 , error =  0.0
training @ iter = 233200 , loss =  0.107941076159
training @ iter = 233200 , error =  0.02
training @ iter = 233300 , loss =  0.143446058035
training @ iter = 233300 , error =  0.04
training @ iter = 233400 , loss =  0.0138559695333
training @ iter = 233400 , error =  0.0
training @ iter = 233500 , loss =  0.00497804954648
training @ iter = 233500 , error =  0.0
training @ iter = 233600 , loss =  0.0195310413837
training @ iter = 233600 , error =  0.0
training @ iter = 233700 , loss =  0.0029767351225
training @ iter = 233700 , error =  0.0
training @ iter = 233800 , loss =  0.000977069023065
training @ iter = 233800 , error =  0.0
training @ iter = 233900 , loss =  0.0284428875893
training @ iter = 233900 , error =  0.0
training @ iter = 234000 , loss =  0.0683509930968
training @ iter = 234000 , error =  0.02
training @ iter = 234100 , loss =  0.00142443727236
training @ iter = 234100 , error =  0.0
training @ iter = 234200 , loss =  0.000757552974392
training @ iter = 234200 , error =  0.0
training @ iter = 234300 , loss =  0.00311248539947
training @ iter = 234300 , error =  0.0
training @ iter = 234400 , loss =  0.00733364280313
training @ iter = 234400 , error =  0.0
training @ iter = 234500 , loss =  0.00108742620796
training @ iter = 234500 , error =  0.0
training @ iter = 234600 , loss =  0.000582284119446
training @ iter = 234600 , error =  0.0
training @ iter = 234700 , loss =  0.00340117583983
training @ iter = 234700 , error =  0.0
training @ iter = 234800 , loss =  0.00275539210998
training @ iter = 234800 , error =  0.0
training @ iter = 234900 , loss =  0.00149500067346
training @ iter = 234900 , error =  0.0
training @ iter = 235000 , loss =  0.00796139705926
training @ iter = 235000 , error =  0.0
training @ iter = 235100 , loss =  0.00159542099573
training @ iter = 235100 , error =  0.0
training @ iter = 235200 , loss =  0.00738272303715
training @ iter = 235200 , error =  0.0
training @ iter = 235300 , loss =  0.000828181277029
training @ iter = 235300 , error =  0.0
training @ iter = 235400 , loss =  0.00103437621146
training @ iter = 235400 , error =  0.0
training @ iter = 235500 , loss =  0.00899829901755
training @ iter = 235500 , error =  0.0
training @ iter = 235600 , loss =  0.00140497228131
training @ iter = 235600 , error =  0.0
training @ iter = 235700 , loss =  0.034156370908
training @ iter = 235700 , error =  0.02
--> train minibatch error =  0.14  at iter  235702
-->  13 9800 chunk_23_50000.pkl
training @ iter = 235800 , loss =  0.00264017144218
training @ iter = 235800 , error =  0.0
training @ iter = 235900 , loss =  0.282602190971
training @ iter = 235900 , error =  0.04
training @ iter = 236000 , loss =  0.0471372455359
training @ iter = 236000 , error =  0.02
training @ iter = 236100 , loss =  0.0693977475166
training @ iter = 236100 , error =  0.02
training @ iter = 236200 , loss =  0.0010598578956
training @ iter = 236200 , error =  0.0
training @ iter = 236300 , loss =  0.065946623683
training @ iter = 236300 , error =  0.02
training @ iter = 236400 , loss =  0.11377826333
training @ iter = 236400 , error =  0.02
training @ iter = 236500 , loss =  0.0193127244711
training @ iter = 236500 , error =  0.02
training @ iter = 236600 , loss =  0.00968815758824
training @ iter = 236600 , error =  0.0
training @ iter = 236700 , loss =  0.0386023037136
training @ iter = 236700 , error =  0.04
training @ iter = 236800 , loss =  0.00549021363258
training @ iter = 236800 , error =  0.0
training @ iter = 236900 , loss =  0.00198240159079
training @ iter = 236900 , error =  0.0
training @ iter = 237000 , loss =  0.000999885029159
training @ iter = 237000 , error =  0.0
training @ iter = 237100 , loss =  0.000827606068924
training @ iter = 237100 , error =  0.0
training @ iter = 237200 , loss =  0.00296206842177
training @ iter = 237200 , error =  0.0
training @ iter = 237300 , loss =  0.0616735853255
training @ iter = 237300 , error =  0.02
training @ iter = 237400 , loss =  0.00613559223711
training @ iter = 237400 , error =  0.0
training @ iter = 237500 , loss =  0.00115753919818
training @ iter = 237500 , error =  0.0
training @ iter = 237600 , loss =  0.00196805410087
training @ iter = 237600 , error =  0.0
training @ iter = 237700 , loss =  0.00965879950672
training @ iter = 237700 , error =  0.0
training @ iter = 237800 , loss =  0.00221964530647
training @ iter = 237800 , error =  0.0
training @ iter = 237900 , loss =  0.0325222909451
training @ iter = 237900 , error =  0.02
training @ iter = 238000 , loss =  0.00140927697066
training @ iter = 238000 , error =  0.0
training @ iter = 238100 , loss =  0.0009292550385
training @ iter = 238100 , error =  0.0
training @ iter = 238200 , loss =  0.000814838567749
training @ iter = 238200 , error =  0.0
training @ iter = 238300 , loss =  0.00298150395975
training @ iter = 238300 , error =  0.0
training @ iter = 238400 , loss =  0.0252129584551
training @ iter = 238400 , error =  0.02
training @ iter = 238500 , loss =  0.000641051970888
training @ iter = 238500 , error =  0.0
training @ iter = 238600 , loss =  0.017804114148
training @ iter = 238600 , error =  0.02
training @ iter = 238700 , loss =  0.00322443991899
training @ iter = 238700 , error =  0.0
training @ iter = 238800 , loss =  0.00358172785491
training @ iter = 238800 , error =  0.0
training @ iter = 238900 , loss =  0.00529819587246
training @ iter = 238900 , error =  0.0
training @ iter = 239000 , loss =  0.000921760045458
training @ iter = 239000 , error =  0.0
training @ iter = 239100 , loss =  0.0469041578472
training @ iter = 239100 , error =  0.02
training @ iter = 239200 , loss =  0.244167253375
training @ iter = 239200 , error =  0.04
training @ iter = 239300 , loss =  0.00228705722839
training @ iter = 239300 , error =  0.0
training @ iter = 239400 , loss =  0.010382572189
training @ iter = 239400 , error =  0.0
--> train minibatch error =  0.14  at iter  239494
-->  16 49400 chunk_26_50000.pkl
training @ iter = 239500 , loss =  0.00453842105344
training @ iter = 239500 , error =  0.0
training @ iter = 239600 , loss =  0.000886960187927
training @ iter = 239600 , error =  0.0
training @ iter = 239700 , loss =  0.00824012979865
training @ iter = 239700 , error =  0.0
training @ iter = 239800 , loss =  0.0241415388882
training @ iter = 239800 , error =  0.0
training @ iter = 239900 , loss =  0.0644557401538
training @ iter = 239900 , error =  0.02
validation @ iter 240000
epoch 0, iter 240000, train buffer error 0.200000 %
epoch 0, iter 240000, validation loss 0.018873
epoch 0, iter 240000, validation error 0.564000 %
patience before checkBest 330000
patience after checkBest 330000
training @ iter = 240000 , loss =  0.00345323630609
training @ iter = 240000 , error =  0.0
training @ iter = 240100 , loss =  0.000902023166418
training @ iter = 240100 , error =  0.0
training @ iter = 240200 , loss =  0.00448644021526
training @ iter = 240200 , error =  0.0
training @ iter = 240300 , loss =  0.000937283504754
training @ iter = 240300 , error =  0.0
training @ iter = 240400 , loss =  0.0087767848745
training @ iter = 240400 , error =  0.0
training @ iter = 240500 , loss =  0.000498507928569
training @ iter = 240500 , error =  0.0
training @ iter = 240600 , loss =  0.0163347050548
training @ iter = 240600 , error =  0.0
training @ iter = 240700 , loss =  0.0064808614552
training @ iter = 240700 , error =  0.0
training @ iter = 240800 , loss =  0.0186348818243
training @ iter = 240800 , error =  0.0
training @ iter = 240900 , loss =  0.000794244988356
training @ iter = 240900 , error =  0.0
training @ iter = 241000 , loss =  0.00395626761019
training @ iter = 241000 , error =  0.0
training @ iter = 241100 , loss =  0.00311140692793
training @ iter = 241100 , error =  0.0
training @ iter = 241200 , loss =  0.00472160521895
training @ iter = 241200 , error =  0.0
ERROR:  /home/shared/Fields_12-2015/chunks_feat_50000/chunks_train/chunk_28_50000.pkl  has  4  candidates.
training @ iter = 241300 , loss =  0.00294453254901
training @ iter = 241300 , error =  0.0
training @ iter = 241400 , loss =  0.00733830081299
training @ iter = 241400 , error =  0.0
training @ iter = 241500 , loss =  0.00306391506456
training @ iter = 241500 , error =  0.0
training @ iter = 241600 , loss =  0.0187978036702
training @ iter = 241600 , error =  0.02
training @ iter = 241700 , loss =  0.0013685390586
training @ iter = 241700 , error =  0.0
training @ iter = 241800 , loss =  0.00152371719014
training @ iter = 241800 , error =  0.0
training @ iter = 241900 , loss =  0.00331216608174
training @ iter = 241900 , error =  0.0
training @ iter = 242000 , loss =  0.00656276941299
training @ iter = 242000 , error =  0.0
training @ iter = 242100 , loss =  0.00624209176749
training @ iter = 242100 , error =  0.0
training @ iter = 242200 , loss =  0.0431881584227
training @ iter = 242200 , error =  0.0
training @ iter = 242300 , loss =  0.0694796442986
training @ iter = 242300 , error =  0.02
--> train minibatch error =  0.24  at iter  242347
-->  20 5900 chunk_5_50000.pkl
--> train minibatch error =  0.16  at iter  242348
-->  20 5950 chunk_5_50000.pkl
training @ iter = 242400 , loss =  0.00974816456437
training @ iter = 242400 , error =  0.0
training @ iter = 242500 , loss =  0.00101942312904
training @ iter = 242500 , error =  0.0
training @ iter = 242600 , loss =  0.0539645850658
training @ iter = 242600 , error =  0.02
training @ iter = 242700 , loss =  0.000699772965163
training @ iter = 242700 , error =  0.0
training @ iter = 242800 , loss =  0.00300258467905
training @ iter = 242800 , error =  0.0
training @ iter = 242900 , loss =  0.0845936834812
training @ iter = 242900 , error =  0.02
training @ iter = 243000 , loss =  0.00664283055812
training @ iter = 243000 , error =  0.0
training @ iter = 243100 , loss =  0.00458874600008
training @ iter = 243100 , error =  0.0
training @ iter = 243200 , loss =  0.00431426754221
training @ iter = 243200 , error =  0.0
training @ iter = 243300 , loss =  0.015138505958
training @ iter = 243300 , error =  0.0
training @ iter = 243400 , loss =  0.0733334571123
training @ iter = 243400 , error =  0.02
training @ iter = 243500 , loss =  0.0274331029505
training @ iter = 243500 , error =  0.02
training @ iter = 243600 , loss =  0.00726381875575
training @ iter = 243600 , error =  0.0
training @ iter = 243700 , loss =  0.11193523556
training @ iter = 243700 , error =  0.04
training @ iter = 243800 , loss =  0.000724992074538
training @ iter = 243800 , error =  0.0
training @ iter = 243900 , loss =  0.0641872882843
training @ iter = 243900 , error =  0.02
training @ iter = 244000 , loss =  0.000628969806712
training @ iter = 244000 , error =  0.0
training @ iter = 244100 , loss =  0.00780268153176
training @ iter = 244100 , error =  0.0
training @ iter = 244200 , loss =  0.00631364155561
training @ iter = 244200 , error =  0.0
training @ iter = 244300 , loss =  0.000743119220715
training @ iter = 244300 , error =  0.0
training @ iter = 244400 , loss =  0.00124967424199
training @ iter = 244400 , error =  0.0
training @ iter = 244500 , loss =  0.00147637014743
training @ iter = 244500 , error =  0.0
training @ iter = 244600 , loss =  0.0149538479745
training @ iter = 244600 , error =  0.0
training @ iter = 244700 , loss =  0.0953280255198
training @ iter = 244700 , error =  0.04
training @ iter = 244800 , loss =  0.0077412952669
training @ iter = 244800 , error =  0.0
--> train minibatch error =  0.14  at iter  244848
-->  22 30950 chunk_7_50000.pkl
training @ iter = 244900 , loss =  0.00827682763338
training @ iter = 244900 , error =  0.0
training @ iter = 245000 , loss =  0.00278007169254
training @ iter = 245000 , error =  0.0
training @ iter = 245100 , loss =  0.00232829130255
training @ iter = 245100 , error =  0.0
training @ iter = 245200 , loss =  0.0294872969389
training @ iter = 245200 , error =  0.02
training @ iter = 245300 , loss =  0.0209399461746
training @ iter = 245300 , error =  0.0
training @ iter = 245400 , loss =  0.0305987112224
training @ iter = 245400 , error =  0.02
training @ iter = 245500 , loss =  0.00223427871242
training @ iter = 245500 , error =  0.0
training @ iter = 245600 , loss =  0.175647988915
training @ iter = 245600 , error =  0.04
--> train minibatch error =  0.12  at iter  245657
-->  23 21400 chunk_8_50000.pkl
training @ iter = 245700 , loss =  0.00609205942601
training @ iter = 245700 , error =  0.0
training @ iter = 245800 , loss =  0.00175648694858
training @ iter = 245800 , error =  0.0
--> train minibatch error =  0.14  at iter  245867
-->  23 31900 chunk_8_50000.pkl
training @ iter = 245900 , loss =  0.00102545379195
training @ iter = 245900 , error =  0.0
training @ iter = 246000 , loss =  0.00560614932328
training @ iter = 246000 , error =  0.0
training @ iter = 246100 , loss =  0.00272615533322
training @ iter = 246100 , error =  0.0
training @ iter = 246200 , loss =  0.00499970652163
training @ iter = 246200 , error =  0.0
training @ iter = 246300 , loss =  0.00529355043545
training @ iter = 246300 , error =  0.0
training @ iter = 246400 , loss =  0.00113070372026
training @ iter = 246400 , error =  0.0
training @ iter = 246500 , loss =  0.00162936234847
training @ iter = 246500 , error =  0.0
training @ iter = 246600 , loss =  0.0395130589604
training @ iter = 246600 , error =  0.0
training @ iter = 246700 , loss =  0.000495368964039
training @ iter = 246700 , error =  0.0
training @ iter = 246800 , loss =  0.00425866199657
training @ iter = 246800 , error =  0.0
training @ iter = 246900 , loss =  0.0193273704499
training @ iter = 246900 , error =  0.0
--> train minibatch error =  0.22  at iter  246923
-->  24 34700 chunk_9_50000.pkl
--> train minibatch error =  0.2  at iter  246924
-->  24 34750 chunk_9_50000.pkl
training @ iter = 247000 , loss =  0.00322722317651
training @ iter = 247000 , error =  0.0
training @ iter = 247100 , loss =  0.0202906224877
training @ iter = 247100 , error =  0.02
training @ iter = 247200 , loss =  0.00049721240066
training @ iter = 247200 , error =  0.0
Epoch  10 , iteration  247230 training @ iter = 247300 , loss =  0.06502404809
training @ iter = 247300 , error =  0.02
training @ iter = 247400 , loss =  0.0118465665728
training @ iter = 247400 , error =  0.0
training @ iter = 247500 , loss =  0.142240226269
training @ iter = 247500 , error =  0.02
training @ iter = 247600 , loss =  0.00794249493629
training @ iter = 247600 , error =  0.0
training @ iter = 247700 , loss =  0.00636907853186
training @ iter = 247700 , error =  0.0
training @ iter = 247800 , loss =  0.00261046737432
training @ iter = 247800 , error =  0.0
training @ iter = 247900 , loss =  0.00555694568902
training @ iter = 247900 , error =  0.0
training @ iter = 248000 , loss =  0.0241133198142
training @ iter = 248000 , error =  0.0
training @ iter = 248100 , loss =  0.00315836933441
training @ iter = 248100 , error =  0.0
training @ iter = 248200 , loss =  0.000925934233237
training @ iter = 248200 , error =  0.0
training @ iter = 248300 , loss =  0.00267896521837
training @ iter = 248300 , error =  0.0
training @ iter = 248400 , loss =  0.155964225531
training @ iter = 248400 , error =  0.04
training @ iter = 248500 , loss =  0.00128492515069
training @ iter = 248500 , error =  0.0
training @ iter = 248600 , loss =  0.0177700705826
training @ iter = 248600 , error =  0.0
training @ iter = 248700 , loss =  0.0019543832168
training @ iter = 248700 , error =  0.0
training @ iter = 248800 , loss =  0.00156476860866
training @ iter = 248800 , error =  0.0
training @ iter = 248900 , loss =  0.0101321414113
training @ iter = 248900 , error =  0.0
training @ iter = 249000 , loss =  0.00384196196683
training @ iter = 249000 , error =  0.0
training @ iter = 249100 , loss =  0.00187749264296
training @ iter = 249100 , error =  0.0
training @ iter = 249200 , loss =  0.0028699063696
training @ iter = 249200 , error =  0.0
training @ iter = 249300 , loss =  0.00922040361911
training @ iter = 249300 , error =  0.0
training @ iter = 249400 , loss =  0.0767058804631
training @ iter = 249400 , error =  0.04
training @ iter = 249500 , loss =  0.000414611480664
training @ iter = 249500 , error =  0.0
training @ iter = 249600 , loss =  0.000884169130586
training @ iter = 249600 , error =  0.0
training @ iter = 249700 , loss =  0.000971831846982
training @ iter = 249700 , error =  0.0
training @ iter = 249800 , loss =  0.0611852370203
training @ iter = 249800 , error =  0.02
training @ iter = 249900 , loss =  0.0186769906431
training @ iter = 249900 , error =  0.0
Saving @ iter  250000
validation @ iter 250000
epoch 0, iter 250000, train buffer error 1.300000 %
epoch 0, iter 250000, validation loss 0.019249
epoch 0, iter 250000, validation error 0.592000 %
patience before checkBest 330000
patience after checkBest 330000
training @ iter = 250000 , loss =  0.0975649729371
training @ iter = 250000 , error =  0.04
training @ iter = 250100 , loss =  0.0105843627825
training @ iter = 250100 , error =  0.0
training @ iter = 250200 , loss =  0.000677307893056
training @ iter = 250200 , error =  0.0
training @ iter = 250300 , loss =  0.196547865868
training @ iter = 250300 , error =  0.06
training @ iter = 250400 , loss =  0.000647227047011
training @ iter = 250400 , error =  0.0
training @ iter = 250500 , loss =  0.0331244133413
training @ iter = 250500 , error =  0.02
training @ iter = 250600 , loss =  0.00709244748577
training @ iter = 250600 , error =  0.0
training @ iter = 250700 , loss =  0.00190345931333
training @ iter = 250700 , error =  0.0
training @ iter = 250800 , loss =  0.0052046161145
training @ iter = 250800 , error =  0.0
training @ iter = 250900 , loss =  0.00926041044295
training @ iter = 250900 , error =  0.0
training @ iter = 251000 , loss =  0.00415117619559
training @ iter = 251000 , error =  0.0
training @ iter = 251100 , loss =  0.0247894506902
training @ iter = 251100 , error =  0.0
training @ iter = 251200 , loss =  0.00953204650432
training @ iter = 251200 , error =  0.0
training @ iter = 251300 , loss =  0.00174262735527
training @ iter = 251300 , error =  0.0
training @ iter = 251400 , loss =  0.044016905129
training @ iter = 251400 , error =  0.02
training @ iter = 251500 , loss =  0.000800710637122
training @ iter = 251500 , error =  0.0
training @ iter = 251600 , loss =  0.00333121744916
training @ iter = 251600 , error =  0.0
training @ iter = 251700 , loss =  0.0384487621486
training @ iter = 251700 , error =  0.0
training @ iter = 251800 , loss =  0.00447622872889
training @ iter = 251800 , error =  0.0
training @ iter = 251900 , loss =  0.000777141132858
training @ iter = 251900 , error =  0.0
training @ iter = 252000 , loss =  0.00406213989481
training @ iter = 252000 , error =  0.0
training @ iter = 252100 , loss =  0.00390876922756
training @ iter = 252100 , error =  0.0
training @ iter = 252200 , loss =  0.0117435827851
training @ iter = 252200 , error =  0.02
training @ iter = 252300 , loss =  0.00275050988421
training @ iter = 252300 , error =  0.0
training @ iter = 252400 , loss =  0.000922686245758
training @ iter = 252400 , error =  0.0
training @ iter = 252500 , loss =  0.00157857325394
training @ iter = 252500 , error =  0.0
training @ iter = 252600 , loss =  0.000714076973964
training @ iter = 252600 , error =  0.0
training @ iter = 252700 , loss =  0.000961115001701
training @ iter = 252700 , error =  0.0
training @ iter = 252800 , loss =  0.000814910978079
training @ iter = 252800 , error =  0.0
training @ iter = 252900 , loss =  0.00248864898458
training @ iter = 252900 , error =  0.0
training @ iter = 253000 , loss =  0.0138614056632
training @ iter = 253000 , error =  0.02
training @ iter = 253100 , loss =  0.00208293204196
training @ iter = 253100 , error =  0.0
training @ iter = 253200 , loss =  0.028768973425
training @ iter = 253200 , error =  0.0
training @ iter = 253300 , loss =  0.00253716227598
training @ iter = 253300 , error =  0.0
training @ iter = 253400 , loss =  0.000744055432733
training @ iter = 253400 , error =  0.0
training @ iter = 253500 , loss =  0.00403450103477
training @ iter = 253500 , error =  0.0
training @ iter = 253600 , loss =  0.00213177572004
training @ iter = 253600 , error =  0.0
training @ iter = 253700 , loss =  0.00363366235979
training @ iter = 253700 , error =  0.0
training @ iter = 253800 , loss =  0.00771144870669
training @ iter = 253800 , error =  0.0
training @ iter = 253900 , loss =  0.240838319063
training @ iter = 253900 , error =  0.06
training @ iter = 254000 , loss =  0.00216412404552
training @ iter = 254000 , error =  0.0
training @ iter = 254100 , loss =  0.00138772744685
training @ iter = 254100 , error =  0.0
training @ iter = 254200 , loss =  0.00546459853649
training @ iter = 254200 , error =  0.0
training @ iter = 254300 , loss =  0.0483215674758
training @ iter = 254300 , error =  0.02
training @ iter = 254400 , loss =  0.00146553944796
training @ iter = 254400 , error =  0.0
training @ iter = 254500 , loss =  0.0255196355283
training @ iter = 254500 , error =  0.02
training @ iter = 254600 , loss =  0.0219375379384
training @ iter = 254600 , error =  0.0
training @ iter = 254700 , loss =  0.0118246711791
training @ iter = 254700 , error =  0.0
training @ iter = 254800 , loss =  0.00578308943659
training @ iter = 254800 , error =  0.0
--> train minibatch error =  0.18  at iter  254896
-->  7 33350 chunk_17_50000.pkl
training @ iter = 254900 , loss =  0.00215835799463
training @ iter = 254900 , error =  0.0
training @ iter = 255000 , loss =  0.000923098763451
training @ iter = 255000 , error =  0.0
training @ iter = 255100 , loss =  0.00164425047114
training @ iter = 255100 , error =  0.0
training @ iter = 255200 , loss =  0.00862287823111
training @ iter = 255200 , error =  0.0
training @ iter = 255300 , loss =  0.0376327000558
training @ iter = 255300 , error =  0.02
--> train minibatch error =  0.12  at iter  255324
-->  8 4750 chunk_18_50000.pkl
training @ iter = 255400 , loss =  0.00549038313329
training @ iter = 255400 , error =  0.0
training @ iter = 255500 , loss =  0.000809161167126
training @ iter = 255500 , error =  0.0
training @ iter = 255600 , loss =  0.00122138019651
training @ iter = 255600 , error =  0.0
training @ iter = 255700 , loss =  0.00475305458531
training @ iter = 255700 , error =  0.0
training @ iter = 255800 , loss =  0.00149452418555
training @ iter = 255800 , error =  0.0
--> train minibatch error =  0.22  at iter  255836
-->  8 30350 chunk_18_50000.pkl
training @ iter = 255900 , loss =  0.0177216790617
training @ iter = 255900 , error =  0.0
--> train minibatch error =  0.14  at iter  255901
-->  8 33600 chunk_18_50000.pkl
training @ iter = 256000 , loss =  0.0364443287253
training @ iter = 256000 , error =  0.02
training @ iter = 256100 , loss =  0.00293958908878
training @ iter = 256100 , error =  0.0
training @ iter = 256200 , loss =  0.0818510279059
training @ iter = 256200 , error =  0.02
training @ iter = 256300 , loss =  0.0309953410178
training @ iter = 256300 , error =  0.02
training @ iter = 256400 , loss =  0.0186187122017
training @ iter = 256400 , error =  0.02
--> train minibatch error =  0.12  at iter  256440
-->  9 10550 chunk_19_50000.pkl
training @ iter = 256500 , loss =  0.0044400440529
training @ iter = 256500 , error =  0.02
training @ iter = 256600 , loss =  0.00420841993764
training @ iter = 256600 , error =  0.0
training @ iter = 256700 , loss =  0.00955020729452
training @ iter = 256700 , error =  0.02
training @ iter = 256800 , loss =  0.101832054555
training @ iter = 256800 , error =  0.02
training @ iter = 256900 , loss =  0.0759560763836
training @ iter = 256900 , error =  0.04
training @ iter = 257000 , loss =  0.0173260718584
training @ iter = 257000 , error =  0.0
training @ iter = 257100 , loss =  0.000698152172845
training @ iter = 257100 , error =  0.0
training @ iter = 257200 , loss =  0.0240721441805
training @ iter = 257200 , error =  0.0
training @ iter = 257300 , loss =  0.00104544230271
training @ iter = 257300 , error =  0.0
training @ iter = 257400 , loss =  0.00289124716073
training @ iter = 257400 , error =  0.0
--> train minibatch error =  0.18  at iter  257411
-->  10 9100 chunk_20_50000.pkl
training @ iter = 257500 , loss =  0.00137122278102
training @ iter = 257500 , error =  0.0
--> train minibatch error =  0.14  at iter  257563
-->  10 16700 chunk_20_50000.pkl
training @ iter = 257600 , loss =  0.0817163437605
training @ iter = 257600 , error =  0.04
training @ iter = 257700 , loss =  0.000427653721999
training @ iter = 257700 , error =  0.0
training @ iter = 257800 , loss =  0.000842644134536
training @ iter = 257800 , error =  0.0
training @ iter = 257900 , loss =  0.00456850463524
training @ iter = 257900 , error =  0.0
training @ iter = 258000 , loss =  0.109508603811
training @ iter = 258000 , error =  0.04
training @ iter = 258100 , loss =  0.00398748554289
training @ iter = 258100 , error =  0.0
training @ iter = 258200 , loss =  0.0147692970932
training @ iter = 258200 , error =  0.0
training @ iter = 258300 , loss =  0.00278650736436
training @ iter = 258300 , error =  0.0
training @ iter = 258400 , loss =  0.00198772642761
training @ iter = 258400 , error =  0.0
training @ iter = 258500 , loss =  0.00101524509955
training @ iter = 258500 , error =  0.0
training @ iter = 258600 , loss =  0.00902333576232
training @ iter = 258600 , error =  0.0
training @ iter = 258700 , loss =  0.0150444665924
training @ iter = 258700 , error =  0.0
training @ iter = 258800 , loss =  0.00149046618026
training @ iter = 258800 , error =  0.0
training @ iter = 258900 , loss =  0.000936032971367
training @ iter = 258900 , error =  0.0
training @ iter = 259000 , loss =  0.00213805190288
training @ iter = 259000 , error =  0.0
training @ iter = 259100 , loss =  0.00146296841558
training @ iter = 259100 , error =  0.0
training @ iter = 259200 , loss =  0.259109348059
training @ iter = 259200 , error =  0.06
training @ iter = 259300 , loss =  0.00103336700704
training @ iter = 259300 , error =  0.0
training @ iter = 259400 , loss =  0.0013632341288
training @ iter = 259400 , error =  0.0
training @ iter = 259500 , loss =  0.147001385689
training @ iter = 259500 , error =  0.02
training @ iter = 259600 , loss =  0.0706954598427
training @ iter = 259600 , error =  0.02
training @ iter = 259700 , loss =  0.0151181127876
training @ iter = 259700 , error =  0.02
training @ iter = 259800 , loss =  0.0613207817078
training @ iter = 259800 , error =  0.04
training @ iter = 259900 , loss =  0.0706295520067
training @ iter = 259900 , error =  0.04
validation @ iter 260000
epoch 0, iter 260000, train buffer error 0.300000 %
epoch 0, iter 260000, validation loss 0.019222
epoch 0, iter 260000, validation error 0.576000 %
patience before checkBest 330000
patience after checkBest 330000
training @ iter = 260000 , loss =  0.0110184047371
training @ iter = 260000 , error =  0.0
training @ iter = 260100 , loss =  0.098210722208
training @ iter = 260100 , error =  0.02
training @ iter = 260200 , loss =  0.0105097498745
training @ iter = 260200 , error =  0.0
training @ iter = 260300 , loss =  0.0385960899293
training @ iter = 260300 , error =  0.02
training @ iter = 260400 , loss =  0.00431358953938
training @ iter = 260400 , error =  0.0
--> train minibatch error =  0.14  at iter  260425
-->  13 9800 chunk_23_50000.pkl
training @ iter = 260500 , loss =  0.00160116527695
training @ iter = 260500 , error =  0.0
training @ iter = 260600 , loss =  0.0102892806754
training @ iter = 260600 , error =  0.0
training @ iter = 260700 , loss =  0.0325547344983
training @ iter = 260700 , error =  0.02
training @ iter = 260800 , loss =  0.0189523585141
training @ iter = 260800 , error =  0.0
training @ iter = 260900 , loss =  0.00239508715458
training @ iter = 260900 , error =  0.0
training @ iter = 261000 , loss =  0.000810117111541
training @ iter = 261000 , error =  0.0
training @ iter = 261100 , loss =  0.00287332199514
training @ iter = 261100 , error =  0.0
training @ iter = 261200 , loss =  0.000327930232743
training @ iter = 261200 , error =  0.0
training @ iter = 261300 , loss =  0.00161783595104
training @ iter = 261300 , error =  0.0
training @ iter = 261400 , loss =  0.00186953810044
training @ iter = 261400 , error =  0.0
training @ iter = 261500 , loss =  0.0326279886067
training @ iter = 261500 , error =  0.02
training @ iter = 261600 , loss =  0.00533448718488
training @ iter = 261600 , error =  0.0
training @ iter = 261700 , loss =  0.0128089273348
training @ iter = 261700 , error =  0.0
training @ iter = 261800 , loss =  0.0434687435627
training @ iter = 261800 , error =  0.02
training @ iter = 261900 , loss =  0.00178597611375
training @ iter = 261900 , error =  0.0
training @ iter = 262000 , loss =  0.00985543243587
training @ iter = 262000 , error =  0.0
training @ iter = 262100 , loss =  0.00176186382305
training @ iter = 262100 , error =  0.0
training @ iter = 262200 , loss =  0.0160191468894
training @ iter = 262200 , error =  0.0
training @ iter = 262300 , loss =  0.00381942861713
training @ iter = 262300 , error =  0.0
training @ iter = 262400 , loss =  0.00366368028335
training @ iter = 262400 , error =  0.0
training @ iter = 262500 , loss =  0.0352269783616
training @ iter = 262500 , error =  0.02
training @ iter = 262600 , loss =  0.00491755595431
training @ iter = 262600 , error =  0.02
training @ iter = 262700 , loss =  0.143456235528
training @ iter = 262700 , error =  0.06
training @ iter = 262800 , loss =  0.00919033400714
training @ iter = 262800 , error =  0.0
training @ iter = 262900 , loss =  0.00154145259876
training @ iter = 262900 , error =  0.0
training @ iter = 263000 , loss =  0.00407341308892
training @ iter = 263000 , error =  0.0
training @ iter = 263100 , loss =  0.00290033360943
training @ iter = 263100 , error =  0.0
training @ iter = 263200 , loss =  0.00318734534085
training @ iter = 263200 , error =  0.0
training @ iter = 263300 , loss =  0.0016433163546
training @ iter = 263300 , error =  0.0
training @ iter = 263400 , loss =  0.00292879040353
training @ iter = 263400 , error =  0.0
training @ iter = 263500 , loss =  0.000592254276853
training @ iter = 263500 , error =  0.0
training @ iter = 263600 , loss =  0.116158522666
training @ iter = 263600 , error =  0.02
training @ iter = 263700 , loss =  0.00272977235727
training @ iter = 263700 , error =  0.0
training @ iter = 263800 , loss =  0.00244992878288
training @ iter = 263800 , error =  0.0
training @ iter = 263900 , loss =  0.143116623163
training @ iter = 263900 , error =  0.02
training @ iter = 264000 , loss =  0.00626391032711
training @ iter = 264000 , error =  0.0
training @ iter = 264100 , loss =  0.0121310176328
training @ iter = 264100 , error =  0.0
training @ iter = 264200 , loss =  0.00190136570018
training @ iter = 264200 , error =  0.0
--> train minibatch error =  0.14  at iter  264217
-->  16 49400 chunk_26_50000.pkl
training @ iter = 264300 , loss =  0.0596322901547
training @ iter = 264300 , error =  0.02
training @ iter = 264400 , loss =  0.00353026809171
training @ iter = 264400 , error =  0.0
training @ iter = 264500 , loss =  0.0126245478168
training @ iter = 264500 , error =  0.0
training @ iter = 264600 , loss =  0.0124294348061
training @ iter = 264600 , error =  0.0
training @ iter = 264700 , loss =  0.2343031317
training @ iter = 264700 , error =  0.06
training @ iter = 264800 , loss =  0.0134627576917
training @ iter = 264800 , error =  0.02
training @ iter = 264900 , loss =  0.000643546751235
training @ iter = 264900 , error =  0.0
training @ iter = 265000 , loss =  0.014773376286
training @ iter = 265000 , error =  0.0
training @ iter = 265100 , loss =  0.00485526956618
training @ iter = 265100 , error =  0.0
training @ iter = 265200 , loss =  0.00259129703045
training @ iter = 265200 , error =  0.0
training @ iter = 265300 , loss =  0.00765079725534
training @ iter = 265300 , error =  0.0
training @ iter = 265400 , loss =  0.000856981961988
training @ iter = 265400 , error =  0.0
training @ iter = 265500 , loss =  0.0129552697763
training @ iter = 265500 , error =  0.02
training @ iter = 265600 , loss =  0.0630958974361
training @ iter = 265600 , error =  0.04
training @ iter = 265700 , loss =  0.00714212376624
training @ iter = 265700 , error =  0.0
training @ iter = 265800 , loss =  0.00995088554919
training @ iter = 265800 , error =  0.0
training @ iter = 265900 , loss =  0.00796739012003
training @ iter = 265900 , error =  0.0
ERROR:  /home/shared/Fields_12-2015/chunks_feat_50000/chunks_train/chunk_28_50000.pkl  has  4  candidates.
training @ iter = 266000 , loss =  0.00283424858935
training @ iter = 266000 , error =  0.0
training @ iter = 266100 , loss =  0.00330440676771
training @ iter = 266100 , error =  0.0
training @ iter = 266200 , loss =  0.00766166206449
training @ iter = 266200 , error =  0.0
training @ iter = 266300 , loss =  0.000885310175363
training @ iter = 266300 , error =  0.0
training @ iter = 266400 , loss =  0.00198674295098
training @ iter = 266400 , error =  0.0
training @ iter = 266500 , loss =  0.0218229740858
training @ iter = 266500 , error =  0.02
training @ iter = 266600 , loss =  0.00909931771457
training @ iter = 266600 , error =  0.0
training @ iter = 266700 , loss =  0.00516560859978
training @ iter = 266700 , error =  0.0
training @ iter = 266800 , loss =  0.0300070308149
training @ iter = 266800 , error =  0.0
training @ iter = 266900 , loss =  0.000458081805846
training @ iter = 266900 , error =  0.0
training @ iter = 267000 , loss =  0.0055964156054
training @ iter = 267000 , error =  0.0
--> train minibatch error =  0.26  at iter  267070
-->  20 5900 chunk_5_50000.pkl
--> train minibatch error =  0.16  at iter  267071
-->  20 5950 chunk_5_50000.pkl
training @ iter = 267100 , loss =  0.00166665227152
training @ iter = 267100 , error =  0.0
training @ iter = 267200 , loss =  0.00184137653559
training @ iter = 267200 , error =  0.0
training @ iter = 267300 , loss =  0.050754699856
training @ iter = 267300 , error =  0.02
training @ iter = 267400 , loss =  0.027877278626
training @ iter = 267400 , error =  0.0
training @ iter = 267500 , loss =  0.0355831496418
training @ iter = 267500 , error =  0.02
training @ iter = 267600 , loss =  0.000562846136745
training @ iter = 267600 , error =  0.0
training @ iter = 267700 , loss =  0.00932630524039
training @ iter = 267700 , error =  0.0
training @ iter = 267800 , loss =  0.00164282124024
training @ iter = 267800 , error =  0.0
training @ iter = 267900 , loss =  0.0315841250122
training @ iter = 267900 , error =  0.02
training @ iter = 268000 , loss =  0.00168897619005
training @ iter = 268000 , error =  0.0
training @ iter = 268100 , loss =  0.00269924639724
training @ iter = 268100 , error =  0.0
training @ iter = 268200 , loss =  0.145591512322
training @ iter = 268200 , error =  0.02
training @ iter = 268300 , loss =  0.00133120908868
training @ iter = 268300 , error =  0.0
training @ iter = 268400 , loss =  0.00902061909437
training @ iter = 268400 , error =  0.0
training @ iter = 268500 , loss =  0.00227364059538
training @ iter = 268500 , error =  0.0
training @ iter = 268600 , loss =  0.00120576191694
training @ iter = 268600 , error =  0.0
training @ iter = 268700 , loss =  0.000855981139466
training @ iter = 268700 , error =  0.0
training @ iter = 268800 , loss =  0.000565816881135
training @ iter = 268800 , error =  0.0
training @ iter = 268900 , loss =  0.0974245145917
training @ iter = 268900 , error =  0.02
training @ iter = 269000 , loss =  0.000669589324389
training @ iter = 269000 , error =  0.0
training @ iter = 269100 , loss =  0.0445234254003
training @ iter = 269100 , error =  0.02
training @ iter = 269200 , loss =  0.0208285525441
training @ iter = 269200 , error =  0.0
training @ iter = 269300 , loss =  0.0179249383509
training @ iter = 269300 , error =  0.02
training @ iter = 269400 , loss =  0.0180870611221
training @ iter = 269400 , error =  0.0
training @ iter = 269500 , loss =  0.00171406683512
training @ iter = 269500 , error =  0.0
training @ iter = 269600 , loss =  0.00627491669729
training @ iter = 269600 , error =  0.0
training @ iter = 269700 , loss =  0.000767378078308
training @ iter = 269700 , error =  0.0
training @ iter = 269800 , loss =  0.000858487095684
training @ iter = 269800 , error =  0.0
training @ iter = 269900 , loss =  0.00349382963032
training @ iter = 269900 , error =  0.0
validation @ iter 270000
epoch 0, iter 270000, train buffer error 0.200000 %
epoch 0, iter 270000, validation loss 0.018523
epoch 0, iter 270000, validation error 0.550000 %
patience before checkBest 330000
Patience =  370000
patience after checkBest 370000
training @ iter = 270000 , loss =  0.0147446524352
training @ iter = 270000 , error =  0.02
training @ iter = 270100 , loss =  0.000657662923913
training @ iter = 270100 , error =  0.0
training @ iter = 270200 , loss =  0.0109827099368
training @ iter = 270200 , error =  0.0
training @ iter = 270300 , loss =  0.000900181708857
training @ iter = 270300 , error =  0.0
training @ iter = 270400 , loss =  0.024827061221
training @ iter = 270400 , error =  0.0
training @ iter = 270500 , loss =  0.00886659976095
training @ iter = 270500 , error =  0.0
--> train minibatch error =  0.14  at iter  270590
-->  23 31900 chunk_8_50000.pkl
training @ iter = 270600 , loss =  0.00912435725331
training @ iter = 270600 , error =  0.0
training @ iter = 270700 , loss =  0.00451202597469
training @ iter = 270700 , error =  0.0
training @ iter = 270800 , loss =  0.0179088953882
training @ iter = 270800 , error =  0.02
training @ iter = 270900 , loss =  0.0026362540666
training @ iter = 270900 , error =  0.0
training @ iter = 271000 , loss =  0.0194123797119
training @ iter = 271000 , error =  0.0
training @ iter = 271100 , loss =  0.00177313538734
training @ iter = 271100 , error =  0.0
training @ iter = 271200 , loss =  0.00268863793463
training @ iter = 271200 , error =  0.0
training @ iter = 271300 , loss =  0.000938883633353
training @ iter = 271300 , error =  0.0
training @ iter = 271400 , loss =  0.0043993871659
training @ iter = 271400 , error =  0.02
training @ iter = 271500 , loss =  0.00403300393373
training @ iter = 271500 , error =  0.0
training @ iter = 271600 , loss =  0.0063382871449
training @ iter = 271600 , error =  0.0
--> train minibatch error =  0.24  at iter  271646
-->  24 34700 chunk_9_50000.pkl
--> train minibatch error =  0.2  at iter  271647
-->  24 34750 chunk_9_50000.pkl
training @ iter = 271700 , loss =  0.0468140281737
training @ iter = 271700 , error =  0.02
training @ iter = 271800 , loss =  0.0310936477035
training @ iter = 271800 , error =  0.0
training @ iter = 271900 , loss =  0.000507736520376
training @ iter = 271900 , error =  0.0
Epoch  11 , iteration  271953 training @ iter = 272000 , loss =  0.00952502619475
training @ iter = 272000 , error =  0.0
training @ iter = 272100 , loss =  0.00579382898286
training @ iter = 272100 , error =  0.0
training @ iter = 272200 , loss =  0.00401760870591
training @ iter = 272200 , error =  0.0
training @ iter = 272300 , loss =  0.00117089564446
training @ iter = 272300 , error =  0.0
training @ iter = 272400 , loss =  0.0030233419966
training @ iter = 272400 , error =  0.0
training @ iter = 272500 , loss =  0.000995463458821
training @ iter = 272500 , error =  0.0
--> train minibatch error =  0.12  at iter  272533
-->  0 29050 chunk_10_50000.pkl
training @ iter = 272600 , loss =  0.0142125794664
training @ iter = 272600 , error =  0.02
training @ iter = 272700 , loss =  0.000986742554232
training @ iter = 272700 , error =  0.0
training @ iter = 272800 , loss =  0.00802524667233
training @ iter = 272800 , error =  0.0
training @ iter = 272900 , loss =  0.000561869121157
training @ iter = 272900 , error =  0.0
training @ iter = 273000 , loss =  0.00199490971863
training @ iter = 273000 , error =  0.0
training @ iter = 273100 , loss =  0.00246062432416
training @ iter = 273100 , error =  0.0
training @ iter = 273200 , loss =  0.0120730903
training @ iter = 273200 , error =  0.0
training @ iter = 273300 , loss =  0.0904161632061
training @ iter = 273300 , error =  0.02
training @ iter = 273400 , loss =  0.00191952765454
training @ iter = 273400 , error =  0.0
training @ iter = 273500 , loss =  0.00681085512042
training @ iter = 273500 , error =  0.0
training @ iter = 273600 , loss =  0.0240648537874
training @ iter = 273600 , error =  0.02
training @ iter = 273700 , loss =  0.00202565919608
training @ iter = 273700 , error =  0.0
training @ iter = 273800 , loss =  0.0010047480464
training @ iter = 273800 , error =  0.0
training @ iter = 273900 , loss =  0.016473190859
training @ iter = 273900 , error =  0.0
training @ iter = 274000 , loss =  0.000627440458629
training @ iter = 274000 , error =  0.0
training @ iter = 274100 , loss =  0.0359001383185
training @ iter = 274100 , error =  0.02
training @ iter = 274200 , loss =  0.00229057972319
training @ iter = 274200 , error =  0.0
training @ iter = 274300 , loss =  0.0148724326864
training @ iter = 274300 , error =  0.02
training @ iter = 274400 , loss =  0.000885765010025
training @ iter = 274400 , error =  0.0
training @ iter = 274500 , loss =  0.0014882737305
training @ iter = 274500 , error =  0.0
training @ iter = 274600 , loss =  0.00169562967494
training @ iter = 274600 , error =  0.0
training @ iter = 274700 , loss =  0.00113598722965
training @ iter = 274700 , error =  0.0
training @ iter = 274800 , loss =  0.0954298377037
training @ iter = 274800 , error =  0.02
training @ iter = 274900 , loss =  0.0864369422197
training @ iter = 274900 , error =  0.02
Saving @ iter  275000
training @ iter = 275000 , loss =  0.000539900211152
training @ iter = 275000 , error =  0.0
training @ iter = 275100 , loss =  0.0106135308743
training @ iter = 275100 , error =  0.0
training @ iter = 275200 , loss =  0.00220141373575
training @ iter = 275200 , error =  0.0
training @ iter = 275300 , loss =  0.0135495271534
training @ iter = 275300 , error =  0.0
training @ iter = 275400 , loss =  0.00195793458261
training @ iter = 275400 , error =  0.0
training @ iter = 275500 , loss =  0.0202734470367
training @ iter = 275500 , error =  0.02
training @ iter = 275600 , loss =  0.00254799961112
training @ iter = 275600 , error =  0.0
training @ iter = 275700 , loss =  0.0167070105672
training @ iter = 275700 , error =  0.0
training @ iter = 275800 , loss =  0.00443621864542
training @ iter = 275800 , error =  0.0
training @ iter = 275900 , loss =  0.00210435711779
training @ iter = 275900 , error =  0.0
training @ iter = 276000 , loss =  0.0659716650844
training @ iter = 276000 , error =  0.02
training @ iter = 276100 , loss =  0.000923995976336
training @ iter = 276100 , error =  0.0
training @ iter = 276200 , loss =  0.00573362363502
training @ iter = 276200 , error =  0.0
training @ iter = 276300 , loss =  0.00745813408867
training @ iter = 276300 , error =  0.0
training @ iter = 276400 , loss =  0.0250291116536
training @ iter = 276400 , error =  0.0
training @ iter = 276500 , loss =  0.00722219096497
training @ iter = 276500 , error =  0.0
training @ iter = 276600 , loss =  0.0239148922265
training @ iter = 276600 , error =  0.02
training @ iter = 276700 , loss =  0.000855299178511
training @ iter = 276700 , error =  0.0
training @ iter = 276800 , loss =  0.0445841252804
training @ iter = 276800 , error =  0.0
training @ iter = 276900 , loss =  0.000663552898914
training @ iter = 276900 , error =  0.0
training @ iter = 277000 , loss =  0.00290041649714
training @ iter = 277000 , error =  0.0
training @ iter = 277100 , loss =  0.0181662030518
training @ iter = 277100 , error =  0.0
training @ iter = 277200 , loss =  0.139342039824
training @ iter = 277200 , error =  0.04
training @ iter = 277300 , loss =  0.000297800754197
training @ iter = 277300 , error =  0.0
training @ iter = 277400 , loss =  0.00477709621191
training @ iter = 277400 , error =  0.0
training @ iter = 277500 , loss =  0.00063910492463
training @ iter = 277500 , error =  0.0
training @ iter = 277600 , loss =  0.0769331678748
training @ iter = 277600 , error =  0.02
training @ iter = 277700 , loss =  0.00118568807375
training @ iter = 277700 , error =  0.0
training @ iter = 277800 , loss =  0.0447623431683
training @ iter = 277800 , error =  0.0
training @ iter = 277900 , loss =  0.00185448711272
training @ iter = 277900 , error =  0.0
training @ iter = 278000 , loss =  0.00452788872644
training @ iter = 278000 , error =  0.0
training @ iter = 278100 , loss =  0.0153395440429
training @ iter = 278100 , error =  0.02
training @ iter = 278200 , loss =  0.00123024964705
training @ iter = 278200 , error =  0.0
training @ iter = 278300 , loss =  0.0239509418607
training @ iter = 278300 , error =  0.02
training @ iter = 278400 , loss =  0.00559589313343
training @ iter = 278400 , error =  0.0
training @ iter = 278500 , loss =  0.0676325783134
training @ iter = 278500 , error =  0.02
training @ iter = 278600 , loss =  0.00109696818981
training @ iter = 278600 , error =  0.0
training @ iter = 278700 , loss =  0.00385757512413
training @ iter = 278700 , error =  0.0
training @ iter = 278800 , loss =  0.000740156276152
training @ iter = 278800 , error =  0.0
training @ iter = 278900 , loss =  0.00355951394886
training @ iter = 278900 , error =  0.0
training @ iter = 279000 , loss =  0.00417458731681
training @ iter = 279000 , error =  0.0
training @ iter = 279100 , loss =  0.0432321578264
training @ iter = 279100 , error =  0.02
training @ iter = 279200 , loss =  0.00491649331525
training @ iter = 279200 , error =  0.0
training @ iter = 279300 , loss =  0.000883568252902
training @ iter = 279300 , error =  0.0
training @ iter = 279400 , loss =  0.000405807630159
training @ iter = 279400 , error =  0.0
training @ iter = 279500 , loss =  0.00121630355716
training @ iter = 279500 , error =  0.0
training @ iter = 279600 , loss =  0.00231451983564
training @ iter = 279600 , error =  0.0
--> train minibatch error =  0.18  at iter  279619
-->  7 33350 chunk_17_50000.pkl
training @ iter = 279700 , loss =  0.00099383876659
training @ iter = 279700 , error =  0.0
training @ iter = 279800 , loss =  0.00486187916249
training @ iter = 279800 , error =  0.0
training @ iter = 279900 , loss =  0.0178703125566
training @ iter = 279900 , error =  0.0
validation @ iter 280000
epoch 0, iter 280000, train buffer error 0.400000 %
epoch 0, iter 280000, validation loss 0.018586
epoch 0, iter 280000, validation error 0.579000 %
patience before checkBest 370000
patience after checkBest 370000
training @ iter = 280000 , loss =  0.00272135739215
training @ iter = 280000 , error =  0.0
--> train minibatch error =  0.12  at iter  280047
-->  8 4750 chunk_18_50000.pkl
training @ iter = 280100 , loss =  0.00204521487467
training @ iter = 280100 , error =  0.0
training @ iter = 280200 , loss =  0.0195061191916
training @ iter = 280200 , error =  0.0
training @ iter = 280300 , loss =  0.00354055454955
training @ iter = 280300 , error =  0.0
training @ iter = 280400 , loss =  0.0178430806845
training @ iter = 280400 , error =  0.02
training @ iter = 280500 , loss =  0.00172394455876
training @ iter = 280500 , error =  0.0
--> train minibatch error =  0.22  at iter  280559
-->  8 30350 chunk_18_50000.pkl
training @ iter = 280600 , loss =  0.0106176864356
training @ iter = 280600 , error =  0.0
--> train minibatch error =  0.12  at iter  280624
-->  8 33600 chunk_18_50000.pkl
training @ iter = 280700 , loss =  0.0117814671248
training @ iter = 280700 , error =  0.0
training @ iter = 280800 , loss =  0.000875513826031
training @ iter = 280800 , error =  0.0
training @ iter = 280900 , loss =  0.0168488547206
training @ iter = 280900 , error =  0.0
training @ iter = 281000 , loss =  0.0109424516559
training @ iter = 281000 , error =  0.0
training @ iter = 281100 , loss =  0.00305123697035
training @ iter = 281100 , error =  0.0
training @ iter = 281200 , loss =  0.000600115570705
training @ iter = 281200 , error =  0.0
training @ iter = 281300 , loss =  0.00513905938715
training @ iter = 281300 , error =  0.0
training @ iter = 281400 , loss =  0.00260294345208
training @ iter = 281400 , error =  0.0
training @ iter = 281500 , loss =  0.0243307724595
training @ iter = 281500 , error =  0.0
training @ iter = 281600 , loss =  0.0137078929693
training @ iter = 281600 , error =  0.0
training @ iter = 281700 , loss =  0.0022866842337
training @ iter = 281700 , error =  0.0
training @ iter = 281800 , loss =  0.00107795128133
training @ iter = 281800 , error =  0.0
training @ iter = 281900 , loss =  0.00157893600408
training @ iter = 281900 , error =  0.0
training @ iter = 282000 , loss =  0.199791431427
training @ iter = 282000 , error =  0.06
training @ iter = 282100 , loss =  0.0455244556069
training @ iter = 282100 , error =  0.02
--> train minibatch error =  0.18  at iter  282134
-->  10 9100 chunk_20_50000.pkl
training @ iter = 282200 , loss =  0.00658564968035
training @ iter = 282200 , error =  0.0
--> train minibatch error =  0.12  at iter  282286
-->  10 16700 chunk_20_50000.pkl
training @ iter = 282300 , loss =  0.139208570123
training @ iter = 282300 , error =  0.02
training @ iter = 282400 , loss =  0.00220117811114
training @ iter = 282400 , error =  0.0
training @ iter = 282500 , loss =  0.00458378251642
training @ iter = 282500 , error =  0.0
training @ iter = 282600 , loss =  0.152592152357
training @ iter = 282600 , error =  0.02
training @ iter = 282700 , loss =  0.00649151392281
training @ iter = 282700 , error =  0.0
training @ iter = 282800 , loss =  0.00295813172124
training @ iter = 282800 , error =  0.0
training @ iter = 282900 , loss =  0.0146970180795
training @ iter = 282900 , error =  0.0
training @ iter = 283000 , loss =  0.00722172064707
training @ iter = 283000 , error =  0.0
training @ iter = 283100 , loss =  0.00182274216786
training @ iter = 283100 , error =  0.0
training @ iter = 283200 , loss =  0.041647054255
training @ iter = 283200 , error =  0.04
training @ iter = 283300 , loss =  0.00246500154026
training @ iter = 283300 , error =  0.0
training @ iter = 283400 , loss =  0.000500880531035
training @ iter = 283400 , error =  0.0
training @ iter = 283500 , loss =  0.000752526219003
training @ iter = 283500 , error =  0.0
--> train minibatch error =  0.12  at iter  283555
-->  11 30150 chunk_21_50000.pkl
training @ iter = 283600 , loss =  0.00698525784537
training @ iter = 283600 , error =  0.0
training @ iter = 283700 , loss =  0.0375704392791
training @ iter = 283700 , error =  0.02
training @ iter = 283800 , loss =  0.00418345909566
training @ iter = 283800 , error =  0.0
training @ iter = 283900 , loss =  0.0206242371351
training @ iter = 283900 , error =  0.0
training @ iter = 284000 , loss =  0.000359810597729
training @ iter = 284000 , error =  0.0
training @ iter = 284100 , loss =  0.00226529408246
training @ iter = 284100 , error =  0.0
training @ iter = 284200 , loss =  0.0102439066395
training @ iter = 284200 , error =  0.0
training @ iter = 284300 , loss =  0.0097739007324
training @ iter = 284300 , error =  0.0
training @ iter = 284400 , loss =  0.00655527133495
training @ iter = 284400 , error =  0.0
training @ iter = 284500 , loss =  0.00509726721793
training @ iter = 284500 , error =  0.0
training @ iter = 284600 , loss =  0.00343053392135
training @ iter = 284600 , error =  0.0
training @ iter = 284700 , loss =  0.0125590432435
training @ iter = 284700 , error =  0.0
training @ iter = 284800 , loss =  0.00528078433126
training @ iter = 284800 , error =  0.0
training @ iter = 284900 , loss =  0.0080219488591
training @ iter = 284900 , error =  0.0
training @ iter = 285000 , loss =  0.0164562575519
training @ iter = 285000 , error =  0.0
training @ iter = 285100 , loss =  0.0051083327271
training @ iter = 285100 , error =  0.0
--> train minibatch error =  0.14  at iter  285148
-->  13 9800 chunk_23_50000.pkl
training @ iter = 285200 , loss =  0.143913418055
training @ iter = 285200 , error =  0.02
training @ iter = 285300 , loss =  0.00924106128514
training @ iter = 285300 , error =  0.0
training @ iter = 285400 , loss =  0.00486352527514
training @ iter = 285400 , error =  0.0
training @ iter = 285500 , loss =  0.00452244980261
training @ iter = 285500 , error =  0.0
training @ iter = 285600 , loss =  0.0046787573956
training @ iter = 285600 , error =  0.0
training @ iter = 285700 , loss =  0.00841800589114
training @ iter = 285700 , error =  0.0
training @ iter = 285800 , loss =  0.00101345824078
training @ iter = 285800 , error =  0.0
training @ iter = 285900 , loss =  0.0296371504664
training @ iter = 285900 , error =  0.02
training @ iter = 286000 , loss =  0.000911243492737
training @ iter = 286000 , error =  0.0
training @ iter = 286100 , loss =  0.0126410536468
training @ iter = 286100 , error =  0.0
training @ iter = 286200 , loss =  0.0217405129224
training @ iter = 286200 , error =  0.0
training @ iter = 286300 , loss =  0.00472852261737
training @ iter = 286300 , error =  0.0
training @ iter = 286400 , loss =  0.00556175457314
training @ iter = 286400 , error =  0.0
training @ iter = 286500 , loss =  0.00559628708288
training @ iter = 286500 , error =  0.0
training @ iter = 286600 , loss =  0.0263330955058
training @ iter = 286600 , error =  0.0
training @ iter = 286700 , loss =  0.00489332154393
training @ iter = 286700 , error =  0.0
training @ iter = 286800 , loss =  0.00669373990968
training @ iter = 286800 , error =  0.0
training @ iter = 286900 , loss =  0.00204932969064
training @ iter = 286900 , error =  0.0
training @ iter = 287000 , loss =  0.00249615497887
training @ iter = 287000 , error =  0.0
training @ iter = 287100 , loss =  0.0169679224491
training @ iter = 287100 , error =  0.02
training @ iter = 287200 , loss =  0.00207659555599
training @ iter = 287200 , error =  0.0
training @ iter = 287300 , loss =  0.0497985109687
training @ iter = 287300 , error =  0.0
training @ iter = 287400 , loss =  0.0086202211678
training @ iter = 287400 , error =  0.0
training @ iter = 287500 , loss =  0.0118264164776
training @ iter = 287500 , error =  0.0
training @ iter = 287600 , loss =  0.00279754516669
training @ iter = 287600 , error =  0.0
training @ iter = 287700 , loss =  0.000661531521473
training @ iter = 287700 , error =  0.0
training @ iter = 287800 , loss =  0.00126110133715
training @ iter = 287800 , error =  0.0
training @ iter = 287900 , loss =  0.0050867353566
training @ iter = 287900 , error =  0.0
training @ iter = 288000 , loss =  0.0067589962855
training @ iter = 288000 , error =  0.0
training @ iter = 288100 , loss =  0.106542609632
training @ iter = 288100 , error =  0.02
training @ iter = 288200 , loss =  0.00116397161037
training @ iter = 288200 , error =  0.0
training @ iter = 288300 , loss =  0.00400523515418
training @ iter = 288300 , error =  0.0
training @ iter = 288400 , loss =  0.00952975824475
training @ iter = 288400 , error =  0.0
training @ iter = 288500 , loss =  0.00368052371778
training @ iter = 288500 , error =  0.0
training @ iter = 288600 , loss =  0.0567139871418
training @ iter = 288600 , error =  0.04
training @ iter = 288700 , loss =  0.0396324805915
training @ iter = 288700 , error =  0.02
training @ iter = 288800 , loss =  0.00104650796857
training @ iter = 288800 , error =  0.0
training @ iter = 288900 , loss =  0.00606377888471
training @ iter = 288900 , error =  0.0
--> train minibatch error =  0.14  at iter  288940
-->  16 49400 chunk_26_50000.pkl
training @ iter = 289000 , loss =  0.0175546053797
training @ iter = 289000 , error =  0.0
training @ iter = 289100 , loss =  0.00266950600781
training @ iter = 289100 , error =  0.0
training @ iter = 289200 , loss =  0.00793316122144
training @ iter = 289200 , error =  0.0
training @ iter = 289300 , loss =  0.0018615371082
training @ iter = 289300 , error =  0.0
training @ iter = 289400 , loss =  0.146579071879
training @ iter = 289400 , error =  0.04
training @ iter = 289500 , loss =  0.00542361428961
training @ iter = 289500 , error =  0.0
training @ iter = 289600 , loss =  0.0353875905275
training @ iter = 289600 , error =  0.02
training @ iter = 289700 , loss =  0.0135824056342
training @ iter = 289700 , error =  0.02
training @ iter = 289800 , loss =  0.00983088370413
training @ iter = 289800 , error =  0.0
training @ iter = 289900 , loss =  0.0667144283652
training @ iter = 289900 , error =  0.02
validation @ iter 290000
epoch 0, iter 290000, train buffer error 0.200000 %
epoch 0, iter 290000, validation loss 0.019089
epoch 0, iter 290000, validation error 0.586000 %
patience before checkBest 370000
patience after checkBest 370000
training @ iter = 290000 , loss =  0.1544585675
training @ iter = 290000 , error =  0.04
training @ iter = 290100 , loss =  0.0853135883808
training @ iter = 290100 , error =  0.02
training @ iter = 290200 , loss =  0.00208132108673
training @ iter = 290200 , error =  0.0
training @ iter = 290300 , loss =  0.00150588573888
training @ iter = 290300 , error =  0.0
training @ iter = 290400 , loss =  0.00638901256025
training @ iter = 290400 , error =  0.0
training @ iter = 290500 , loss =  0.00137531012297
training @ iter = 290500 , error =  0.0
training @ iter = 290600 , loss =  0.0015147269005
training @ iter = 290600 , error =  0.0
ERROR:  /home/shared/Fields_12-2015/chunks_feat_50000/chunks_train/chunk_28_50000.pkl  has  4  candidates.
training @ iter = 290700 , loss =  0.00158370879944
training @ iter = 290700 , error =  0.0
training @ iter = 290800 , loss =  0.144193917513
training @ iter = 290800 , error =  0.06
training @ iter = 290900 , loss =  0.00200697500259
training @ iter = 290900 , error =  0.0
training @ iter = 291000 , loss =  0.0273540113121
training @ iter = 291000 , error =  0.02
training @ iter = 291100 , loss =  0.00103045988362
training @ iter = 291100 , error =  0.0
training @ iter = 291200 , loss =  0.00750874681398
training @ iter = 291200 , error =  0.0
training @ iter = 291300 , loss =  0.0005418639048
training @ iter = 291300 , error =  0.0
training @ iter = 291400 , loss =  0.0271579511464
training @ iter = 291400 , error =  0.02
training @ iter = 291500 , loss =  0.00143038213719
training @ iter = 291500 , error =  0.0
training @ iter = 291600 , loss =  0.0037066875957
training @ iter = 291600 , error =  0.0
training @ iter = 291700 , loss =  0.00793310906738
training @ iter = 291700 , error =  0.0
--> train minibatch error =  0.24  at iter  291793
-->  20 5900 chunk_5_50000.pkl
--> train minibatch error =  0.16  at iter  291794
-->  20 5950 chunk_5_50000.pkl
training @ iter = 291800 , loss =  0.0925658494234
training @ iter = 291800 , error =  0.02
training @ iter = 291900 , loss =  0.00832821149379
training @ iter = 291900 , error =  0.0
training @ iter = 292000 , loss =  0.069569028914
training @ iter = 292000 , error =  0.02
training @ iter = 292100 , loss =  0.00585657404736
training @ iter = 292100 , error =  0.0
training @ iter = 292200 , loss =  0.00310092838481
training @ iter = 292200 , error =  0.0
training @ iter = 292300 , loss =  0.00646147551015
training @ iter = 292300 , error =  0.0
training @ iter = 292400 , loss =  0.0848381221294
training @ iter = 292400 , error =  0.02
training @ iter = 292500 , loss =  0.0482651516795
training @ iter = 292500 , error =  0.0
training @ iter = 292600 , loss =  0.000563324603718
training @ iter = 292600 , error =  0.0
training @ iter = 292700 , loss =  0.00133978319354
training @ iter = 292700 , error =  0.0
--> train minibatch error =  0.12  at iter  292761
-->  21 4300 chunk_6_50000.pkl
training @ iter = 292800 , loss =  0.0830053314567
training @ iter = 292800 , error =  0.04
training @ iter = 292900 , loss =  0.00152430078015
training @ iter = 292900 , error =  0.0
training @ iter = 293000 , loss =  0.00145870621782
training @ iter = 293000 , error =  0.0
training @ iter = 293100 , loss =  0.00220266799442
training @ iter = 293100 , error =  0.0
training @ iter = 293200 , loss =  0.00232721632347
training @ iter = 293200 , error =  0.0
training @ iter = 293300 , loss =  0.00547148426995
training @ iter = 293300 , error =  0.0
training @ iter = 293400 , loss =  0.0198650546372
training @ iter = 293400 , error =  0.0
training @ iter = 293500 , loss =  0.00305023067631
training @ iter = 293500 , error =  0.0
training @ iter = 293600 , loss =  0.00076195015572
training @ iter = 293600 , error =  0.0
training @ iter = 293700 , loss =  0.102087460458
training @ iter = 293700 , error =  0.02
training @ iter = 293800 , loss =  0.00315868668258
training @ iter = 293800 , error =  0.0
training @ iter = 293900 , loss =  0.0241523869336
training @ iter = 293900 , error =  0.0
training @ iter = 294000 , loss =  0.000861258013174
training @ iter = 294000 , error =  0.0
training @ iter = 294100 , loss =  0.00282452255487
training @ iter = 294100 , error =  0.0
training @ iter = 294200 , loss =  0.00140555354301
training @ iter = 294200 , error =  0.0
training @ iter = 294300 , loss =  0.00208164472133
training @ iter = 294300 , error =  0.0
training @ iter = 294400 , loss =  0.0299978610128
training @ iter = 294400 , error =  0.02
training @ iter = 294500 , loss =  0.00161029631272
training @ iter = 294500 , error =  0.0
training @ iter = 294600 , loss =  0.00955370999873
training @ iter = 294600 , error =  0.0
training @ iter = 294700 , loss =  0.00380925531499
training @ iter = 294700 , error =  0.0
training @ iter = 294800 , loss =  0.0325870066881
training @ iter = 294800 , error =  0.02
training @ iter = 294900 , loss =  0.0184107366949
training @ iter = 294900 , error =  0.02
training @ iter = 295000 , loss =  0.00851798802614
training @ iter = 295000 , error =  0.0
training @ iter = 295100 , loss =  0.0102740908042
training @ iter = 295100 , error =  0.0
training @ iter = 295200 , loss =  0.174541220069
training @ iter = 295200 , error =  0.02
training @ iter = 295300 , loss =  0.0066834744066
training @ iter = 295300 , error =  0.0
--> train minibatch error =  0.14  at iter  295313
-->  23 31900 chunk_8_50000.pkl
training @ iter = 295400 , loss =  0.00138262670953
training @ iter = 295400 , error =  0.0
training @ iter = 295500 , loss =  0.0052580726333
training @ iter = 295500 , error =  0.0
training @ iter = 295600 , loss =  0.00558288581669
training @ iter = 295600 , error =  0.0
training @ iter = 295700 , loss =  0.257405877113
training @ iter = 295700 , error =  0.08
training @ iter = 295800 , loss =  0.0763287246227
training @ iter = 295800 , error =  0.02
training @ iter = 295900 , loss =  0.0419261455536
training @ iter = 295900 , error =  0.02
training @ iter = 296000 , loss =  0.000723641365767
training @ iter = 296000 , error =  0.0
training @ iter = 296100 , loss =  0.000602737767622
training @ iter = 296100 , error =  0.0
training @ iter = 296200 , loss =  0.00412128912285
training @ iter = 296200 , error =  0.0
training @ iter = 296300 , loss =  0.000402288278565
training @ iter = 296300 , error =  0.0
--> train minibatch error =  0.24  at iter  296369
-->  24 34700 chunk_9_50000.pkl
--> train minibatch error =  0.18  at iter  296370
-->  24 34750 chunk_9_50000.pkl
training @ iter = 296400 , loss =  0.00695290463045
training @ iter = 296400 , error =  0.0
training @ iter = 296500 , loss =  0.0109472582117
training @ iter = 296500 , error =  0.02
training @ iter = 296600 , loss =  0.00765315815806
training @ iter = 296600 , error =  0.0
Epoch  12 , iteration  296676 training @ iter = 296700 , loss =  0.0332356914878
training @ iter = 296700 , error =  0.02
training @ iter = 296800 , loss =  0.0241314582527
training @ iter = 296800 , error =  0.0
training @ iter = 296900 , loss =  0.0160549264401
training @ iter = 296900 , error =  0.0
training @ iter = 297000 , loss =  0.0500792711973
training @ iter = 297000 , error =  0.02
training @ iter = 297100 , loss =  0.0139469113201
training @ iter = 297100 , error =  0.02
training @ iter = 297200 , loss =  0.00883473269641
training @ iter = 297200 , error =  0.0
training @ iter = 297300 , loss =  0.0657480359077
training @ iter = 297300 , error =  0.02
training @ iter = 297400 , loss =  0.0592618696392
training @ iter = 297400 , error =  0.04
training @ iter = 297500 , loss =  0.0161878000945
training @ iter = 297500 , error =  0.0
training @ iter = 297600 , loss =  0.0123502574861
training @ iter = 297600 , error =  0.0
training @ iter = 297700 , loss =  0.000853530713357
training @ iter = 297700 , error =  0.0
training @ iter = 297800 , loss =  0.000978572992608
training @ iter = 297800 , error =  0.0
training @ iter = 297900 , loss =  0.00776118505746
training @ iter = 297900 , error =  0.0
training @ iter = 298000 , loss =  0.00353071070276
training @ iter = 298000 , error =  0.0
training @ iter = 298100 , loss =  0.00285188644193
training @ iter = 298100 , error =  0.0
training @ iter = 298200 , loss =  0.00377527531236
training @ iter = 298200 , error =  0.0
training @ iter = 298300 , loss =  0.00868594832718
training @ iter = 298300 , error =  0.0
training @ iter = 298400 , loss =  0.000874210731126
training @ iter = 298400 , error =  0.0
training @ iter = 298500 , loss =  0.00252662133425
training @ iter = 298500 , error =  0.0
training @ iter = 298600 , loss =  0.00308188167401
training @ iter = 298600 , error =  0.0
training @ iter = 298700 , loss =  0.0408732183278
training @ iter = 298700 , error =  0.0
training @ iter = 298800 , loss =  0.00588990282267
training @ iter = 298800 , error =  0.0
training @ iter = 298900 , loss =  0.00126187037677
training @ iter = 298900 , error =  0.0
training @ iter = 299000 , loss =  0.00795976817608
training @ iter = 299000 , error =  0.0
training @ iter = 299100 , loss =  0.0416612252593
training @ iter = 299100 , error =  0.02
training @ iter = 299200 , loss =  0.00117084628437
training @ iter = 299200 , error =  0.0
training @ iter = 299300 , loss =  0.000925519911107
training @ iter = 299300 , error =  0.0
training @ iter = 299400 , loss =  0.00983232446015
training @ iter = 299400 , error =  0.0
training @ iter = 299500 , loss =  0.0067843850702
training @ iter = 299500 , error =  0.0
training @ iter = 299600 , loss =  0.059526797384
training @ iter = 299600 , error =  0.02
training @ iter = 299700 , loss =  0.00753384642303
training @ iter = 299700 , error =  0.0
training @ iter = 299800 , loss =  0.0206570867449
training @ iter = 299800 , error =  0.02
training @ iter = 299900 , loss =  0.00735126575455
training @ iter = 299900 , error =  0.0
Saving @ iter  300000
Learning rate:  0.005
validation @ iter 300000
epoch 0, iter 300000, train buffer error 0.200000 %
epoch 0, iter 300000, validation loss 0.018397
epoch 0, iter 300000, validation error 0.555000 %
patience before checkBest 370000
patience after checkBest 370000
training @ iter = 300000 , loss =  0.0028447189834
training @ iter = 300000 , error =  0.0
training @ iter = 300100 , loss =  0.00152297155
training @ iter = 300100 , error =  0.0
training @ iter = 300200 , loss =  0.00579585367814
training @ iter = 300200 , error =  0.0
training @ iter = 300300 , loss =  0.0045330170542
training @ iter = 300300 , error =  0.0
training @ iter = 300400 , loss =  0.000741332478356
training @ iter = 300400 , error =  0.0
training @ iter = 300500 , loss =  0.0102225150913
training @ iter = 300500 , error =  0.0
training @ iter = 300600 , loss =  0.00064532016404
training @ iter = 300600 , error =  0.0
training @ iter = 300700 , loss =  0.0018853652291
training @ iter = 300700 , error =  0.0
training @ iter = 300800 , loss =  0.00141048850492
training @ iter = 300800 , error =  0.0
training @ iter = 300900 , loss =  0.00272347126156
training @ iter = 300900 , error =  0.0
training @ iter = 301000 , loss =  0.0392379611731
training @ iter = 301000 , error =  0.02
training @ iter = 301100 , loss =  0.126010641456
training @ iter = 301100 , error =  0.02
training @ iter = 301200 , loss =  0.0128815080971
training @ iter = 301200 , error =  0.0
training @ iter = 301300 , loss =  0.00291811814532
training @ iter = 301300 , error =  0.0
training @ iter = 301400 , loss =  0.0117867207155
training @ iter = 301400 , error =  0.0
training @ iter = 301500 , loss =  0.0027166204527
training @ iter = 301500 , error =  0.0
training @ iter = 301600 , loss =  0.0134123777971
training @ iter = 301600 , error =  0.02
training @ iter = 301700 , loss =  0.00348776439205
training @ iter = 301700 , error =  0.0
training @ iter = 301800 , loss =  0.00074937735917
training @ iter = 301800 , error =  0.0
training @ iter = 301900 , loss =  0.00167312845588
training @ iter = 301900 , error =  0.0
training @ iter = 302000 , loss =  0.000730963773094
training @ iter = 302000 , error =  0.0
training @ iter = 302100 , loss =  0.00915849767625
training @ iter = 302100 , error =  0.0
training @ iter = 302200 , loss =  0.029795916751
training @ iter = 302200 , error =  0.02
training @ iter = 302300 , loss =  0.0143315196037
training @ iter = 302300 , error =  0.0
training @ iter = 302400 , loss =  0.0338542312384
training @ iter = 302400 , error =  0.02
training @ iter = 302500 , loss =  0.00465758983046
training @ iter = 302500 , error =  0.0
training @ iter = 302600 , loss =  0.0157548636198
training @ iter = 302600 , error =  0.0
training @ iter = 302700 , loss =  0.0678522288799
training @ iter = 302700 , error =  0.02
training @ iter = 302800 , loss =  0.0792071670294
training @ iter = 302800 , error =  0.04
training @ iter = 302900 , loss =  0.00315105775371
training @ iter = 302900 , error =  0.0
training @ iter = 303000 , loss =  0.00291690044105
training @ iter = 303000 , error =  0.0
training @ iter = 303100 , loss =  0.0234681796283
training @ iter = 303100 , error =  0.0
training @ iter = 303200 , loss =  0.00448483694345
training @ iter = 303200 , error =  0.0
training @ iter = 303300 , loss =  0.00108255969826
training @ iter = 303300 , error =  0.0
training @ iter = 303400 , loss =  0.00206889770925
training @ iter = 303400 , error =  0.0
training @ iter = 303500 , loss =  0.0122641799971
training @ iter = 303500 , error =  0.0
training @ iter = 303600 , loss =  0.000645555788651
training @ iter = 303600 , error =  0.0
training @ iter = 303700 , loss =  0.0126401400194
training @ iter = 303700 , error =  0.0
training @ iter = 303800 , loss =  0.0065496917814
training @ iter = 303800 , error =  0.0
training @ iter = 303900 , loss =  0.00215616961941
training @ iter = 303900 , error =  0.0
training @ iter = 304000 , loss =  0.000798978668172
training @ iter = 304000 , error =  0.0
training @ iter = 304100 , loss =  0.00770092615858
training @ iter = 304100 , error =  0.0
training @ iter = 304200 , loss =  0.00043589703273
training @ iter = 304200 , error =  0.0
training @ iter = 304300 , loss =  0.00951835978776
training @ iter = 304300 , error =  0.0
--> train minibatch error =  0.18  at iter  304342
-->  7 33350 chunk_17_50000.pkl
training @ iter = 304400 , loss =  0.000467866135295
training @ iter = 304400 , error =  0.0
training @ iter = 304500 , loss =  0.244215279818
training @ iter = 304500 , error =  0.04
training @ iter = 304600 , loss =  0.0506904236972
training @ iter = 304600 , error =  0.0
training @ iter = 304700 , loss =  0.00115325523075
training @ iter = 304700 , error =  0.0
--> train minibatch error =  0.12  at iter  304770
-->  8 4750 chunk_18_50000.pkl
training @ iter = 304800 , loss =  0.00114091834985
training @ iter = 304800 , error =  0.0
training @ iter = 304900 , loss =  0.00277061201632
training @ iter = 304900 , error =  0.0
training @ iter = 305000 , loss =  0.0541279539466
training @ iter = 305000 , error =  0.02
training @ iter = 305100 , loss =  0.00363451708108
training @ iter = 305100 , error =  0.0
training @ iter = 305200 , loss =  0.00258985813707
training @ iter = 305200 , error =  0.0
--> train minibatch error =  0.24  at iter  305282
-->  8 30350 chunk_18_50000.pkl
training @ iter = 305300 , loss =  0.00745743280277
training @ iter = 305300 , error =  0.0
--> train minibatch error =  0.14  at iter  305347
-->  8 33600 chunk_18_50000.pkl
training @ iter = 305400 , loss =  0.0766312628984
training @ iter = 305400 , error =  0.02
training @ iter = 305500 , loss =  0.0219797901809
training @ iter = 305500 , error =  0.02
training @ iter = 305600 , loss =  0.00142091605812
training @ iter = 305600 , error =  0.0
training @ iter = 305700 , loss =  0.00380386551842
training @ iter = 305700 , error =  0.0
training @ iter = 305800 , loss =  0.00380731932819
training @ iter = 305800 , error =  0.0
training @ iter = 305900 , loss =  0.107784420252
training @ iter = 305900 , error =  0.02
training @ iter = 306000 , loss =  0.0077003268525
training @ iter = 306000 , error =  0.02
training @ iter = 306100 , loss =  0.00220765825361
training @ iter = 306100 , error =  0.0
training @ iter = 306200 , loss =  0.0013737580739
training @ iter = 306200 , error =  0.0
training @ iter = 306300 , loss =  0.00462584476918
training @ iter = 306300 , error =  0.0
training @ iter = 306400 , loss =  0.0256053060293
training @ iter = 306400 , error =  0.02
training @ iter = 306500 , loss =  0.00256297946908
training @ iter = 306500 , error =  0.0
training @ iter = 306600 , loss =  0.00172941118944
training @ iter = 306600 , error =  0.0
training @ iter = 306700 , loss =  0.00694346707314
training @ iter = 306700 , error =  0.0
training @ iter = 306800 , loss =  0.00190728565212
training @ iter = 306800 , error =  0.0
--> train minibatch error =  0.18  at iter  306857
-->  10 9100 chunk_20_50000.pkl
training @ iter = 306900 , loss =  0.00121349992696
training @ iter = 306900 , error =  0.0
training @ iter = 307000 , loss =  0.00239072111435
training @ iter = 307000 , error =  0.0
--> train minibatch error =  0.12  at iter  307009
-->  10 16700 chunk_20_50000.pkl
training @ iter = 307100 , loss =  0.00133283645846
training @ iter = 307100 , error =  0.0
training @ iter = 307200 , loss =  0.0109820393845
training @ iter = 307200 , error =  0.02
training @ iter = 307300 , loss =  0.0263812597841
training @ iter = 307300 , error =  0.0
training @ iter = 307400 , loss =  0.0861247479916
training @ iter = 307400 , error =  0.02
training @ iter = 307500 , loss =  0.00109922292177
training @ iter = 307500 , error =  0.0
training @ iter = 307600 , loss =  0.0019087359542
training @ iter = 307600 , error =  0.0
training @ iter = 307700 , loss =  0.0022522539366
training @ iter = 307700 , error =  0.0
training @ iter = 307800 , loss =  0.00415063416585
training @ iter = 307800 , error =  0.0
training @ iter = 307900 , loss =  0.0736937224865
training @ iter = 307900 , error =  0.04
training @ iter = 308000 , loss =  0.053266543895
training @ iter = 308000 , error =  0.02
training @ iter = 308100 , loss =  0.0626309886575
training @ iter = 308100 , error =  0.02
training @ iter = 308200 , loss =  0.00377765065059
training @ iter = 308200 , error =  0.0
--> train minibatch error =  0.12  at iter  308278
-->  11 30150 chunk_21_50000.pkl
training @ iter = 308300 , loss =  0.0223395545036
training @ iter = 308300 , error =  0.0
training @ iter = 308400 , loss =  0.00151497218758
training @ iter = 308400 , error =  0.0
training @ iter = 308500 , loss =  0.17266690731
training @ iter = 308500 , error =  0.08
training @ iter = 308600 , loss =  0.00125081744045
training @ iter = 308600 , error =  0.0
training @ iter = 308700 , loss =  0.00119228078984
training @ iter = 308700 , error =  0.0
training @ iter = 308800 , loss =  0.0663360059261
training @ iter = 308800 , error =  0.02
training @ iter = 308900 , loss =  0.159699261189
training @ iter = 308900 , error =  0.04
training @ iter = 309000 , loss =  0.0014712678967
training @ iter = 309000 , error =  0.0
training @ iter = 309100 , loss =  0.000735240930226
training @ iter = 309100 , error =  0.0
training @ iter = 309200 , loss =  0.000413886009483
training @ iter = 309200 , error =  0.0
training @ iter = 309300 , loss =  0.00181122857612
training @ iter = 309300 , error =  0.0
training @ iter = 309400 , loss =  0.00100627122447
training @ iter = 309400 , error =  0.0
training @ iter = 309500 , loss =  0.00831271894276
training @ iter = 309500 , error =  0.0
training @ iter = 309600 , loss =  0.00241572060622
training @ iter = 309600 , error =  0.0
training @ iter = 309700 , loss =  0.00161123368889
training @ iter = 309700 , error =  0.0
training @ iter = 309800 , loss =  0.0372712090611
training @ iter = 309800 , error =  0.0
--> train minibatch error =  0.14  at iter  309871
-->  13 9800 chunk_23_50000.pkl
training @ iter = 309900 , loss =  0.00337327364832
training @ iter = 309900 , error =  0.0
validation @ iter 310000
epoch 0, iter 310000, train buffer error 0.200000 %
epoch 0, iter 310000, validation loss 0.018668
epoch 0, iter 310000, validation error 0.567000 %
patience before checkBest 370000
patience after checkBest 370000
training @ iter = 310000 , loss =  0.00207234360278
training @ iter = 310000 , error =  0.0
training @ iter = 310100 , loss =  0.000923324376345
training @ iter = 310100 , error =  0.0
training @ iter = 310200 , loss =  0.00952452141792
training @ iter = 310200 , error =  0.02
training @ iter = 310300 , loss =  0.00644416920841
training @ iter = 310300 , error =  0.0
training @ iter = 310400 , loss =  0.000771446968429
training @ iter = 310400 , error =  0.0
training @ iter = 310500 , loss =  0.00173492822796
training @ iter = 310500 , error =  0.0
training @ iter = 310600 , loss =  0.0176814738661
training @ iter = 310600 , error =  0.0
training @ iter = 310700 , loss =  0.0228902287781
training @ iter = 310700 , error =  0.02
training @ iter = 310800 , loss =  0.0177624933422
training @ iter = 310800 , error =  0.0
training @ iter = 310900 , loss =  0.00133610831108
training @ iter = 310900 , error =  0.0
training @ iter = 311000 , loss =  0.00386762735434
training @ iter = 311000 , error =  0.0
training @ iter = 311100 , loss =  0.000795224506874
training @ iter = 311100 , error =  0.0
training @ iter = 311200 , loss =  0.000992025830783
training @ iter = 311200 , error =  0.0
training @ iter = 311300 , loss =  0.00135697575752
training @ iter = 311300 , error =  0.0
training @ iter = 311400 , loss =  0.00993444770575
training @ iter = 311400 , error =  0.0
training @ iter = 311500 , loss =  0.244781568646
training @ iter = 311500 , error =  0.04
training @ iter = 311600 , loss =  0.00196326733567
training @ iter = 311600 , error =  0.0
training @ iter = 311700 , loss =  0.00949380360544
training @ iter = 311700 , error =  0.0
training @ iter = 311800 , loss =  0.00280775059946
training @ iter = 311800 , error =  0.0
training @ iter = 311900 , loss =  0.00601388979703
training @ iter = 311900 , error =  0.0
training @ iter = 312000 , loss =  0.00158382533118
training @ iter = 312000 , error =  0.0
training @ iter = 312100 , loss =  0.00212634215131
training @ iter = 312100 , error =  0.0
training @ iter = 312200 , loss =  0.00675749778748
training @ iter = 312200 , error =  0.0
training @ iter = 312300 , loss =  0.070618711412
training @ iter = 312300 , error =  0.02
training @ iter = 312400 , loss =  0.0116728618741
training @ iter = 312400 , error =  0.0
training @ iter = 312500 , loss =  0.103589847684
training @ iter = 312500 , error =  0.02
training @ iter = 312600 , loss =  0.00395644269884
training @ iter = 312600 , error =  0.0
training @ iter = 312700 , loss =  0.00866647809744
training @ iter = 312700 , error =  0.0
training @ iter = 312800 , loss =  0.0495634116232
training @ iter = 312800 , error =  0.02
training @ iter = 312900 , loss =  0.0130287734792
training @ iter = 312900 , error =  0.0
training @ iter = 313000 , loss =  0.00136044027749
training @ iter = 313000 , error =  0.0
training @ iter = 313100 , loss =  0.0033394054044
training @ iter = 313100 , error =  0.0
training @ iter = 313200 , loss =  0.010032556951
training @ iter = 313200 , error =  0.0
training @ iter = 313300 , loss =  0.00065420626197
training @ iter = 313300 , error =  0.0
training @ iter = 313400 , loss =  0.0652135238051
training @ iter = 313400 , error =  0.02
training @ iter = 313500 , loss =  0.0122153786942
training @ iter = 313500 , error =  0.0
training @ iter = 313600 , loss =  0.00197050813586
training @ iter = 313600 , error =  0.0
--> train minibatch error =  0.14  at iter  313663
-->  16 49400 chunk_26_50000.pkl
training @ iter = 313700 , loss =  0.000691770459525
training @ iter = 313700 , error =  0.0
training @ iter = 313800 , loss =  0.00149266410153
training @ iter = 313800 , error =  0.0
training @ iter = 313900 , loss =  0.000370184890926
training @ iter = 313900 , error =  0.0
training @ iter = 314000 , loss =  0.00207939441316
training @ iter = 314000 , error =  0.0
training @ iter = 314100 , loss =  0.000559049076401
training @ iter = 314100 , error =  0.0
training @ iter = 314200 , loss =  0.00271938391961
training @ iter = 314200 , error =  0.0
training @ iter = 314300 , loss =  0.00252450606786
training @ iter = 314300 , error =  0.0
training @ iter = 314400 , loss =  0.00389981083572
training @ iter = 314400 , error =  0.0
training @ iter = 314500 , loss =  0.0172259863466
training @ iter = 314500 , error =  0.02
training @ iter = 314600 , loss =  0.00225018616766
training @ iter = 314600 , error =  0.0
training @ iter = 314700 , loss =  0.0817363634706
training @ iter = 314700 , error =  0.02
training @ iter = 314800 , loss =  0.228158414364
training @ iter = 314800 , error =  0.04
training @ iter = 314900 , loss =  0.0137789966539
training @ iter = 314900 , error =  0.0
training @ iter = 315000 , loss =  0.03684373945
training @ iter = 315000 , error =  0.0
training @ iter = 315100 , loss =  0.129831433296
training @ iter = 315100 , error =  0.04
training @ iter = 315200 , loss =  0.00926502794027
training @ iter = 315200 , error =  0.0
training @ iter = 315300 , loss =  0.029455255717
training @ iter = 315300 , error =  0.0
ERROR:  /home/shared/Fields_12-2015/chunks_feat_50000/chunks_train/chunk_28_50000.pkl  has  4  candidates.
training @ iter = 315400 , loss =  0.0132334781811
training @ iter = 315400 , error =  0.0
training @ iter = 315500 , loss =  0.00654031522572
training @ iter = 315500 , error =  0.0
training @ iter = 315600 , loss =  0.00108959968202
training @ iter = 315600 , error =  0.0
training @ iter = 315700 , loss =  0.00075370608829
training @ iter = 315700 , error =  0.0
training @ iter = 315800 , loss =  0.00122392550111
training @ iter = 315800 , error =  0.0
training @ iter = 315900 , loss =  0.000653664756101
training @ iter = 315900 , error =  0.0
training @ iter = 316000 , loss =  0.0216351430863
training @ iter = 316000 , error =  0.0
training @ iter = 316100 , loss =  0.00100460741669
training @ iter = 316100 , error =  0.0
training @ iter = 316200 , loss =  0.00118985259905
training @ iter = 316200 , error =  0.0
training @ iter = 316300 , loss =  0.00441495701671
training @ iter = 316300 , error =  0.0
training @ iter = 316400 , loss =  0.00323209771886
training @ iter = 316400 , error =  0.0
training @ iter = 316500 , loss =  0.0252779610455
training @ iter = 316500 , error =  0.02
--> train minibatch error =  0.26  at iter  316516
-->  20 5900 chunk_5_50000.pkl
--> train minibatch error =  0.16  at iter  316517
-->  20 5950 chunk_5_50000.pkl
training @ iter = 316600 , loss =  0.00599728524685
training @ iter = 316600 , error =  0.0
training @ iter = 316700 , loss =  0.00569589715451
training @ iter = 316700 , error =  0.0
training @ iter = 316800 , loss =  0.0279784947634
training @ iter = 316800 , error =  0.0
training @ iter = 316900 , loss =  0.0234398432076
training @ iter = 316900 , error =  0.02
training @ iter = 317000 , loss =  0.00337837915868
training @ iter = 317000 , error =  0.0
training @ iter = 317100 , loss =  0.244191229343
training @ iter = 317100 , error =  0.04
training @ iter = 317200 , loss =  0.000698293733876
training @ iter = 317200 , error =  0.0
training @ iter = 317300 , loss =  0.00815256033093
training @ iter = 317300 , error =  0.0
training @ iter = 317400 , loss =  0.0117836650461
training @ iter = 317400 , error =  0.0
training @ iter = 317500 , loss =  0.0180091112852
training @ iter = 317500 , error =  0.0
training @ iter = 317600 , loss =  0.00875098258257
training @ iter = 317600 , error =  0.0
training @ iter = 317700 , loss =  0.0261553283781
training @ iter = 317700 , error =  0.02
training @ iter = 317800 , loss =  0.010388603434
training @ iter = 317800 , error =  0.0
training @ iter = 317900 , loss =  0.0338368602097
training @ iter = 317900 , error =  0.02
training @ iter = 318000 , loss =  0.00553698884323
training @ iter = 318000 , error =  0.0
training @ iter = 318100 , loss =  0.0028873803094
training @ iter = 318100 , error =  0.0
training @ iter = 318200 , loss =  0.00143098994158
training @ iter = 318200 , error =  0.0
training @ iter = 318300 , loss =  0.00195208366495
training @ iter = 318300 , error =  0.0
training @ iter = 318400 , loss =  0.00574769312516
training @ iter = 318400 , error =  0.0
training @ iter = 318500 , loss =  0.00122050056234
training @ iter = 318500 , error =  0.0
training @ iter = 318600 , loss =  0.0063731498085
training @ iter = 318600 , error =  0.0
training @ iter = 318700 , loss =  0.0203333441168
training @ iter = 318700 , error =  0.02
training @ iter = 318800 , loss =  0.12894949317
training @ iter = 318800 , error =  0.02
training @ iter = 318900 , loss =  0.00219187280163
training @ iter = 318900 , error =  0.0
training @ iter = 319000 , loss =  0.00556511990726
training @ iter = 319000 , error =  0.0
--> train minibatch error =  0.12  at iter  319017
-->  22 30950 chunk_7_50000.pkl
training @ iter = 319100 , loss =  0.0146650709212
training @ iter = 319100 , error =  0.0
training @ iter = 319200 , loss =  0.000374169641873
training @ iter = 319200 , error =  0.0
training @ iter = 319300 , loss =  0.00284395646304
training @ iter = 319300 , error =  0.0
training @ iter = 319400 , loss =  0.0855273455381
training @ iter = 319400 , error =  0.06
training @ iter = 319500 , loss =  0.00459438748658
training @ iter = 319500 , error =  0.0
training @ iter = 319600 , loss =  0.00160407787189
training @ iter = 319600 , error =  0.0
training @ iter = 319700 , loss =  0.00218355469406
training @ iter = 319700 , error =  0.0
training @ iter = 319800 , loss =  0.000522449612617
training @ iter = 319800 , error =  0.0
training @ iter = 319900 , loss =  0.0276456326246
training @ iter = 319900 , error =  0.02
validation @ iter 320000
epoch 0, iter 320000, train buffer error 0.400000 %
epoch 0, iter 320000, validation loss 0.018042
epoch 0, iter 320000, validation error 0.552000 %
patience before checkBest 370000
patience after checkBest 370000
training @ iter = 320000 , loss =  0.00184848764911
training @ iter = 320000 , error =  0.0
--> train minibatch error =  0.14  at iter  320036
-->  23 31900 chunk_8_50000.pkl
training @ iter = 320100 , loss =  0.000964477309026
training @ iter = 320100 , error =  0.0
training @ iter = 320200 , loss =  0.00097921746783
training @ iter = 320200 , error =  0.0
training @ iter = 320300 , loss =  0.0249834638089
training @ iter = 320300 , error =  0.02
training @ iter = 320400 , loss =  0.0218027085066
training @ iter = 320400 , error =  0.02
training @ iter = 320500 , loss =  0.0704967975616
training @ iter = 320500 , error =  0.02
training @ iter = 320600 , loss =  0.000392986316001
training @ iter = 320600 , error =  0.0
training @ iter = 320700 , loss =  0.00227387854829
training @ iter = 320700 , error =  0.0
training @ iter = 320800 , loss =  0.00508663104847
training @ iter = 320800 , error =  0.0
training @ iter = 320900 , loss =  0.00201574293897
training @ iter = 320900 , error =  0.0
training @ iter = 321000 , loss =  0.000962696969509
training @ iter = 321000 , error =  0.0
--> train minibatch error =  0.2  at iter  321092
-->  24 34700 chunk_9_50000.pkl
--> train minibatch error =  0.2  at iter  321093
-->  24 34750 chunk_9_50000.pkl
training @ iter = 321100 , loss =  0.00850898399949
training @ iter = 321100 , error =  0.0
training @ iter = 321200 , loss =  0.0092392982915
training @ iter = 321200 , error =  0.0
training @ iter = 321300 , loss =  0.0352623090148
training @ iter = 321300 , error =  0.02
Epoch  13 , iteration  321399 training @ iter = 321400 , loss =  0.00134918896947
training @ iter = 321400 , error =  0.0
training @ iter = 321500 , loss =  0.00218359916471
training @ iter = 321500 , error =  0.0
training @ iter = 321600 , loss =  0.00849867612123
training @ iter = 321600 , error =  0.0
training @ iter = 321700 , loss =  0.00898525398225
training @ iter = 321700 , error =  0.0
training @ iter = 321800 , loss =  0.00124928820878
training @ iter = 321800 , error =  0.0
training @ iter = 321900 , loss =  0.0326758474112
training @ iter = 321900 , error =  0.0
training @ iter = 322000 , loss =  0.00125480501447
training @ iter = 322000 , error =  0.0
training @ iter = 322100 , loss =  0.00114465423394
training @ iter = 322100 , error =  0.0
training @ iter = 322200 , loss =  0.00741535844281
training @ iter = 322200 , error =  0.0
training @ iter = 322300 , loss =  0.00100979965646
training @ iter = 322300 , error =  0.0
training @ iter = 322400 , loss =  0.00306024681777
training @ iter = 322400 , error =  0.0
training @ iter = 322500 , loss =  0.00146329135168
training @ iter = 322500 , error =  0.0
training @ iter = 322600 , loss =  0.00103803176899
training @ iter = 322600 , error =  0.0
training @ iter = 322700 , loss =  0.00107554870192
training @ iter = 322700 , error =  0.0
training @ iter = 322800 , loss =  0.00531097967178
training @ iter = 322800 , error =  0.0
training @ iter = 322900 , loss =  0.00813324470073
training @ iter = 322900 , error =  0.0
training @ iter = 323000 , loss =  0.0123929195106
training @ iter = 323000 , error =  0.0
training @ iter = 323100 , loss =  0.00790639873594
training @ iter = 323100 , error =  0.0
training @ iter = 323200 , loss =  0.00649539474398
training @ iter = 323200 , error =  0.0
training @ iter = 323300 , loss =  0.055174741894
training @ iter = 323300 , error =  0.02
training @ iter = 323400 , loss =  0.0348412692547
training @ iter = 323400 , error =  0.02
training @ iter = 323500 , loss =  0.0011076402152
training @ iter = 323500 , error =  0.0
training @ iter = 323600 , loss =  0.004086160101
training @ iter = 323600 , error =  0.0
training @ iter = 323700 , loss =  0.00203682202846
training @ iter = 323700 , error =  0.0
training @ iter = 323800 , loss =  0.000637873250525
training @ iter = 323800 , error =  0.0
training @ iter = 323900 , loss =  0.000733118969947
training @ iter = 323900 , error =  0.0
training @ iter = 324000 , loss =  0.0339626371861
training @ iter = 324000 , error =  0.02
training @ iter = 324100 , loss =  0.00144387315959
training @ iter = 324100 , error =  0.0
training @ iter = 324200 , loss =  0.00180294329766
training @ iter = 324200 , error =  0.0
training @ iter = 324300 , loss =  0.0149920415133
training @ iter = 324300 , error =  0.0
training @ iter = 324400 , loss =  0.0331887193024
training @ iter = 324400 , error =  0.02
training @ iter = 324500 , loss =  0.0017178527778
training @ iter = 324500 , error =  0.0
training @ iter = 324600 , loss =  0.00892232079059
training @ iter = 324600 , error =  0.0
training @ iter = 324700 , loss =  0.112635679543
training @ iter = 324700 , error =  0.02
training @ iter = 324800 , loss =  0.00185635266826
training @ iter = 324800 , error =  0.0
training @ iter = 324900 , loss =  0.00591776007786
training @ iter = 324900 , error =  0.0
Saving @ iter  325000
training @ iter = 325000 , loss =  0.00193986715749
training @ iter = 325000 , error =  0.0
training @ iter = 325100 , loss =  0.0332109183073
training @ iter = 325100 , error =  0.02
training @ iter = 325200 , loss =  0.00738122919574
training @ iter = 325200 , error =  0.0
training @ iter = 325300 , loss =  0.000997237046249
training @ iter = 325300 , error =  0.0
training @ iter = 325400 , loss =  0.00479338411242
training @ iter = 325400 , error =  0.0
training @ iter = 325500 , loss =  0.000561312888749
training @ iter = 325500 , error =  0.0
training @ iter = 325600 , loss =  0.00306943501346
training @ iter = 325600 , error =  0.0
training @ iter = 325700 , loss =  0.0684212893248
training @ iter = 325700 , error =  0.02
training @ iter = 325800 , loss =  0.00328180519864
training @ iter = 325800 , error =  0.0
training @ iter = 325900 , loss =  0.00304650934413
training @ iter = 325900 , error =  0.0
training @ iter = 326000 , loss =  0.00547826150432
training @ iter = 326000 , error =  0.0
training @ iter = 326100 , loss =  0.075680218637
training @ iter = 326100 , error =  0.02
training @ iter = 326200 , loss =  0.0264153815806
training @ iter = 326200 , error =  0.02
training @ iter = 326300 , loss =  0.00226604333147
training @ iter = 326300 , error =  0.0
training @ iter = 326400 , loss =  0.167080610991
training @ iter = 326400 , error =  0.02
training @ iter = 326500 , loss =  0.00271263485774
training @ iter = 326500 , error =  0.0
training @ iter = 326600 , loss =  0.00260210991837
training @ iter = 326600 , error =  0.0
training @ iter = 326700 , loss =  0.00233634538017
training @ iter = 326700 , error =  0.0
training @ iter = 326800 , loss =  0.0108522782102
training @ iter = 326800 , error =  0.0
training @ iter = 326900 , loss =  0.0645734295249
training @ iter = 326900 , error =  0.02
training @ iter = 327000 , loss =  0.0015555000864
training @ iter = 327000 , error =  0.0
training @ iter = 327100 , loss =  0.001751934411
training @ iter = 327100 , error =  0.0
training @ iter = 327200 , loss =  0.000557902036235
training @ iter = 327200 , error =  0.0
training @ iter = 327300 , loss =  0.0013253550278
training @ iter = 327300 , error =  0.0
training @ iter = 327400 , loss =  0.00526852253824
training @ iter = 327400 , error =  0.0
training @ iter = 327500 , loss =  0.0054906825535
training @ iter = 327500 , error =  0.0
training @ iter = 327600 , loss =  0.00909727904946
training @ iter = 327600 , error =  0.0
training @ iter = 327700 , loss =  0.00376054923981
training @ iter = 327700 , error =  0.0
training @ iter = 327800 , loss =  0.0774816721678
training @ iter = 327800 , error =  0.02
training @ iter = 327900 , loss =  0.00627729715779
training @ iter = 327900 , error =  0.0
training @ iter = 328000 , loss =  0.000929744623136
training @ iter = 328000 , error =  0.0
training @ iter = 328100 , loss =  0.00701475422829
training @ iter = 328100 , error =  0.0
training @ iter = 328200 , loss =  0.00124994246289
training @ iter = 328200 , error =  0.0
training @ iter = 328300 , loss =  0.00259895692579
training @ iter = 328300 , error =  0.0
training @ iter = 328400 , loss =  0.000424491619924
training @ iter = 328400 , error =  0.0
training @ iter = 328500 , loss =  0.00158085639123
training @ iter = 328500 , error =  0.0
training @ iter = 328600 , loss =  0.00125485123135
training @ iter = 328600 , error =  0.0
training @ iter = 328700 , loss =  0.000896037206985
training @ iter = 328700 , error =  0.0
training @ iter = 328800 , loss =  0.117154605687
training @ iter = 328800 , error =  0.04
training @ iter = 328900 , loss =  0.00181159854401
training @ iter = 328900 , error =  0.0
training @ iter = 329000 , loss =  0.00396327069029
training @ iter = 329000 , error =  0.0
--> train minibatch error =  0.18  at iter  329065
-->  7 33350 chunk_17_50000.pkl
training @ iter = 329100 , loss =  0.00141814618837
training @ iter = 329100 , error =  0.0
training @ iter = 329200 , loss =  0.0731547102332
training @ iter = 329200 , error =  0.02
training @ iter = 329300 , loss =  0.0115861324593
training @ iter = 329300 , error =  0.0
training @ iter = 329400 , loss =  0.252999097109
training @ iter = 329400 , error =  0.06
--> train minibatch error =  0.12  at iter  329493
-->  8 4750 chunk_18_50000.pkl
training @ iter = 329500 , loss =  0.015178585425
training @ iter = 329500 , error =  0.02
training @ iter = 329600 , loss =  0.00301619106904
training @ iter = 329600 , error =  0.0
training @ iter = 329700 , loss =  0.00320664583705
training @ iter = 329700 , error =  0.0
training @ iter = 329800 , loss =  0.00159363541752
training @ iter = 329800 , error =  0.0
training @ iter = 329900 , loss =  0.0039227027446
training @ iter = 329900 , error =  0.0
validation @ iter 330000
epoch 0, iter 330000, train buffer error 0.300000 %
epoch 0, iter 330000, validation loss 0.018251
epoch 0, iter 330000, validation error 0.559000 %
patience before checkBest 370000
patience after checkBest 370000
training @ iter = 330000 , loss =  0.0153910359368
training @ iter = 330000 , error =  0.0
--> train minibatch error =  0.22  at iter  330005
-->  8 30350 chunk_18_50000.pkl
--> train minibatch error =  0.14  at iter  330070
-->  8 33600 chunk_18_50000.pkl
training @ iter = 330100 , loss =  0.0119217066094
training @ iter = 330100 , error =  0.0
training @ iter = 330200 , loss =  0.00654809037223
training @ iter = 330200 , error =  0.0
training @ iter = 330300 , loss =  0.00425956724212
training @ iter = 330300 , error =  0.0
training @ iter = 330400 , loss =  0.0106369424611
training @ iter = 330400 , error =  0.0
training @ iter = 330500 , loss =  0.00164395745378
training @ iter = 330500 , error =  0.0
training @ iter = 330600 , loss =  0.00260726874694
training @ iter = 330600 , error =  0.0
training @ iter = 330700 , loss =  0.0052198539488
training @ iter = 330700 , error =  0.0
training @ iter = 330800 , loss =  0.0213574245572
training @ iter = 330800 , error =  0.02
training @ iter = 330900 , loss =  0.00125808920711
training @ iter = 330900 , error =  0.0
training @ iter = 331000 , loss =  0.107221670449
training @ iter = 331000 , error =  0.02
training @ iter = 331100 , loss =  0.00433786166832
training @ iter = 331100 , error =  0.0
training @ iter = 331200 , loss =  0.00583181064576
training @ iter = 331200 , error =  0.0
training @ iter = 331300 , loss =  0.0031879991293
training @ iter = 331300 , error =  0.0
training @ iter = 331400 , loss =  0.00251288386062
training @ iter = 331400 , error =  0.0
training @ iter = 331500 , loss =  0.000475492357509
training @ iter = 331500 , error =  0.0
--> train minibatch error =  0.18  at iter  331580
-->  10 9100 chunk_20_50000.pkl
training @ iter = 331600 , loss =  0.0565076693892
training @ iter = 331600 , error =  0.02
training @ iter = 331700 , loss =  0.00265046185814
training @ iter = 331700 , error =  0.0
--> train minibatch error =  0.12  at iter  331732
-->  10 16700 chunk_20_50000.pkl
training @ iter = 331800 , loss =  0.0232816357166
training @ iter = 331800 , error =  0.0
training @ iter = 331900 , loss =  0.0164960809052
training @ iter = 331900 , error =  0.0
training @ iter = 332000 , loss =  0.000767465971876
training @ iter = 332000 , error =  0.0
training @ iter = 332100 , loss =  0.083468541503
training @ iter = 332100 , error =  0.02
training @ iter = 332200 , loss =  0.101673148572
training @ iter = 332200 , error =  0.04
training @ iter = 332300 , loss =  0.00347554055043
training @ iter = 332300 , error =  0.0
training @ iter = 332400 , loss =  0.0710448697209
training @ iter = 332400 , error =  0.02
training @ iter = 332500 , loss =  0.00669070938602
training @ iter = 332500 , error =  0.0
training @ iter = 332600 , loss =  0.00157494377345
training @ iter = 332600 , error =  0.0
training @ iter = 332700 , loss =  0.0302047245204
training @ iter = 332700 , error =  0.0
training @ iter = 332800 , loss =  0.000713087560143
training @ iter = 332800 , error =  0.0
training @ iter = 332900 , loss =  0.00812528561801
training @ iter = 332900 , error =  0.0
training @ iter = 333000 , loss =  0.472122907639
training @ iter = 333000 , error =  0.06
training @ iter = 333100 , loss =  0.0179034583271
training @ iter = 333100 , error =  0.02
training @ iter = 333200 , loss =  0.00327741238289
training @ iter = 333200 , error =  0.0
training @ iter = 333300 , loss =  0.00320542091504
training @ iter = 333300 , error =  0.0
training @ iter = 333400 , loss =  0.00133974524215
training @ iter = 333400 , error =  0.0
training @ iter = 333500 , loss =  0.000637633726001
training @ iter = 333500 , error =  0.0
training @ iter = 333600 , loss =  0.0286080315709
training @ iter = 333600 , error =  0.02
training @ iter = 333700 , loss =  0.00604267884046
training @ iter = 333700 , error =  0.0
training @ iter = 333800 , loss =  0.00766283692792
training @ iter = 333800 , error =  0.0
training @ iter = 333900 , loss =  0.00232126936316
training @ iter = 333900 , error =  0.0
training @ iter = 334000 , loss =  0.00636595021933
training @ iter = 334000 , error =  0.0
training @ iter = 334100 , loss =  0.00279526528902
training @ iter = 334100 , error =  0.0
training @ iter = 334200 , loss =  0.00438580662012
training @ iter = 334200 , error =  0.0
training @ iter = 334300 , loss =  0.00599808385596
training @ iter = 334300 , error =  0.0
training @ iter = 334400 , loss =  0.000802912691142
training @ iter = 334400 , error =  0.0
training @ iter = 334500 , loss =  0.00969844125211
training @ iter = 334500 , error =  0.0
--> train minibatch error =  0.14  at iter  334594
-->  13 9800 chunk_23_50000.pkl
training @ iter = 334600 , loss =  0.0138767315075
training @ iter = 334600 , error =  0.0
training @ iter = 334700 , loss =  0.00245658215135
training @ iter = 334700 , error =  0.0
training @ iter = 334800 , loss =  0.000722877855878
training @ iter = 334800 , error =  0.0
training @ iter = 334900 , loss =  0.00158989219926
training @ iter = 334900 , error =  0.0
training @ iter = 335000 , loss =  0.00307333399542
training @ iter = 335000 , error =  0.0
training @ iter = 335100 , loss =  0.01932759583
training @ iter = 335100 , error =  0.0
training @ iter = 335200 , loss =  0.0979847833514
training @ iter = 335200 , error =  0.02
training @ iter = 335300 , loss =  0.00509545626119
training @ iter = 335300 , error =  0.0
training @ iter = 335400 , loss =  0.021202377975
training @ iter = 335400 , error =  0.0
training @ iter = 335500 , loss =  0.0293660666794
training @ iter = 335500 , error =  0.0
training @ iter = 335600 , loss =  0.0940535962582
training @ iter = 335600 , error =  0.02
training @ iter = 335700 , loss =  0.0048432154581
training @ iter = 335700 , error =  0.0
training @ iter = 335800 , loss =  0.00785062182695
training @ iter = 335800 , error =  0.0
training @ iter = 335900 , loss =  0.00374520476907
training @ iter = 335900 , error =  0.0
training @ iter = 336000 , loss =  0.000796909909695
training @ iter = 336000 , error =  0.0
training @ iter = 336100 , loss =  0.00205592997372
training @ iter = 336100 , error =  0.0
training @ iter = 336200 , loss =  0.00359516288154
training @ iter = 336200 , error =  0.0
training @ iter = 336300 , loss =  0.00333672529086
training @ iter = 336300 , error =  0.0
training @ iter = 336400 , loss =  0.00268832291476
training @ iter = 336400 , error =  0.0
training @ iter = 336500 , loss =  0.0150741590187
training @ iter = 336500 , error =  0.02
training @ iter = 336600 , loss =  0.00216367701069
training @ iter = 336600 , error =  0.0
training @ iter = 336700 , loss =  0.00356115307659
training @ iter = 336700 , error =  0.0
training @ iter = 336800 , loss =  0.00393453938887
training @ iter = 336800 , error =  0.0
training @ iter = 336900 , loss =  0.000711119151674
training @ iter = 336900 , error =  0.0
training @ iter = 337000 , loss =  0.00215919688344
training @ iter = 337000 , error =  0.0
training @ iter = 337100 , loss =  0.000955913215876
training @ iter = 337100 , error =  0.0
training @ iter = 337200 , loss =  0.0219051074237
training @ iter = 337200 , error =  0.02
training @ iter = 337300 , loss =  0.000401586585212
training @ iter = 337300 , error =  0.0
training @ iter = 337400 , loss =  0.00803267396986
training @ iter = 337400 , error =  0.0
training @ iter = 337500 , loss =  0.00482129817829
training @ iter = 337500 , error =  0.0
training @ iter = 337600 , loss =  0.000369539193343
training @ iter = 337600 , error =  0.0
training @ iter = 337700 , loss =  0.00109225604683
training @ iter = 337700 , error =  0.0
training @ iter = 337800 , loss =  0.00839996989816
training @ iter = 337800 , error =  0.0
training @ iter = 337900 , loss =  0.000291620264761
training @ iter = 337900 , error =  0.0
training @ iter = 338000 , loss =  0.00447748415172
training @ iter = 338000 , error =  0.0
training @ iter = 338100 , loss =  0.0135768055916
training @ iter = 338100 , error =  0.0
training @ iter = 338200 , loss =  0.00246063177474
training @ iter = 338200 , error =  0.0
training @ iter = 338300 , loss =  0.00360891968012
training @ iter = 338300 , error =  0.0
--> train minibatch error =  0.14  at iter  338386
-->  16 49400 chunk_26_50000.pkl
training @ iter = 338400 , loss =  0.111059553921
training @ iter = 338400 , error =  0.02
training @ iter = 338500 , loss =  0.000791906786617
training @ iter = 338500 , error =  0.0
training @ iter = 338600 , loss =  0.00077587767737
training @ iter = 338600 , error =  0.0
training @ iter = 338700 , loss =  0.00217911484651
training @ iter = 338700 , error =  0.0
training @ iter = 338800 , loss =  0.00389609811828
training @ iter = 338800 , error =  0.0
training @ iter = 338900 , loss =  0.00214796210639
training @ iter = 338900 , error =  0.0
training @ iter = 339000 , loss =  0.00422308500856
training @ iter = 339000 , error =  0.0
training @ iter = 339100 , loss =  0.0104584228247
training @ iter = 339100 , error =  0.02
training @ iter = 339200 , loss =  0.00177581456956
training @ iter = 339200 , error =  0.0
training @ iter = 339300 , loss =  0.00234989402816
training @ iter = 339300 , error =  0.0
training @ iter = 339400 , loss =  0.00118942023255
training @ iter = 339400 , error =  0.0
training @ iter = 339500 , loss =  0.00393057009205
training @ iter = 339500 , error =  0.0
training @ iter = 339600 , loss =  0.0016067820834
training @ iter = 339600 , error =  0.0
training @ iter = 339700 , loss =  0.00287455995567
training @ iter = 339700 , error =  0.0
training @ iter = 339800 , loss =  0.0128595307469
training @ iter = 339800 , error =  0.0
training @ iter = 339900 , loss =  0.00311885052361
training @ iter = 339900 , error =  0.0
validation @ iter 340000
epoch 0, iter 340000, train buffer error 0.200000 %
epoch 0, iter 340000, validation loss 0.017938
epoch 0, iter 340000, validation error 0.544000 %
patience before checkBest 370000
Patience =  440000
patience after checkBest 440000
training @ iter = 340000 , loss =  0.0071769808419
training @ iter = 340000 , error =  0.0
training @ iter = 340100 , loss =  0.00267803599127
training @ iter = 340100 , error =  0.0
ERROR:  /home/shared/Fields_12-2015/chunks_feat_50000/chunks_train/chunk_28_50000.pkl  has  4  candidates.
training @ iter = 340200 , loss =  0.171083793044
training @ iter = 340200 , error =  0.04
training @ iter = 340300 , loss =  0.0816515907645
training @ iter = 340300 , error =  0.06
training @ iter = 340400 , loss =  0.00994428247213
training @ iter = 340400 , error =  0.02
training @ iter = 340500 , loss =  0.0141375316307
training @ iter = 340500 , error =  0.0
training @ iter = 340600 , loss =  0.000827284471598
training @ iter = 340600 , error =  0.0
training @ iter = 340700 , loss =  0.00364898215048
training @ iter = 340700 , error =  0.0
training @ iter = 340800 , loss =  0.00242998986505
training @ iter = 340800 , error =  0.0
training @ iter = 340900 , loss =  0.009277747944
training @ iter = 340900 , error =  0.0
training @ iter = 341000 , loss =  0.00111270043999
training @ iter = 341000 , error =  0.0
training @ iter = 341100 , loss =  0.00423643784598
training @ iter = 341100 , error =  0.0
training @ iter = 341200 , loss =  0.00137590558734
training @ iter = 341200 , error =  0.0
--> train minibatch error =  0.24  at iter  341239
-->  20 5900 chunk_5_50000.pkl
--> train minibatch error =  0.16  at iter  341240
-->  20 5950 chunk_5_50000.pkl
training @ iter = 341300 , loss =  0.00782120693475
training @ iter = 341300 , error =  0.0
training @ iter = 341400 , loss =  0.00283418409526
training @ iter = 341400 , error =  0.0
training @ iter = 341500 , loss =  0.00737809063867
training @ iter = 341500 , error =  0.0
training @ iter = 341600 , loss =  0.00108460115734
training @ iter = 341600 , error =  0.0
training @ iter = 341700 , loss =  0.0497533977032
training @ iter = 341700 , error =  0.02
training @ iter = 341800 , loss =  0.00964793097228
training @ iter = 341800 , error =  0.0
training @ iter = 341900 , loss =  0.0050283302553
training @ iter = 341900 , error =  0.0
training @ iter = 342000 , loss =  0.00421011634171
training @ iter = 342000 , error =  0.0
training @ iter = 342100 , loss =  0.0116932066157
training @ iter = 342100 , error =  0.02
training @ iter = 342200 , loss =  0.0568542666733
training @ iter = 342200 , error =  0.02
--> train minibatch error =  0.12  at iter  342207
-->  21 4300 chunk_6_50000.pkl
training @ iter = 342300 , loss =  0.0410019978881
training @ iter = 342300 , error =  0.02
training @ iter = 342400 , loss =  0.0338922552764
training @ iter = 342400 , error =  0.02
training @ iter = 342500 , loss =  0.00156932172831
training @ iter = 342500 , error =  0.0
training @ iter = 342600 , loss =  0.0202021058649
training @ iter = 342600 , error =  0.0
training @ iter = 342700 , loss =  0.0109826587141
training @ iter = 342700 , error =  0.0
training @ iter = 342800 , loss =  0.000906912668142
training @ iter = 342800 , error =  0.0
training @ iter = 342900 , loss =  0.0400056950748
training @ iter = 342900 , error =  0.02
training @ iter = 343000 , loss =  0.00396131444722
training @ iter = 343000 , error =  0.0
training @ iter = 343100 , loss =  0.00200057332404
training @ iter = 343100 , error =  0.0
training @ iter = 343200 , loss =  0.0175834409893
training @ iter = 343200 , error =  0.0
training @ iter = 343300 , loss =  0.00164360436611
training @ iter = 343300 , error =  0.0
training @ iter = 343400 , loss =  0.00366356619634
training @ iter = 343400 , error =  0.0
training @ iter = 343500 , loss =  0.00119709561113
training @ iter = 343500 , error =  0.0
training @ iter = 343600 , loss =  0.00100715551525
training @ iter = 343600 , error =  0.0
training @ iter = 343700 , loss =  0.0175230223686
training @ iter = 343700 , error =  0.0
training @ iter = 343800 , loss =  0.000908709713258
training @ iter = 343800 , error =  0.0
training @ iter = 343900 , loss =  0.114624001086
training @ iter = 343900 , error =  0.02
training @ iter = 344000 , loss =  0.000358513061656
training @ iter = 344000 , error =  0.0
training @ iter = 344100 , loss =  0.0157381631434
training @ iter = 344100 , error =  0.0
training @ iter = 344200 , loss =  0.00213886005804
training @ iter = 344200 , error =  0.0
training @ iter = 344300 , loss =  0.02716964297
training @ iter = 344300 , error =  0.0
training @ iter = 344400 , loss =  0.00249942089431
training @ iter = 344400 , error =  0.0
training @ iter = 344500 , loss =  0.0019870523829
training @ iter = 344500 , error =  0.0
training @ iter = 344600 , loss =  0.132800012827
training @ iter = 344600 , error =  0.02
training @ iter = 344700 , loss =  0.030998615548
training @ iter = 344700 , error =  0.02
--> train minibatch error =  0.14  at iter  344759
-->  23 31900 chunk_8_50000.pkl
training @ iter = 344800 , loss =  0.008072222583
training @ iter = 344800 , error =  0.02
training @ iter = 344900 , loss =  0.00320213008672
training @ iter = 344900 , error =  0.0
training @ iter = 345000 , loss =  0.113906577229
training @ iter = 345000 , error =  0.02
training @ iter = 345100 , loss =  0.000717606395483
training @ iter = 345100 , error =  0.0
training @ iter = 345200 , loss =  0.0322108715773
training @ iter = 345200 , error =  0.02
training @ iter = 345300 , loss =  0.00359893077984
training @ iter = 345300 , error =  0.0
training @ iter = 345400 , loss =  0.00840260833502
training @ iter = 345400 , error =  0.02
training @ iter = 345500 , loss =  0.0192533005029
training @ iter = 345500 , error =  0.0
training @ iter = 345600 , loss =  0.0636131241918
training @ iter = 345600 , error =  0.02
training @ iter = 345700 , loss =  0.00395087013021
training @ iter = 345700 , error =  0.0
training @ iter = 345800 , loss =  0.0877437666059
training @ iter = 345800 , error =  0.02
--> train minibatch error =  0.2  at iter  345815
-->  24 34700 chunk_9_50000.pkl
--> train minibatch error =  0.18  at iter  345816
-->  24 34750 chunk_9_50000.pkl
training @ iter = 345900 , loss =  0.00078214763198
training @ iter = 345900 , error =  0.0
training @ iter = 346000 , loss =  0.00534734129906
training @ iter = 346000 , error =  0.0
training @ iter = 346100 , loss =  0.000820596003905
training @ iter = 346100 , error =  0.0
Epoch  14 , iteration  346122 training @ iter = 346200 , loss =  0.00390920275822
training @ iter = 346200 , error =  0.0
training @ iter = 346300 , loss =  0.000734158151317
training @ iter = 346300 , error =  0.0
training @ iter = 346400 , loss =  0.00261518242769
training @ iter = 346400 , error =  0.0
training @ iter = 346500 , loss =  0.00359678873792
training @ iter = 346500 , error =  0.0
training @ iter = 346600 , loss =  0.0118586802855
training @ iter = 346600 , error =  0.02
training @ iter = 346700 , loss =  0.00182624685112
training @ iter = 346700 , error =  0.0
training @ iter = 346800 , loss =  0.03302808851
training @ iter = 346800 , error =  0.02
training @ iter = 346900 , loss =  0.00275972788222
training @ iter = 346900 , error =  0.0
training @ iter = 347000 , loss =  0.00402968237177
training @ iter = 347000 , error =  0.0
training @ iter = 347100 , loss =  0.000656599120703
training @ iter = 347100 , error =  0.0
training @ iter = 347200 , loss =  0.00534201553091
training @ iter = 347200 , error =  0.0
training @ iter = 347300 , loss =  0.00513898395002
training @ iter = 347300 , error =  0.0
training @ iter = 347400 , loss =  0.0092014586553
training @ iter = 347400 , error =  0.0
training @ iter = 347500 , loss =  0.1187460199
training @ iter = 347500 , error =  0.02
training @ iter = 347600 , loss =  0.0139063689858
training @ iter = 347600 , error =  0.0
training @ iter = 347700 , loss =  0.00312796141952
training @ iter = 347700 , error =  0.0
training @ iter = 347800 , loss =  0.069631524384
training @ iter = 347800 , error =  0.02
training @ iter = 347900 , loss =  0.00432908767834
training @ iter = 347900 , error =  0.0
training @ iter = 348000 , loss =  0.00172326224856
training @ iter = 348000 , error =  0.0
training @ iter = 348100 , loss =  0.000811665784568
training @ iter = 348100 , error =  0.0
training @ iter = 348200 , loss =  0.00303680845536
training @ iter = 348200 , error =  0.0
training @ iter = 348300 , loss =  0.00516279926524
training @ iter = 348300 , error =  0.0
training @ iter = 348400 , loss =  0.0361226908863
training @ iter = 348400 , error =  0.02
training @ iter = 348500 , loss =  0.083244740963
training @ iter = 348500 , error =  0.02
training @ iter = 348600 , loss =  0.00483045261353
training @ iter = 348600 , error =  0.0
training @ iter = 348700 , loss =  0.000854399229866
training @ iter = 348700 , error =  0.0
training @ iter = 348800 , loss =  0.00298951123841
training @ iter = 348800 , error =  0.0
training @ iter = 348900 , loss =  0.00296076363884
training @ iter = 348900 , error =  0.0
training @ iter = 349000 , loss =  0.0261620711535
training @ iter = 349000 , error =  0.02
training @ iter = 349100 , loss =  0.00105985219125
training @ iter = 349100 , error =  0.0
training @ iter = 349200 , loss =  0.00272587360814
training @ iter = 349200 , error =  0.0
training @ iter = 349300 , loss =  0.00538762845099
training @ iter = 349300 , error =  0.0
training @ iter = 349400 , loss =  0.00999288354069
training @ iter = 349400 , error =  0.0
training @ iter = 349500 , loss =  0.00180571200326
training @ iter = 349500 , error =  0.0
training @ iter = 349600 , loss =  0.00307125295512
training @ iter = 349600 , error =  0.0
training @ iter = 349700 , loss =  0.0241271108389
training @ iter = 349700 , error =  0.02
training @ iter = 349800 , loss =  0.00371861550957
training @ iter = 349800 , error =  0.0
training @ iter = 349900 , loss =  0.118456162512
training @ iter = 349900 , error =  0.04
Saving @ iter  350000
validation @ iter 350000
epoch 0, iter 350000, train buffer error 0.400000 %
epoch 0, iter 350000, validation loss 0.018146
epoch 0, iter 350000, validation error 0.543000 %
patience before checkBest 440000
patience after checkBest 440000
training @ iter = 350000 , loss =  0.00122021278366
training @ iter = 350000 , error =  0.0
training @ iter = 350100 , loss =  0.0245737023652
training @ iter = 350100 , error =  0.02
training @ iter = 350200 , loss =  0.00495269242674
training @ iter = 350200 , error =  0.0
training @ iter = 350300 , loss =  0.00116694904864
training @ iter = 350300 , error =  0.0
training @ iter = 350400 , loss =  0.00137996522244
training @ iter = 350400 , error =  0.0
training @ iter = 350500 , loss =  0.00268370215781
training @ iter = 350500 , error =  0.0
training @ iter = 350600 , loss =  0.00135794549715
training @ iter = 350600 , error =  0.0
training @ iter = 350700 , loss =  0.0144503638148
training @ iter = 350700 , error =  0.0
training @ iter = 350800 , loss =  0.0175842735916
training @ iter = 350800 , error =  0.0
training @ iter = 350900 , loss =  0.00790450721979
training @ iter = 350900 , error =  0.0
training @ iter = 351000 , loss =  0.00060796237085
training @ iter = 351000 , error =  0.0
training @ iter = 351100 , loss =  0.012868957594
training @ iter = 351100 , error =  0.0
training @ iter = 351200 , loss =  0.00378423207439
training @ iter = 351200 , error =  0.0
training @ iter = 351300 , loss =  0.173520356417
training @ iter = 351300 , error =  0.02
training @ iter = 351400 , loss =  0.00296438904479
training @ iter = 351400 , error =  0.0
training @ iter = 351500 , loss =  0.0021473034285
training @ iter = 351500 , error =  0.0
training @ iter = 351600 , loss =  0.149463057518
training @ iter = 351600 , error =  0.06
training @ iter = 351700 , loss =  0.0393143892288
training @ iter = 351700 , error =  0.0
training @ iter = 351800 , loss =  0.00588429160416
training @ iter = 351800 , error =  0.0
training @ iter = 351900 , loss =  0.00062177417567
training @ iter = 351900 , error =  0.0
training @ iter = 352000 , loss =  0.000976385606918
training @ iter = 352000 , error =  0.0
training @ iter = 352100 , loss =  0.0189638063312
training @ iter = 352100 , error =  0.0
training @ iter = 352200 , loss =  0.00129814620595
training @ iter = 352200 , error =  0.0
training @ iter = 352300 , loss =  0.000781808921602
training @ iter = 352300 , error =  0.0
training @ iter = 352400 , loss =  0.00402369676158
training @ iter = 352400 , error =  0.0
training @ iter = 352500 , loss =  0.00118634756655
training @ iter = 352500 , error =  0.0
training @ iter = 352600 , loss =  0.089843608439
training @ iter = 352600 , error =  0.04
training @ iter = 352700 , loss =  0.0146854175255
training @ iter = 352700 , error =  0.0
training @ iter = 352800 , loss =  0.00130721076857
training @ iter = 352800 , error =  0.0
training @ iter = 352900 , loss =  0.0110416356474
training @ iter = 352900 , error =  0.0
training @ iter = 353000 , loss =  0.00452088145539
training @ iter = 353000 , error =  0.0
training @ iter = 353100 , loss =  0.00479883607477
training @ iter = 353100 , error =  0.0
training @ iter = 353200 , loss =  0.0111102238297
training @ iter = 353200 , error =  0.0
training @ iter = 353300 , loss =  0.0460270792246
training @ iter = 353300 , error =  0.02
training @ iter = 353400 , loss =  0.00641537504271
training @ iter = 353400 , error =  0.0
training @ iter = 353500 , loss =  0.000613128300756
training @ iter = 353500 , error =  0.0
training @ iter = 353600 , loss =  0.00202355463989
training @ iter = 353600 , error =  0.0
training @ iter = 353700 , loss =  0.0637414678931
training @ iter = 353700 , error =  0.02
--> train minibatch error =  0.18  at iter  353788
-->  7 33350 chunk_17_50000.pkl
training @ iter = 353800 , loss =  0.0148220900446
training @ iter = 353800 , error =  0.02
training @ iter = 353900 , loss =  0.000734787900001
training @ iter = 353900 , error =  0.0
training @ iter = 354000 , loss =  0.000934323645197
training @ iter = 354000 , error =  0.0
training @ iter = 354100 , loss =  0.0101499613374
training @ iter = 354100 , error =  0.0
training @ iter = 354200 , loss =  0.000773412000854
training @ iter = 354200 , error =  0.0
training @ iter = 354300 , loss =  0.00874799862504
training @ iter = 354300 , error =  0.0
training @ iter = 354400 , loss =  0.00101732951589
training @ iter = 354400 , error =  0.0
training @ iter = 354500 , loss =  0.0194525010884
training @ iter = 354500 , error =  0.0
training @ iter = 354600 , loss =  0.00419643567875
training @ iter = 354600 , error =  0.0
training @ iter = 354700 , loss =  0.00905053596944
training @ iter = 354700 , error =  0.0
--> train minibatch error =  0.18  at iter  354728
-->  8 30350 chunk_18_50000.pkl
--> train minibatch error =  0.14  at iter  354793
-->  8 33600 chunk_18_50000.pkl
training @ iter = 354800 , loss =  0.010688405484
training @ iter = 354800 , error =  0.0
training @ iter = 354900 , loss =  0.00855630636215
training @ iter = 354900 , error =  0.0
training @ iter = 355000 , loss =  0.0155145255849
training @ iter = 355000 , error =  0.0
training @ iter = 355100 , loss =  0.0103595312685
training @ iter = 355100 , error =  0.0
training @ iter = 355200 , loss =  0.00383971608244
training @ iter = 355200 , error =  0.0
training @ iter = 355300 , loss =  0.00360153708607
training @ iter = 355300 , error =  0.0
--> train minibatch error =  0.12  at iter  355332
-->  9 10550 chunk_19_50000.pkl
training @ iter = 355400 , loss =  0.118971340358
training @ iter = 355400 , error =  0.02
training @ iter = 355500 , loss =  0.00389712722972
training @ iter = 355500 , error =  0.0
training @ iter = 355600 , loss =  0.0256303921342
training @ iter = 355600 , error =  0.02
training @ iter = 355700 , loss =  0.00114372337703
training @ iter = 355700 , error =  0.0
training @ iter = 355800 , loss =  0.0521658696234
training @ iter = 355800 , error =  0.02
training @ iter = 355900 , loss =  0.0070933685638
training @ iter = 355900 , error =  0.0
training @ iter = 356000 , loss =  0.0224578101188
training @ iter = 356000 , error =  0.0
training @ iter = 356100 , loss =  0.00131750747096
training @ iter = 356100 , error =  0.0
training @ iter = 356200 , loss =  0.0145898554474
training @ iter = 356200 , error =  0.0
training @ iter = 356300 , loss =  0.00100158457644
training @ iter = 356300 , error =  0.0
--> train minibatch error =  0.18  at iter  356303
-->  10 9100 chunk_20_50000.pkl
training @ iter = 356400 , loss =  0.069107145071
training @ iter = 356400 , error =  0.02
--> train minibatch error =  0.12  at iter  356455
-->  10 16700 chunk_20_50000.pkl
training @ iter = 356500 , loss =  0.00527785997838
training @ iter = 356500 , error =  0.0
training @ iter = 356600 , loss =  0.00796682666987
training @ iter = 356600 , error =  0.0
training @ iter = 356700 , loss =  0.0362803414464
training @ iter = 356700 , error =  0.0
training @ iter = 356800 , loss =  0.000989306136034
training @ iter = 356800 , error =  0.0
training @ iter = 356900 , loss =  0.0902390703559
training @ iter = 356900 , error =  0.02
training @ iter = 357000 , loss =  0.000472127838293
training @ iter = 357000 , error =  0.0
training @ iter = 357100 , loss =  0.00349570531398
training @ iter = 357100 , error =  0.0
training @ iter = 357200 , loss =  0.0279836710542
training @ iter = 357200 , error =  0.0
training @ iter = 357300 , loss =  0.00345732271671
training @ iter = 357300 , error =  0.0
training @ iter = 357400 , loss =  0.00195715646259
training @ iter = 357400 , error =  0.0
training @ iter = 357500 , loss =  0.0003877041745
training @ iter = 357500 , error =  0.0
training @ iter = 357600 , loss =  0.0563849881291
training @ iter = 357600 , error =  0.02
training @ iter = 357700 , loss =  0.01652722992
training @ iter = 357700 , error =  0.0
training @ iter = 357800 , loss =  0.00421698577702
training @ iter = 357800 , error =  0.0
training @ iter = 357900 , loss =  0.00306470808573
training @ iter = 357900 , error =  0.0
training @ iter = 358000 , loss =  0.0160041861236
training @ iter = 358000 , error =  0.0
training @ iter = 358100 , loss =  0.0271598920226
training @ iter = 358100 , error =  0.0
training @ iter = 358200 , loss =  0.0925842672586
training @ iter = 358200 , error =  0.04
training @ iter = 358300 , loss =  0.00140087632462
training @ iter = 358300 , error =  0.0
training @ iter = 358400 , loss =  0.00711151771247
training @ iter = 358400 , error =  0.0
training @ iter = 358500 , loss =  0.016292700544
training @ iter = 358500 , error =  0.02
training @ iter = 358600 , loss =  0.00171016994864
training @ iter = 358600 , error =  0.0
training @ iter = 358700 , loss =  0.00988819077611
training @ iter = 358700 , error =  0.0
training @ iter = 358800 , loss =  0.00121129804756
training @ iter = 358800 , error =  0.0
training @ iter = 358900 , loss =  0.00154985103291
training @ iter = 358900 , error =  0.0
training @ iter = 359000 , loss =  0.00323827867396
training @ iter = 359000 , error =  0.0
training @ iter = 359100 , loss =  0.000673833419569
training @ iter = 359100 , error =  0.0
training @ iter = 359200 , loss =  0.00146813644096
training @ iter = 359200 , error =  0.0
training @ iter = 359300 , loss =  0.0123683204874
training @ iter = 359300 , error =  0.0
--> train minibatch error =  0.14  at iter  359317
-->  13 9800 chunk_23_50000.pkl
training @ iter = 359400 , loss =  0.00226307474077
training @ iter = 359400 , error =  0.0
training @ iter = 359500 , loss =  0.00317955343053
training @ iter = 359500 , error =  0.0
training @ iter = 359600 , loss =  0.0033181339968
training @ iter = 359600 , error =  0.0
training @ iter = 359700 , loss =  0.0219791624695
training @ iter = 359700 , error =  0.0
training @ iter = 359800 , loss =  0.00151623249985
training @ iter = 359800 , error =  0.0
training @ iter = 359900 , loss =  0.00200360664167
training @ iter = 359900 , error =  0.0
validation @ iter 360000
epoch 0, iter 360000, train buffer error 0.400000 %
epoch 0, iter 360000, validation loss 0.018004
epoch 0, iter 360000, validation error 0.547000 %
patience before checkBest 440000
patience after checkBest 440000
training @ iter = 360000 , loss =  0.0261782072484
training @ iter = 360000 , error =  0.0
training @ iter = 360100 , loss =  0.000690827611834
training @ iter = 360100 , error =  0.0
training @ iter = 360200 , loss =  0.0516620352864
training @ iter = 360200 , error =  0.02
training @ iter = 360300 , loss =  0.0455486774445
training @ iter = 360300 , error =  0.02
training @ iter = 360400 , loss =  0.00332028069533
training @ iter = 360400 , error =  0.0
training @ iter = 360500 , loss =  0.0282471422106
training @ iter = 360500 , error =  0.0
training @ iter = 360600 , loss =  0.0265378952026
training @ iter = 360600 , error =  0.02
training @ iter = 360700 , loss =  0.000755639397539
training @ iter = 360700 , error =  0.0
training @ iter = 360800 , loss =  0.0256589986384
training @ iter = 360800 , error =  0.04
training @ iter = 360900 , loss =  0.10930582881
training @ iter = 360900 , error =  0.02
training @ iter = 361000 , loss =  0.00204868498258
training @ iter = 361000 , error =  0.0
training @ iter = 361100 , loss =  0.000477270776173
training @ iter = 361100 , error =  0.0
training @ iter = 361200 , loss =  0.000670776527841
training @ iter = 361200 , error =  0.0
training @ iter = 361300 , loss =  0.00191602052655
training @ iter = 361300 , error =  0.0
training @ iter = 361400 , loss =  0.00610106391832
training @ iter = 361400 , error =  0.0
training @ iter = 361500 , loss =  0.0126170720905
training @ iter = 361500 , error =  0.0
training @ iter = 361600 , loss =  0.00141774851363
training @ iter = 361600 , error =  0.0
training @ iter = 361700 , loss =  0.00103453593329
training @ iter = 361700 , error =  0.0
training @ iter = 361800 , loss =  0.00453183474019
training @ iter = 361800 , error =  0.0
training @ iter = 361900 , loss =  0.000429158506449
training @ iter = 361900 , error =  0.0
training @ iter = 362000 , loss =  0.00242319260724
training @ iter = 362000 , error =  0.0
training @ iter = 362100 , loss =  0.000763180083595
training @ iter = 362100 , error =  0.0
training @ iter = 362200 , loss =  0.127639338374
training @ iter = 362200 , error =  0.02
training @ iter = 362300 , loss =  0.00960187055171
training @ iter = 362300 , error =  0.0
training @ iter = 362400 , loss =  0.00241978140548
training @ iter = 362400 , error =  0.0
training @ iter = 362500 , loss =  0.000686782295816
training @ iter = 362500 , error =  0.0
training @ iter = 362600 , loss =  0.00158524920698
training @ iter = 362600 , error =  0.0
training @ iter = 362700 , loss =  0.00214788294397
training @ iter = 362700 , error =  0.0
training @ iter = 362800 , loss =  0.0106994733214
training @ iter = 362800 , error =  0.0
training @ iter = 362900 , loss =  0.00343847181648
training @ iter = 362900 , error =  0.0
training @ iter = 363000 , loss =  0.00170464918483
training @ iter = 363000 , error =  0.0
training @ iter = 363100 , loss =  0.00186337647028
training @ iter = 363100 , error =  0.0
--> train minibatch error =  0.14  at iter  363109
-->  16 49400 chunk_26_50000.pkl
training @ iter = 363200 , loss =  0.0741371288896
training @ iter = 363200 , error =  0.02
training @ iter = 363300 , loss =  0.0194617118686
training @ iter = 363300 , error =  0.0
training @ iter = 363400 , loss =  0.00672054523602
training @ iter = 363400 , error =  0.0
training @ iter = 363500 , loss =  0.0422327816486
training @ iter = 363500 , error =  0.02
training @ iter = 363600 , loss =  0.000268460746156
training @ iter = 363600 , error =  0.0
training @ iter = 363700 , loss =  0.00154249952175
training @ iter = 363700 , error =  0.0
training @ iter = 363800 , loss =  0.00327161303721
training @ iter = 363800 , error =  0.0
training @ iter = 363900 , loss =  0.00177154317498
training @ iter = 363900 , error =  0.0
training @ iter = 364000 , loss =  0.031576719135
training @ iter = 364000 , error =  0.02
training @ iter = 364100 , loss =  0.00258520571515
training @ iter = 364100 , error =  0.0
training @ iter = 364200 , loss =  0.00160735147074
training @ iter = 364200 , error =  0.0
training @ iter = 364300 , loss =  0.00683071371168
training @ iter = 364300 , error =  0.0
training @ iter = 364400 , loss =  0.00255881762132
training @ iter = 364400 , error =  0.0
training @ iter = 364500 , loss =  0.00078323262278
training @ iter = 364500 , error =  0.0
training @ iter = 364600 , loss =  0.00129178003408
training @ iter = 364600 , error =  0.0
training @ iter = 364700 , loss =  0.00540794152766
training @ iter = 364700 , error =  0.0
training @ iter = 364800 , loss =  0.000477321969811
training @ iter = 364800 , error =  0.0
ERROR:  /home/shared/Fields_12-2015/chunks_feat_50000/chunks_train/chunk_28_50000.pkl  has  4  candidates.
training @ iter = 364900 , loss =  0.000457424815977
training @ iter = 364900 , error =  0.0
training @ iter = 365000 , loss =  0.000885526416823
training @ iter = 365000 , error =  0.0
training @ iter = 365100 , loss =  0.00362284947187
training @ iter = 365100 , error =  0.0
training @ iter = 365200 , loss =  0.00152119772974
training @ iter = 365200 , error =  0.0
training @ iter = 365300 , loss =  0.00206030602567
training @ iter = 365300 , error =  0.0
training @ iter = 365400 , loss =  0.105341337621
training @ iter = 365400 , error =  0.04
training @ iter = 365500 , loss =  0.000465555815026
training @ iter = 365500 , error =  0.0
training @ iter = 365600 , loss =  0.00145767908543
training @ iter = 365600 , error =  0.0
training @ iter = 365700 , loss =  0.0240560099483
training @ iter = 365700 , error =  0.02
training @ iter = 365800 , loss =  0.00117094500456
training @ iter = 365800 , error =  0.0
training @ iter = 365900 , loss =  0.005370978266
training @ iter = 365900 , error =  0.0
--> train minibatch error =  0.24  at iter  365962
-->  20 5900 chunk_5_50000.pkl
--> train minibatch error =  0.16  at iter  365963
-->  20 5950 chunk_5_50000.pkl
training @ iter = 366000 , loss =  0.00646726321429
training @ iter = 366000 , error =  0.0
training @ iter = 366100 , loss =  0.00117436377332
training @ iter = 366100 , error =  0.0
training @ iter = 366200 , loss =  0.0440394207835
training @ iter = 366200 , error =  0.0
training @ iter = 366300 , loss =  0.000587649119552
training @ iter = 366300 , error =  0.0
training @ iter = 366400 , loss =  0.0498803630471
training @ iter = 366400 , error =  0.04
training @ iter = 366500 , loss =  0.0013701049611
training @ iter = 366500 , error =  0.0
training @ iter = 366600 , loss =  0.0018692020094
training @ iter = 366600 , error =  0.0
training @ iter = 366700 , loss =  0.0190510768443
training @ iter = 366700 , error =  0.0
training @ iter = 366800 , loss =  0.00173070107121
training @ iter = 366800 , error =  0.0
training @ iter = 366900 , loss =  0.000737816968467
training @ iter = 366900 , error =  0.0
training @ iter = 367000 , loss =  0.00347663112916
training @ iter = 367000 , error =  0.0
training @ iter = 367100 , loss =  0.0202365536243
training @ iter = 367100 , error =  0.0
training @ iter = 367200 , loss =  0.00596864894032
training @ iter = 367200 , error =  0.0
training @ iter = 367300 , loss =  0.00157196936198
training @ iter = 367300 , error =  0.0
training @ iter = 367400 , loss =  0.0411095917225
training @ iter = 367400 , error =  0.0
training @ iter = 367500 , loss =  0.00177584169433
training @ iter = 367500 , error =  0.0
training @ iter = 367600 , loss =  0.00126991933212
training @ iter = 367600 , error =  0.0
training @ iter = 367700 , loss =  0.00667585199699
training @ iter = 367700 , error =  0.0
training @ iter = 367800 , loss =  0.00331928883679
training @ iter = 367800 , error =  0.0
training @ iter = 367900 , loss =  0.125608205795
training @ iter = 367900 , error =  0.04
training @ iter = 368000 , loss =  0.0235577635467
training @ iter = 368000 , error =  0.0
training @ iter = 368100 , loss =  0.00456901593134
training @ iter = 368100 , error =  0.0
training @ iter = 368200 , loss =  0.0256099514663
training @ iter = 368200 , error =  0.02
training @ iter = 368300 , loss =  0.00645091058686
training @ iter = 368300 , error =  0.0
training @ iter = 368400 , loss =  0.00141033856198
training @ iter = 368400 , error =  0.0
--> train minibatch error =  0.12  at iter  368463
-->  22 30950 chunk_7_50000.pkl
training @ iter = 368500 , loss =  0.058894071728
training @ iter = 368500 , error =  0.02
training @ iter = 368600 , loss =  0.0498401671648
training @ iter = 368600 , error =  0.02
training @ iter = 368700 , loss =  0.0149933788925
training @ iter = 368700 , error =  0.0
training @ iter = 368800 , loss =  0.0644803345203
training @ iter = 368800 , error =  0.02
training @ iter = 368900 , loss =  0.00751732150093
training @ iter = 368900 , error =  0.0
training @ iter = 369000 , loss =  0.00341799436137
training @ iter = 369000 , error =  0.0
training @ iter = 369100 , loss =  0.0541842617095
training @ iter = 369100 , error =  0.02
training @ iter = 369200 , loss =  0.0222390703857
training @ iter = 369200 , error =  0.0
training @ iter = 369300 , loss =  0.033425360918
training @ iter = 369300 , error =  0.02
training @ iter = 369400 , loss =  0.0827367976308
training @ iter = 369400 , error =  0.02
--> train minibatch error =  0.14  at iter  369482
-->  23 31900 chunk_8_50000.pkl
training @ iter = 369500 , loss =  0.033452346921
training @ iter = 369500 , error =  0.02
training @ iter = 369600 , loss =  0.00193720357493
training @ iter = 369600 , error =  0.0
training @ iter = 369700 , loss =  0.0722045302391
training @ iter = 369700 , error =  0.02
training @ iter = 369800 , loss =  0.0074124885723
training @ iter = 369800 , error =  0.0
training @ iter = 369900 , loss =  0.0207395907491
training @ iter = 369900 , error =  0.02
validation @ iter 370000
epoch 0, iter 370000, train buffer error 0.300000 %
epoch 0, iter 370000, validation loss 0.018393
epoch 0, iter 370000, validation error 0.573000 %
patience before checkBest 440000
patience after checkBest 440000
training @ iter = 370000 , loss =  0.0609843879938
training @ iter = 370000 , error =  0.02
training @ iter = 370100 , loss =  0.00330942147411
training @ iter = 370100 , error =  0.0
training @ iter = 370200 , loss =  0.0182673409581
training @ iter = 370200 , error =  0.0
training @ iter = 370300 , loss =  0.00994155555964
training @ iter = 370300 , error =  0.0
training @ iter = 370400 , loss =  0.000834738602862
training @ iter = 370400 , error =  0.0
training @ iter = 370500 , loss =  0.00544140767306
training @ iter = 370500 , error =  0.0
--> train minibatch error =  0.22  at iter  370538
-->  24 34700 chunk_9_50000.pkl
--> train minibatch error =  0.2  at iter  370539
-->  24 34750 chunk_9_50000.pkl
training @ iter = 370600 , loss =  0.0106058558449
training @ iter = 370600 , error =  0.0
training @ iter = 370700 , loss =  0.00309910648502
training @ iter = 370700 , error =  0.0
training @ iter = 370800 , loss =  0.0110936621204
training @ iter = 370800 , error =  0.0
Epoch  15 , iteration  370845 training @ iter = 370900 , loss =  0.000994622823782
training @ iter = 370900 , error =  0.0
training @ iter = 371000 , loss =  0.000783651019447
training @ iter = 371000 , error =  0.0
training @ iter = 371100 , loss =  0.136023432016
training @ iter = 371100 , error =  0.04
training @ iter = 371200 , loss =  0.0111195147038
training @ iter = 371200 , error =  0.0
training @ iter = 371300 , loss =  0.00156146276277
training @ iter = 371300 , error =  0.0
training @ iter = 371400 , loss =  0.0257364865392
training @ iter = 371400 , error =  0.0
training @ iter = 371500 , loss =  0.0176595393568
training @ iter = 371500 , error =  0.0
training @ iter = 371600 , loss =  0.00365759897977
training @ iter = 371600 , error =  0.0
training @ iter = 371700 , loss =  0.00846875924617
training @ iter = 371700 , error =  0.0
training @ iter = 371800 , loss =  0.0503384917974
training @ iter = 371800 , error =  0.02
training @ iter = 371900 , loss =  0.00203101267107
training @ iter = 371900 , error =  0.0
training @ iter = 372000 , loss =  0.00102499546483
training @ iter = 372000 , error =  0.0
training @ iter = 372100 , loss =  0.189361914992
training @ iter = 372100 , error =  0.02
training @ iter = 372200 , loss =  0.009705866687
training @ iter = 372200 , error =  0.0
training @ iter = 372300 , loss =  0.00268230796792
training @ iter = 372300 , error =  0.0
training @ iter = 372400 , loss =  0.000629683432635
training @ iter = 372400 , error =  0.0
training @ iter = 372500 , loss =  0.000928944442421
training @ iter = 372500 , error =  0.0
training @ iter = 372600 , loss =  0.000902460305952
training @ iter = 372600 , error =  0.0
training @ iter = 372700 , loss =  0.00469003478065
training @ iter = 372700 , error =  0.0
training @ iter = 372800 , loss =  0.00125210906845
training @ iter = 372800 , error =  0.0
training @ iter = 372900 , loss =  0.0210324525833
training @ iter = 372900 , error =  0.02
training @ iter = 373000 , loss =  0.141707986593
training @ iter = 373000 , error =  0.02
training @ iter = 373100 , loss =  0.00869651604444
training @ iter = 373100 , error =  0.0
training @ iter = 373200 , loss =  0.0275458544493
training @ iter = 373200 , error =  0.02
training @ iter = 373300 , loss =  0.00604235101491
training @ iter = 373300 , error =  0.0
training @ iter = 373400 , loss =  0.00447912607342
training @ iter = 373400 , error =  0.0
training @ iter = 373500 , loss =  0.0312178786844
training @ iter = 373500 , error =  0.0
training @ iter = 373600 , loss =  0.114864826202
training @ iter = 373600 , error =  0.06
training @ iter = 373700 , loss =  0.00790750049055
training @ iter = 373700 , error =  0.0
training @ iter = 373800 , loss =  0.000443546363385
training @ iter = 373800 , error =  0.0
training @ iter = 373900 , loss =  0.0154118184
training @ iter = 373900 , error =  0.02
training @ iter = 374000 , loss =  0.0489557795227
training @ iter = 374000 , error =  0.02
training @ iter = 374100 , loss =  0.00271857623011
training @ iter = 374100 , error =  0.0
training @ iter = 374200 , loss =  0.0481746234
training @ iter = 374200 , error =  0.02
training @ iter = 374300 , loss =  0.00652011390775
training @ iter = 374300 , error =  0.0
training @ iter = 374400 , loss =  0.000972358859144
training @ iter = 374400 , error =  0.0
training @ iter = 374500 , loss =  0.00250345445238
training @ iter = 374500 , error =  0.0
training @ iter = 374600 , loss =  0.0089341821149
training @ iter = 374600 , error =  0.0
training @ iter = 374700 , loss =  0.0121579375118
training @ iter = 374700 , error =  0.0
training @ iter = 374800 , loss =  0.00382302189246
training @ iter = 374800 , error =  0.0
training @ iter = 374900 , loss =  0.0257181208581
training @ iter = 374900 , error =  0.02
Saving @ iter  375000
training @ iter = 375000 , loss =  0.00115211901721
training @ iter = 375000 , error =  0.0
training @ iter = 375100 , loss =  0.0173971131444
training @ iter = 375100 , error =  0.0
training @ iter = 375200 , loss =  0.0187368057668
training @ iter = 375200 , error =  0.02
training @ iter = 375300 , loss =  0.00215660315007
training @ iter = 375300 , error =  0.0
training @ iter = 375400 , loss =  0.00118721579202
training @ iter = 375400 , error =  0.0
training @ iter = 375500 , loss =  0.00302608427592
training @ iter = 375500 , error =  0.0
training @ iter = 375600 , loss =  0.00235222303309
training @ iter = 375600 , error =  0.0
training @ iter = 375700 , loss =  0.00301156076603
training @ iter = 375700 , error =  0.0
training @ iter = 375800 , loss =  0.00372856203467
training @ iter = 375800 , error =  0.0
training @ iter = 375900 , loss =  0.00434880238026
training @ iter = 375900 , error =  0.0
training @ iter = 376000 , loss =  0.00072452344466
training @ iter = 376000 , error =  0.0
training @ iter = 376100 , loss =  0.0114774191752
training @ iter = 376100 , error =  0.0
training @ iter = 376200 , loss =  0.00516700139269
training @ iter = 376200 , error =  0.0
training @ iter = 376300 , loss =  0.00049647805281
training @ iter = 376300 , error =  0.0
training @ iter = 376400 , loss =  0.00241973344237
training @ iter = 376400 , error =  0.0
training @ iter = 376500 , loss =  0.0137384822592
training @ iter = 376500 , error =  0.0
training @ iter = 376600 , loss =  0.00936344731599
training @ iter = 376600 , error =  0.0
training @ iter = 376700 , loss =  0.0132868317887
training @ iter = 376700 , error =  0.0
training @ iter = 376800 , loss =  0.00130770262331
training @ iter = 376800 , error =  0.0
training @ iter = 376900 , loss =  0.156186595559
training @ iter = 376900 , error =  0.04
training @ iter = 377000 , loss =  0.000551872013602
training @ iter = 377000 , error =  0.0
training @ iter = 377100 , loss =  0.00402235984802
training @ iter = 377100 , error =  0.0
training @ iter = 377200 , loss =  0.0014057935914
training @ iter = 377200 , error =  0.0
training @ iter = 377300 , loss =  0.0131304813549
training @ iter = 377300 , error =  0.0
training @ iter = 377400 , loss =  0.204856872559
training @ iter = 377400 , error =  0.04
training @ iter = 377500 , loss =  0.00290979864076
training @ iter = 377500 , error =  0.0
training @ iter = 377600 , loss =  0.00125288870186
training @ iter = 377600 , error =  0.0
training @ iter = 377700 , loss =  0.000545369286556
training @ iter = 377700 , error =  0.0
training @ iter = 377800 , loss =  0.00084656587569
training @ iter = 377800 , error =  0.0
training @ iter = 377900 , loss =  0.019020408392
training @ iter = 377900 , error =  0.02
training @ iter = 378000 , loss =  0.00561539968476
training @ iter = 378000 , error =  0.0
training @ iter = 378100 , loss =  0.135232239962
training @ iter = 378100 , error =  0.04
training @ iter = 378200 , loss =  0.0287903118879
training @ iter = 378200 , error =  0.02
training @ iter = 378300 , loss =  0.0136527260765
training @ iter = 378300 , error =  0.0
training @ iter = 378400 , loss =  0.101960621774
training @ iter = 378400 , error =  0.02
training @ iter = 378500 , loss =  0.0150983659551
training @ iter = 378500 , error =  0.0
--> train minibatch error =  0.18  at iter  378511
-->  7 33350 chunk_17_50000.pkl
training @ iter = 378600 , loss =  0.00136930495501
training @ iter = 378600 , error =  0.0
training @ iter = 378700 , loss =  0.00555172283202
training @ iter = 378700 , error =  0.0
training @ iter = 378800 , loss =  0.00282533001155
training @ iter = 378800 , error =  0.0
training @ iter = 378900 , loss =  0.00366181856953
training @ iter = 378900 , error =  0.0
--> train minibatch error =  0.12  at iter  378939
-->  8 4750 chunk_18_50000.pkl
training @ iter = 379000 , loss =  0.00204325700179
training @ iter = 379000 , error =  0.0
training @ iter = 379100 , loss =  0.0308559425175
training @ iter = 379100 , error =  0.02
training @ iter = 379200 , loss =  0.000389699271182
training @ iter = 379200 , error =  0.0
training @ iter = 379300 , loss =  0.00442187441513
training @ iter = 379300 , error =  0.0
training @ iter = 379400 , loss =  0.0109748300165
training @ iter = 379400 , error =  0.0
--> train minibatch error =  0.22  at iter  379451
-->  8 30350 chunk_18_50000.pkl
training @ iter = 379500 , loss =  0.0233755018562
training @ iter = 379500 , error =  0.02
--> train minibatch error =  0.14  at iter  379516
-->  8 33600 chunk_18_50000.pkl
training @ iter = 379600 , loss =  0.00136300013401
training @ iter = 379600 , error =  0.0
training @ iter = 379700 , loss =  0.00333865731955
training @ iter = 379700 , error =  0.0
training @ iter = 379800 , loss =  0.0928510352969
training @ iter = 379800 , error =  0.04
training @ iter = 379900 , loss =  0.00366027234122
training @ iter = 379900 , error =  0.0
validation @ iter 380000
epoch 0, iter 380000, train buffer error 0.800000 %
epoch 0, iter 380000, validation loss 0.017646
epoch 0, iter 380000, validation error 0.537000 %
patience before checkBest 440000
Patience =  480000
patience after checkBest 480000
training @ iter = 380000 , loss =  0.013187430799
training @ iter = 380000 , error =  0.0
--> train minibatch error =  0.12  at iter  380055
-->  9 10550 chunk_19_50000.pkl
training @ iter = 380100 , loss =  0.00105634657666
training @ iter = 380100 , error =  0.0
training @ iter = 380200 , loss =  0.000909971771762
training @ iter = 380200 , error =  0.0
training @ iter = 380300 , loss =  0.00229729595594
training @ iter = 380300 , error =  0.0
training @ iter = 380400 , loss =  0.00961889699101
training @ iter = 380400 , error =  0.0
training @ iter = 380500 , loss =  0.0654609650373
training @ iter = 380500 , error =  0.02
training @ iter = 380600 , loss =  0.0209086034447
training @ iter = 380600 , error =  0.02
training @ iter = 380700 , loss =  0.0899145677686
training @ iter = 380700 , error =  0.06
training @ iter = 380800 , loss =  0.0111145218834
training @ iter = 380800 , error =  0.0
training @ iter = 380900 , loss =  0.00811519101262
training @ iter = 380900 , error =  0.0
training @ iter = 381000 , loss =  0.000482804549392
training @ iter = 381000 , error =  0.0
--> train minibatch error =  0.18  at iter  381026
-->  10 9100 chunk_20_50000.pkl
training @ iter = 381100 , loss =  0.00129919918254
training @ iter = 381100 , error =  0.0
--> train minibatch error =  0.12  at iter  381178
-->  10 16700 chunk_20_50000.pkl
training @ iter = 381200 , loss =  0.00186097726692
training @ iter = 381200 , error =  0.0
training @ iter = 381300 , loss =  0.0612857341766
training @ iter = 381300 , error =  0.02
training @ iter = 381400 , loss =  0.00322185386904
training @ iter = 381400 , error =  0.0
training @ iter = 381500 , loss =  0.0107356896624
training @ iter = 381500 , error =  0.0
training @ iter = 381600 , loss =  0.0708634927869
training @ iter = 381600 , error =  0.02
training @ iter = 381700 , loss =  0.0249107200652
training @ iter = 381700 , error =  0.02
training @ iter = 381800 , loss =  0.000509307661559
training @ iter = 381800 , error =  0.0
training @ iter = 381900 , loss =  0.000815979670733
training @ iter = 381900 , error =  0.0
training @ iter = 382000 , loss =  0.000539882399607
training @ iter = 382000 , error =  0.0
training @ iter = 382100 , loss =  0.0010655883234
training @ iter = 382100 , error =  0.0
training @ iter = 382200 , loss =  0.00121834268793
training @ iter = 382200 , error =  0.0
training @ iter = 382300 , loss =  0.00276420149021
training @ iter = 382300 , error =  0.0
training @ iter = 382400 , loss =  0.00888218265027
training @ iter = 382400 , error =  0.0
--> train minibatch error =  0.12  at iter  382447
-->  11 30150 chunk_21_50000.pkl
training @ iter = 382500 , loss =  0.00332480156794
training @ iter = 382500 , error =  0.0
training @ iter = 382600 , loss =  0.00340555841103
training @ iter = 382600 , error =  0.0
training @ iter = 382700 , loss =  0.00284330011345
training @ iter = 382700 , error =  0.0
training @ iter = 382800 , loss =  0.00126667832956
training @ iter = 382800 , error =  0.0
training @ iter = 382900 , loss =  0.018043095246
training @ iter = 382900 , error =  0.0
training @ iter = 383000 , loss =  0.00326561904512
training @ iter = 383000 , error =  0.0
training @ iter = 383100 , loss =  0.0311578735709
training @ iter = 383100 , error =  0.02
training @ iter = 383200 , loss =  0.00162297184579
training @ iter = 383200 , error =  0.0
training @ iter = 383300 , loss =  0.00766022084281
training @ iter = 383300 , error =  0.02
training @ iter = 383400 , loss =  0.01137993671
training @ iter = 383400 , error =  0.0
training @ iter = 383500 , loss =  0.00241903564893
training @ iter = 383500 , error =  0.0
training @ iter = 383600 , loss =  0.00572550483048
training @ iter = 383600 , error =  0.0
training @ iter = 383700 , loss =  0.00646188249812
training @ iter = 383700 , error =  0.0
training @ iter = 383800 , loss =  0.00429048808292
training @ iter = 383800 , error =  0.0
training @ iter = 383900 , loss =  0.000335970224114
training @ iter = 383900 , error =  0.0
training @ iter = 384000 , loss =  0.00493451580405
training @ iter = 384000 , error =  0.0
--> train minibatch error =  0.14  at iter  384040
-->  13 9800 chunk_23_50000.pkl
training @ iter = 384100 , loss =  0.00286721647717
training @ iter = 384100 , error =  0.0
training @ iter = 384200 , loss =  0.00198305211961
training @ iter = 384200 , error =  0.0
training @ iter = 384300 , loss =  0.00101759994868
training @ iter = 384300 , error =  0.0
training @ iter = 384400 , loss =  0.00316304271109
training @ iter = 384400 , error =  0.0
training @ iter = 384500 , loss =  0.0215208865702
training @ iter = 384500 , error =  0.02
training @ iter = 384600 , loss =  0.0358880907297
training @ iter = 384600 , error =  0.02
training @ iter = 384700 , loss =  0.00948584079742
training @ iter = 384700 , error =  0.0
training @ iter = 384800 , loss =  0.00144426955376
training @ iter = 384800 , error =  0.0
training @ iter = 384900 , loss =  0.00641307840124
training @ iter = 384900 , error =  0.0
training @ iter = 385000 , loss =  0.0133906351402
training @ iter = 385000 , error =  0.0
training @ iter = 385100 , loss =  0.00410411972553
training @ iter = 385100 , error =  0.0
training @ iter = 385200 , loss =  0.0215052794665
training @ iter = 385200 , error =  0.0
training @ iter = 385300 , loss =  0.00045828326256
training @ iter = 385300 , error =  0.0
training @ iter = 385400 , loss =  0.00304155889899
training @ iter = 385400 , error =  0.0
training @ iter = 385500 , loss =  0.00572150247172
training @ iter = 385500 , error =  0.0
training @ iter = 385600 , loss =  0.00282589532435
training @ iter = 385600 , error =  0.0
training @ iter = 385700 , loss =  0.00264973589219
training @ iter = 385700 , error =  0.0
training @ iter = 385800 , loss =  0.00692095980048
training @ iter = 385800 , error =  0.0
training @ iter = 385900 , loss =  0.0130609953776
training @ iter = 385900 , error =  0.0
training @ iter = 386000 , loss =  0.000548984156922
training @ iter = 386000 , error =  0.0
training @ iter = 386100 , loss =  0.00421780627221
training @ iter = 386100 , error =  0.0
training @ iter = 386200 , loss =  0.00770447542891
training @ iter = 386200 , error =  0.0
training @ iter = 386300 , loss =  0.00296313106082
training @ iter = 386300 , error =  0.0
training @ iter = 386400 , loss =  0.00421788077801
training @ iter = 386400 , error =  0.0
training @ iter = 386500 , loss =  0.129739448428
training @ iter = 386500 , error =  0.02
training @ iter = 386600 , loss =  0.00103937881067
training @ iter = 386600 , error =  0.0
training @ iter = 386700 , loss =  0.00816810969263
training @ iter = 386700 , error =  0.0
training @ iter = 386800 , loss =  0.00831699278206
training @ iter = 386800 , error =  0.0
training @ iter = 386900 , loss =  0.040855396539
training @ iter = 386900 , error =  0.02
training @ iter = 387000 , loss =  0.000859586987644
training @ iter = 387000 , error =  0.0
training @ iter = 387100 , loss =  0.00238045142032
training @ iter = 387100 , error =  0.0
training @ iter = 387200 , loss =  0.00234593590721
training @ iter = 387200 , error =  0.0
training @ iter = 387300 , loss =  0.000729307590518
training @ iter = 387300 , error =  0.0
training @ iter = 387400 , loss =  0.0193552859128
training @ iter = 387400 , error =  0.0
training @ iter = 387500 , loss =  0.00545092346147
training @ iter = 387500 , error =  0.0
training @ iter = 387600 , loss =  0.123959153891
training @ iter = 387600 , error =  0.04
training @ iter = 387700 , loss =  0.00100493477657
training @ iter = 387700 , error =  0.0
training @ iter = 387800 , loss =  0.00140767917037
training @ iter = 387800 , error =  0.0
--> train minibatch error =  0.14  at iter  387832
-->  16 49400 chunk_26_50000.pkl
training @ iter = 387900 , loss =  0.0195894297212
training @ iter = 387900 , error =  0.02
training @ iter = 388000 , loss =  0.00801507104188
training @ iter = 388000 , error =  0.0
training @ iter = 388100 , loss =  0.00318399793468
training @ iter = 388100 , error =  0.0
training @ iter = 388200 , loss =  0.0408080257475
training @ iter = 388200 , error =  0.02
training @ iter = 388300 , loss =  0.000415674701799
training @ iter = 388300 , error =  0.0
training @ iter = 388400 , loss =  0.005656842608
training @ iter = 388400 , error =  0.0
training @ iter = 388500 , loss =  0.000472217041533
training @ iter = 388500 , error =  0.0
training @ iter = 388600 , loss =  0.0040629399009
training @ iter = 388600 , error =  0.0
training @ iter = 388700 , loss =  0.00193217862397
training @ iter = 388700 , error =  0.0
training @ iter = 388800 , loss =  0.00417624553666
training @ iter = 388800 , error =  0.0
training @ iter = 388900 , loss =  0.000610130431596
training @ iter = 388900 , error =  0.0
training @ iter = 389000 , loss =  0.0218195915222
training @ iter = 389000 , error =  0.0
training @ iter = 389100 , loss =  0.0329196900129
training @ iter = 389100 , error =  0.0
training @ iter = 389200 , loss =  0.0109118483961
training @ iter = 389200 , error =  0.0
training @ iter = 389300 , loss =  0.00152542383876
training @ iter = 389300 , error =  0.0
training @ iter = 389400 , loss =  0.00290036341175
training @ iter = 389400 , error =  0.0
training @ iter = 389500 , loss =  0.00932700745761
training @ iter = 389500 , error =  0.0
ERROR:  /home/shared/Fields_12-2015/chunks_feat_50000/chunks_train/chunk_28_50000.pkl  has  4  candidates.
training @ iter = 389600 , loss =  0.00914990343153
training @ iter = 389600 , error =  0.0
training @ iter = 389700 , loss =  0.044693261385
training @ iter = 389700 , error =  0.02
training @ iter = 389800 , loss =  0.00445636315271
training @ iter = 389800 , error =  0.0
training @ iter = 389900 , loss =  0.0235047265887
training @ iter = 389900 , error =  0.0
validation @ iter 390000
epoch 0, iter 390000, train buffer error 0.500000 %
epoch 0, iter 390000, validation loss 0.018019
epoch 0, iter 390000, validation error 0.535000 %
patience before checkBest 480000
patience after checkBest 480000
training @ iter = 390000 , loss =  0.000866932619829
training @ iter = 390000 , error =  0.0
training @ iter = 390100 , loss =  0.0138721754774
training @ iter = 390100 , error =  0.0
training @ iter = 390200 , loss =  0.0013701885473
training @ iter = 390200 , error =  0.0
training @ iter = 390300 , loss =  0.000987343606539
training @ iter = 390300 , error =  0.0
training @ iter = 390400 , loss =  0.00304892007262
training @ iter = 390400 , error =  0.0
training @ iter = 390500 , loss =  0.00258242315613
training @ iter = 390500 , error =  0.0
training @ iter = 390600 , loss =  0.00647494848818
training @ iter = 390600 , error =  0.0
--> train minibatch error =  0.24  at iter  390685
-->  20 5900 chunk_5_50000.pkl
--> train minibatch error =  0.16  at iter  390686
-->  20 5950 chunk_5_50000.pkl
training @ iter = 390700 , loss =  0.000604686327279
training @ iter = 390700 , error =  0.0
training @ iter = 390800 , loss =  0.00802896823734
training @ iter = 390800 , error =  0.02
training @ iter = 390900 , loss =  0.0565234944224
training @ iter = 390900 , error =  0.02
training @ iter = 391000 , loss =  0.0235998947173
training @ iter = 391000 , error =  0.02
training @ iter = 391100 , loss =  0.00414926744998
training @ iter = 391100 , error =  0.0
training @ iter = 391200 , loss =  0.00277537642978
training @ iter = 391200 , error =  0.0
training @ iter = 391300 , loss =  0.0380139835179
training @ iter = 391300 , error =  0.02
training @ iter = 391400 , loss =  0.00722825294361
training @ iter = 391400 , error =  0.0
training @ iter = 391500 , loss =  0.040504977107
training @ iter = 391500 , error =  0.02
training @ iter = 391600 , loss =  0.000587893358897
training @ iter = 391600 , error =  0.0
training @ iter = 391700 , loss =  0.00123692804482
training @ iter = 391700 , error =  0.0
training @ iter = 391800 , loss =  0.00207350566052
training @ iter = 391800 , error =  0.0
training @ iter = 391900 , loss =  0.00183685135562
training @ iter = 391900 , error =  0.0
training @ iter = 392000 , loss =  0.00598788121715
training @ iter = 392000 , error =  0.02
training @ iter = 392100 , loss =  0.00160744297318
training @ iter = 392100 , error =  0.0
training @ iter = 392200 , loss =  0.00786005519331
training @ iter = 392200 , error =  0.0
training @ iter = 392300 , loss =  0.0355414710939
training @ iter = 392300 , error =  0.0
training @ iter = 392400 , loss =  0.0164480824023
training @ iter = 392400 , error =  0.0
training @ iter = 392500 , loss =  0.00308795738965
training @ iter = 392500 , error =  0.0
training @ iter = 392600 , loss =  0.0777155086398
training @ iter = 392600 , error =  0.0
training @ iter = 392700 , loss =  0.00343412975781
training @ iter = 392700 , error =  0.0
training @ iter = 392800 , loss =  0.00252527976409
training @ iter = 392800 , error =  0.0
training @ iter = 392900 , loss =  0.0232117250562
training @ iter = 392900 , error =  0.0
training @ iter = 393000 , loss =  0.0129999388009
training @ iter = 393000 , error =  0.0
training @ iter = 393100 , loss =  0.0160711761564
training @ iter = 393100 , error =  0.0
--> train minibatch error =  0.12  at iter  393186
-->  22 30950 chunk_7_50000.pkl
training @ iter = 393200 , loss =  0.00110448501073
training @ iter = 393200 , error =  0.0
training @ iter = 393300 , loss =  0.00058142124908
training @ iter = 393300 , error =  0.0
training @ iter = 393400 , loss =  0.00100407632999
training @ iter = 393400 , error =  0.0
training @ iter = 393500 , loss =  0.0692206397653
training @ iter = 393500 , error =  0.02
training @ iter = 393600 , loss =  0.0505407862365
training @ iter = 393600 , error =  0.02
training @ iter = 393700 , loss =  0.000598524115048
training @ iter = 393700 , error =  0.0
training @ iter = 393800 , loss =  0.00500421272591
training @ iter = 393800 , error =  0.0
training @ iter = 393900 , loss =  0.00110780331306
training @ iter = 393900 , error =  0.0
training @ iter = 394000 , loss =  0.0990214720368
training @ iter = 394000 , error =  0.02
training @ iter = 394100 , loss =  0.0113008180633
training @ iter = 394100 , error =  0.0
training @ iter = 394200 , loss =  0.00264968257397
training @ iter = 394200 , error =  0.0
--> train minibatch error =  0.14  at iter  394205
-->  23 31900 chunk_8_50000.pkl
training @ iter = 394300 , loss =  0.127278849483
training @ iter = 394300 , error =  0.02
training @ iter = 394400 , loss =  0.000537129992153
training @ iter = 394400 , error =  0.0
training @ iter = 394500 , loss =  0.00753029761836
training @ iter = 394500 , error =  0.0
training @ iter = 394600 , loss =  0.000696501752827
training @ iter = 394600 , error =  0.0
training @ iter = 394700 , loss =  0.00169872969855
training @ iter = 394700 , error =  0.0
training @ iter = 394800 , loss =  0.00188405497465
training @ iter = 394800 , error =  0.0
training @ iter = 394900 , loss =  0.0269972961396
training @ iter = 394900 , error =  0.02
training @ iter = 395000 , loss =  0.00681174220517
training @ iter = 395000 , error =  0.0
training @ iter = 395100 , loss =  0.00189729884733
training @ iter = 395100 , error =  0.0
training @ iter = 395200 , loss =  0.00378944491968
training @ iter = 395200 , error =  0.0
--> train minibatch error =  0.2  at iter  395261
-->  24 34700 chunk_9_50000.pkl
--> train minibatch error =  0.18  at iter  395262
-->  24 34750 chunk_9_50000.pkl
training @ iter = 395300 , loss =  0.000578968960326
training @ iter = 395300 , error =  0.0
training @ iter = 395400 , loss =  0.0875449851155
training @ iter = 395400 , error =  0.02
training @ iter = 395500 , loss =  0.00180451234337
training @ iter = 395500 , error =  0.0
Epoch  16 , iteration  395568 training @ iter = 395600 , loss =  0.0479533299804
training @ iter = 395600 , error =  0.0
training @ iter = 395700 , loss =  0.00174539815634
training @ iter = 395700 , error =  0.0
training @ iter = 395800 , loss =  0.146060675383
training @ iter = 395800 , error =  0.04
training @ iter = 395900 , loss =  0.00721390079707
training @ iter = 395900 , error =  0.0
training @ iter = 396000 , loss =  0.0263290405273
training @ iter = 396000 , error =  0.0
training @ iter = 396100 , loss =  0.0505984276533
training @ iter = 396100 , error =  0.02
training @ iter = 396200 , loss =  0.0228796545416
training @ iter = 396200 , error =  0.0
training @ iter = 396300 , loss =  0.0015556612052
training @ iter = 396300 , error =  0.0
training @ iter = 396400 , loss =  0.0359635278583
training @ iter = 396400 , error =  0.02
training @ iter = 396500 , loss =  0.00345916301012
training @ iter = 396500 , error =  0.0
training @ iter = 396600 , loss =  0.00851691234857
training @ iter = 396600 , error =  0.0
training @ iter = 396700 , loss =  0.00358395790681
training @ iter = 396700 , error =  0.0
training @ iter = 396800 , loss =  0.00565467402339
training @ iter = 396800 , error =  0.0
training @ iter = 396900 , loss =  0.0478004924953
training @ iter = 396900 , error =  0.02
training @ iter = 397000 , loss =  0.000486023433041
training @ iter = 397000 , error =  0.0
training @ iter = 397100 , loss =  0.05658897385
training @ iter = 397100 , error =  0.02
training @ iter = 397200 , loss =  0.068379253149
training @ iter = 397200 , error =  0.02
training @ iter = 397300 , loss =  0.00245493091643
training @ iter = 397300 , error =  0.0
training @ iter = 397400 , loss =  0.00059511460131
training @ iter = 397400 , error =  0.0
training @ iter = 397500 , loss =  0.00474050780758
training @ iter = 397500 , error =  0.0
training @ iter = 397600 , loss =  0.0794452652335
training @ iter = 397600 , error =  0.04
training @ iter = 397700 , loss =  0.106253661215
training @ iter = 397700 , error =  0.02
training @ iter = 397800 , loss =  0.00175830721855
training @ iter = 397800 , error =  0.0
training @ iter = 397900 , loss =  0.173528313637
training @ iter = 397900 , error =  0.04
training @ iter = 398000 , loss =  0.00273987115361
training @ iter = 398000 , error =  0.0
training @ iter = 398100 , loss =  0.000780909147579
training @ iter = 398100 , error =  0.0
training @ iter = 398200 , loss =  0.00355852488428
training @ iter = 398200 , error =  0.0
training @ iter = 398300 , loss =  0.0113439075649
training @ iter = 398300 , error =  0.0
training @ iter = 398400 , loss =  0.0128519842401
training @ iter = 398400 , error =  0.0
training @ iter = 398500 , loss =  0.000894227239769
training @ iter = 398500 , error =  0.0
training @ iter = 398600 , loss =  0.00420775124803
training @ iter = 398600 , error =  0.0
training @ iter = 398700 , loss =  0.0216826461256
training @ iter = 398700 , error =  0.0
training @ iter = 398800 , loss =  0.00454032281414
training @ iter = 398800 , error =  0.0
training @ iter = 398900 , loss =  0.00902390386909
training @ iter = 398900 , error =  0.0
training @ iter = 399000 , loss =  0.00318088452332
training @ iter = 399000 , error =  0.0
training @ iter = 399100 , loss =  0.00938695669174
training @ iter = 399100 , error =  0.0
training @ iter = 399200 , loss =  0.00341268349439
training @ iter = 399200 , error =  0.0
training @ iter = 399300 , loss =  0.0265245884657
training @ iter = 399300 , error =  0.0
training @ iter = 399400 , loss =  0.0209569912404
training @ iter = 399400 , error =  0.0
training @ iter = 399500 , loss =  0.153215765953
training @ iter = 399500 , error =  0.02
training @ iter = 399600 , loss =  0.00187506584916
training @ iter = 399600 , error =  0.0
training @ iter = 399700 , loss =  0.00341661297716
training @ iter = 399700 , error =  0.0
training @ iter = 399800 , loss =  0.0419451333582
training @ iter = 399800 , error =  0.02
training @ iter = 399900 , loss =  0.0158796235919
training @ iter = 399900 , error =  0.0
Saving @ iter  400000
Learning rate:  0.0025
validation @ iter 400000
epoch 0, iter 400000, train buffer error 0.400000 %
epoch 0, iter 400000, validation loss 0.018077
epoch 0, iter 400000, validation error 0.532000 %
patience before checkBest 480000
patience after checkBest 480000
training @ iter = 400000 , loss =  0.000622161256615
training @ iter = 400000 , error =  0.0
training @ iter = 400100 , loss =  0.000734639004804
training @ iter = 400100 , error =  0.0
training @ iter = 400200 , loss =  0.139997944236
training @ iter = 400200 , error =  0.02
training @ iter = 400300 , loss =  0.0574105829
training @ iter = 400300 , error =  0.02
training @ iter = 400400 , loss =  0.00123831804376
training @ iter = 400400 , error =  0.0
training @ iter = 400500 , loss =  0.0050997491926
training @ iter = 400500 , error =  0.0
training @ iter = 400600 , loss =  0.0248727463186
training @ iter = 400600 , error =  0.02
training @ iter = 400700 , loss =  0.0029208464548
training @ iter = 400700 , error =  0.0
training @ iter = 400800 , loss =  0.0287793558091
training @ iter = 400800 , error =  0.02
training @ iter = 400900 , loss =  0.000577300204895
training @ iter = 400900 , error =  0.0
training @ iter = 401000 , loss =  0.0090521639213
training @ iter = 401000 , error =  0.0
training @ iter = 401100 , loss =  0.00108863401692
training @ iter = 401100 , error =  0.0
training @ iter = 401200 , loss =  0.00335577130318
training @ iter = 401200 , error =  0.0
training @ iter = 401300 , loss =  0.00274217734113
training @ iter = 401300 , error =  0.0
training @ iter = 401400 , loss =  0.00788917765021
training @ iter = 401400 , error =  0.0
training @ iter = 401500 , loss =  0.00348177202977
training @ iter = 401500 , error =  0.0
training @ iter = 401600 , loss =  0.0466200150549
training @ iter = 401600 , error =  0.02
training @ iter = 401700 , loss =  0.00381169933826
training @ iter = 401700 , error =  0.0
training @ iter = 401800 , loss =  0.0039259805344
training @ iter = 401800 , error =  0.0
training @ iter = 401900 , loss =  0.0139707969502
training @ iter = 401900 , error =  0.0
training @ iter = 402000 , loss =  0.00941911898553
training @ iter = 402000 , error =  0.0
training @ iter = 402100 , loss =  0.00198743352666
training @ iter = 402100 , error =  0.0
training @ iter = 402200 , loss =  0.00164155440871
training @ iter = 402200 , error =  0.0
training @ iter = 402300 , loss =  0.00933412928134
training @ iter = 402300 , error =  0.0
training @ iter = 402400 , loss =  0.00210476736538
training @ iter = 402400 , error =  0.0
training @ iter = 402500 , loss =  0.00602532550693
training @ iter = 402500 , error =  0.0
training @ iter = 402600 , loss =  0.000436348753283
training @ iter = 402600 , error =  0.0
training @ iter = 402700 , loss =  0.0149389430881
training @ iter = 402700 , error =  0.0
training @ iter = 402800 , loss =  0.00371173978783
training @ iter = 402800 , error =  0.0
training @ iter = 402900 , loss =  0.00076195364818
training @ iter = 402900 , error =  0.0
training @ iter = 403000 , loss =  0.00923692621291
training @ iter = 403000 , error =  0.0
training @ iter = 403100 , loss =  0.00722823245451
training @ iter = 403100 , error =  0.0
training @ iter = 403200 , loss =  0.00618337281048
training @ iter = 403200 , error =  0.0
--> train minibatch error =  0.18  at iter  403234
-->  7 33350 chunk_17_50000.pkl
training @ iter = 403300 , loss =  0.019316572696
training @ iter = 403300 , error =  0.02
training @ iter = 403400 , loss =  0.00119793880731
training @ iter = 403400 , error =  0.0
training @ iter = 403500 , loss =  0.0584666505456
training @ iter = 403500 , error =  0.02
training @ iter = 403600 , loss =  0.00112293928396
training @ iter = 403600 , error =  0.0
--> train minibatch error =  0.12  at iter  403662
-->  8 4750 chunk_18_50000.pkl
training @ iter = 403700 , loss =  0.00598070863634
training @ iter = 403700 , error =  0.0
training @ iter = 403800 , loss =  0.00298925884999
training @ iter = 403800 , error =  0.0
training @ iter = 403900 , loss =  0.0810131803155
training @ iter = 403900 , error =  0.02
training @ iter = 404000 , loss =  0.00161899824161
training @ iter = 404000 , error =  0.0
training @ iter = 404100 , loss =  0.00220604427159
training @ iter = 404100 , error =  0.0
--> train minibatch error =  0.24  at iter  404174
-->  8 30350 chunk_18_50000.pkl
training @ iter = 404200 , loss =  0.0169859472662
training @ iter = 404200 , error =  0.0
training @ iter = 404300 , loss =  0.00168812472839
training @ iter = 404300 , error =  0.0
training @ iter = 404400 , loss =  0.00139114144258
training @ iter = 404400 , error =  0.0
training @ iter = 404500 , loss =  0.0163684953004
training @ iter = 404500 , error =  0.0
training @ iter = 404600 , loss =  0.0127910468727
training @ iter = 404600 , error =  0.0
training @ iter = 404700 , loss =  0.0025005149655
training @ iter = 404700 , error =  0.0
--> train minibatch error =  0.12  at iter  404778
-->  9 10550 chunk_19_50000.pkl
training @ iter = 404800 , loss =  0.00078118086094
training @ iter = 404800 , error =  0.0
training @ iter = 404900 , loss =  0.00167580321431
training @ iter = 404900 , error =  0.0
training @ iter = 405000 , loss =  0.0417395941913
training @ iter = 405000 , error =  0.02
training @ iter = 405100 , loss =  0.0177362319082
training @ iter = 405100 , error =  0.0
training @ iter = 405200 , loss =  0.00157499010675
training @ iter = 405200 , error =  0.0
training @ iter = 405300 , loss =  0.0110658099875
training @ iter = 405300 , error =  0.0
training @ iter = 405400 , loss =  0.0220791622996
training @ iter = 405400 , error =  0.02
training @ iter = 405500 , loss =  0.00125401979312
training @ iter = 405500 , error =  0.0
training @ iter = 405600 , loss =  0.0169862769544
training @ iter = 405600 , error =  0.0
training @ iter = 405700 , loss =  0.00100102857687
training @ iter = 405700 , error =  0.0
--> train minibatch error =  0.18  at iter  405749
-->  10 9100 chunk_20_50000.pkl
training @ iter = 405800 , loss =  0.0726117119193
training @ iter = 405800 , error =  0.02
training @ iter = 405900 , loss =  0.145718276501
training @ iter = 405900 , error =  0.04
--> train minibatch error =  0.12  at iter  405901
-->  10 16700 chunk_20_50000.pkl
training @ iter = 406000 , loss =  0.00117072253488
training @ iter = 406000 , error =  0.0
training @ iter = 406100 , loss =  0.00347477383912
training @ iter = 406100 , error =  0.0
training @ iter = 406200 , loss =  0.0168760865927
training @ iter = 406200 , error =  0.0
training @ iter = 406300 , loss =  0.0222603585571
training @ iter = 406300 , error =  0.02
training @ iter = 406400 , loss =  0.00125481723808
training @ iter = 406400 , error =  0.0
training @ iter = 406500 , loss =  0.000956193194725
training @ iter = 406500 , error =  0.0
training @ iter = 406600 , loss =  0.00215918733738
training @ iter = 406600 , error =  0.0
training @ iter = 406700 , loss =  0.000689734239131
training @ iter = 406700 , error =  0.0
training @ iter = 406800 , loss =  0.00133036088664
training @ iter = 406800 , error =  0.0
training @ iter = 406900 , loss =  0.0259897634387
training @ iter = 406900 , error =  0.0
training @ iter = 407000 , loss =  0.00136699469294
training @ iter = 407000 , error =  0.0
training @ iter = 407100 , loss =  0.0062115569599
training @ iter = 407100 , error =  0.0
--> train minibatch error =  0.12  at iter  407170
-->  11 30150 chunk_21_50000.pkl
training @ iter = 407200 , loss =  0.019876210019
training @ iter = 407200 , error =  0.0
training @ iter = 407300 , loss =  0.000749517523218
training @ iter = 407300 , error =  0.0
training @ iter = 407400 , loss =  0.0193987973034
training @ iter = 407400 , error =  0.02
training @ iter = 407500 , loss =  0.0627735108137
training @ iter = 407500 , error =  0.02
training @ iter = 407600 , loss =  0.0063473652117
training @ iter = 407600 , error =  0.0
training @ iter = 407700 , loss =  0.106754481792
training @ iter = 407700 , error =  0.02
training @ iter = 407800 , loss =  0.00855514686555
training @ iter = 407800 , error =  0.0
training @ iter = 407900 , loss =  0.0324203521013
training @ iter = 407900 , error =  0.0
training @ iter = 408000 , loss =  0.14690309763
training @ iter = 408000 , error =  0.02
training @ iter = 408100 , loss =  0.0160497669131
training @ iter = 408100 , error =  0.0
training @ iter = 408200 , loss =  0.00929790362716
training @ iter = 408200 , error =  0.0
training @ iter = 408300 , loss =  0.0197882726789
training @ iter = 408300 , error =  0.02
training @ iter = 408400 , loss =  0.00424216361716
training @ iter = 408400 , error =  0.0
training @ iter = 408500 , loss =  0.00358077767305
training @ iter = 408500 , error =  0.0
training @ iter = 408600 , loss =  0.0153281996027
training @ iter = 408600 , error =  0.0
training @ iter = 408700 , loss =  0.000885813031346
training @ iter = 408700 , error =  0.0
--> train minibatch error =  0.14  at iter  408763
-->  13 9800 chunk_23_50000.pkl
training @ iter = 408800 , loss =  0.00272313598543
training @ iter = 408800 , error =  0.0
training @ iter = 408900 , loss =  0.000803602917586
training @ iter = 408900 , error =  0.0
training @ iter = 409000 , loss =  0.00120625202544
training @ iter = 409000 , error =  0.0
training @ iter = 409100 , loss =  0.00351204932667
training @ iter = 409100 , error =  0.0
training @ iter = 409200 , loss =  0.00290506053716
training @ iter = 409200 , error =  0.0
training @ iter = 409300 , loss =  0.000702190387528
training @ iter = 409300 , error =  0.0
training @ iter = 409400 , loss =  0.00609984388575
training @ iter = 409400 , error =  0.0
training @ iter = 409500 , loss =  0.0033310353756
training @ iter = 409500 , error =  0.0
training @ iter = 409600 , loss =  0.00611053407192
training @ iter = 409600 , error =  0.02
training @ iter = 409700 , loss =  0.000729138497263
training @ iter = 409700 , error =  0.0
training @ iter = 409800 , loss =  0.0306690149009
training @ iter = 409800 , error =  0.0
training @ iter = 409900 , loss =  0.0091446954757
training @ iter = 409900 , error =  0.0
validation @ iter 410000
epoch 0, iter 410000, train buffer error 0.200000 %
epoch 0, iter 410000, validation loss 0.017881
epoch 0, iter 410000, validation error 0.546000 %
patience before checkBest 480000
patience after checkBest 480000
training @ iter = 410000 , loss =  0.00165990681853
training @ iter = 410000 , error =  0.0
training @ iter = 410100 , loss =  0.0265473127365
training @ iter = 410100 , error =  0.0
training @ iter = 410200 , loss =  0.000935170217417
training @ iter = 410200 , error =  0.0
training @ iter = 410300 , loss =  0.00110608385876
training @ iter = 410300 , error =  0.0
training @ iter = 410400 , loss =  0.000325003929902
training @ iter = 410400 , error =  0.0
training @ iter = 410500 , loss =  0.00198167935014
training @ iter = 410500 , error =  0.0
training @ iter = 410600 , loss =  0.0765078440309
training @ iter = 410600 , error =  0.02
training @ iter = 410700 , loss =  0.00114259391557
training @ iter = 410700 , error =  0.0
training @ iter = 410800 , loss =  0.00175361242145
training @ iter = 410800 , error =  0.0
training @ iter = 410900 , loss =  0.000959124765359
training @ iter = 410900 , error =  0.0
training @ iter = 411000 , loss =  0.00291214813478
training @ iter = 411000 , error =  0.0
training @ iter = 411100 , loss =  0.00259034521878
training @ iter = 411100 , error =  0.0
training @ iter = 411200 , loss =  0.00905755721033
training @ iter = 411200 , error =  0.0
training @ iter = 411300 , loss =  0.0112502016127
training @ iter = 411300 , error =  0.0
training @ iter = 411400 , loss =  0.00248946528882
training @ iter = 411400 , error =  0.0
training @ iter = 411500 , loss =  0.00410229200497
training @ iter = 411500 , error =  0.0
training @ iter = 411600 , loss =  0.000578461156692
training @ iter = 411600 , error =  0.0
training @ iter = 411700 , loss =  0.00264337053522
training @ iter = 411700 , error =  0.0
training @ iter = 411800 , loss =  0.00257363473065
training @ iter = 411800 , error =  0.0
training @ iter = 411900 , loss =  0.000787235214375
training @ iter = 411900 , error =  0.0
training @ iter = 412000 , loss =  0.067055054009
training @ iter = 412000 , error =  0.02
training @ iter = 412100 , loss =  0.000549979449715
training @ iter = 412100 , error =  0.0
training @ iter = 412200 , loss =  0.0100218411535
training @ iter = 412200 , error =  0.0
training @ iter = 412300 , loss =  0.00117318017874
training @ iter = 412300 , error =  0.0
training @ iter = 412400 , loss =  0.0139004122466
training @ iter = 412400 , error =  0.02
training @ iter = 412500 , loss =  0.000498335284647
training @ iter = 412500 , error =  0.0
--> train minibatch error =  0.14  at iter  412555
-->  16 49400 chunk_26_50000.pkl
training @ iter = 412600 , loss =  0.00516498880461
training @ iter = 412600 , error =  0.0
training @ iter = 412700 , loss =  0.00295458547771
training @ iter = 412700 , error =  0.0
training @ iter = 412800 , loss =  0.00109971442726
training @ iter = 412800 , error =  0.0
training @ iter = 412900 , loss =  0.00318186730146
training @ iter = 412900 , error =  0.0
training @ iter = 413000 , loss =  0.000871425960213
training @ iter = 413000 , error =  0.0
training @ iter = 413100 , loss =  0.0215158481151
training @ iter = 413100 , error =  0.0
training @ iter = 413200 , loss =  0.0929582342505
training @ iter = 413200 , error =  0.04
training @ iter = 413300 , loss =  0.00489654624835
training @ iter = 413300 , error =  0.0
training @ iter = 413400 , loss =  0.0207614786923
training @ iter = 413400 , error =  0.0
training @ iter = 413500 , loss =  0.0285560991615
training @ iter = 413500 , error =  0.02
training @ iter = 413600 , loss =  0.00478562805802
training @ iter = 413600 , error =  0.0
training @ iter = 413700 , loss =  0.00434798700735
training @ iter = 413700 , error =  0.0
training @ iter = 413800 , loss =  0.000962825259194
training @ iter = 413800 , error =  0.0
training @ iter = 413900 , loss =  0.000952281814534
training @ iter = 413900 , error =  0.0
training @ iter = 414000 , loss =  0.00716289738193
training @ iter = 414000 , error =  0.0
training @ iter = 414100 , loss =  0.00475604040548
training @ iter = 414100 , error =  0.0
training @ iter = 414200 , loss =  0.00974408257753
training @ iter = 414200 , error =  0.0
ERROR:  /home/shared/Fields_12-2015/chunks_feat_50000/chunks_train/chunk_28_50000.pkl  has  4  candidates.
training @ iter = 414300 , loss =  0.183784678578
training @ iter = 414300 , error =  0.04
training @ iter = 414400 , loss =  0.0489722192287
training @ iter = 414400 , error =  0.02
training @ iter = 414500 , loss =  0.00109093217179
training @ iter = 414500 , error =  0.0
training @ iter = 414600 , loss =  0.00206667324528
training @ iter = 414600 , error =  0.0
training @ iter = 414700 , loss =  0.00522690545768
training @ iter = 414700 , error =  0.0
training @ iter = 414800 , loss =  0.0360148400068
training @ iter = 414800 , error =  0.02
training @ iter = 414900 , loss =  0.0213936213404
training @ iter = 414900 , error =  0.0
training @ iter = 415000 , loss =  0.000994274276309
training @ iter = 415000 , error =  0.0
training @ iter = 415100 , loss =  0.00252797757275
training @ iter = 415100 , error =  0.0
training @ iter = 415200 , loss =  0.000524842354935
training @ iter = 415200 , error =  0.0
training @ iter = 415300 , loss =  0.000955668685492
training @ iter = 415300 , error =  0.0
training @ iter = 415400 , loss =  0.00179530109745
training @ iter = 415400 , error =  0.0
--> train minibatch error =  0.28  at iter  415408
-->  20 5900 chunk_5_50000.pkl
--> train minibatch error =  0.16  at iter  415409
-->  20 5950 chunk_5_50000.pkl
training @ iter = 415500 , loss =  0.0136209372431
training @ iter = 415500 , error =  0.02
training @ iter = 415600 , loss =  0.0336381569505
training @ iter = 415600 , error =  0.02
training @ iter = 415700 , loss =  0.0138608003035
training @ iter = 415700 , error =  0.0
training @ iter = 415800 , loss =  0.0045123109594
training @ iter = 415800 , error =  0.0
training @ iter = 415900 , loss =  0.00125163630582
training @ iter = 415900 , error =  0.0
training @ iter = 416000 , loss =  0.000720454903785
training @ iter = 416000 , error =  0.0
training @ iter = 416100 , loss =  0.000439284776803
training @ iter = 416100 , error =  0.0
training @ iter = 416200 , loss =  0.0045504886657
training @ iter = 416200 , error =  0.0
training @ iter = 416300 , loss =  0.0126799512655
training @ iter = 416300 , error =  0.0
training @ iter = 416400 , loss =  0.00135379016865
training @ iter = 416400 , error =  0.0
training @ iter = 416500 , loss =  0.00498502328992
training @ iter = 416500 , error =  0.0
training @ iter = 416600 , loss =  0.211338505149
training @ iter = 416600 , error =  0.06
training @ iter = 416700 , loss =  0.113610684872
training @ iter = 416700 , error =  0.02
training @ iter = 416800 , loss =  0.0261317752302
training @ iter = 416800 , error =  0.02
training @ iter = 416900 , loss =  0.0104106077924
training @ iter = 416900 , error =  0.0
training @ iter = 417000 , loss =  0.00414203107357
training @ iter = 417000 , error =  0.0
training @ iter = 417100 , loss =  0.0115073202178
training @ iter = 417100 , error =  0.0
training @ iter = 417200 , loss =  0.0676147639751
training @ iter = 417200 , error =  0.02
training @ iter = 417300 , loss =  0.00210964400321
training @ iter = 417300 , error =  0.0
training @ iter = 417400 , loss =  0.124721676111
training @ iter = 417400 , error =  0.02
training @ iter = 417500 , loss =  0.0342157557607
training @ iter = 417500 , error =  0.02
training @ iter = 417600 , loss =  0.000517389620654
training @ iter = 417600 , error =  0.0
training @ iter = 417700 , loss =  0.00763867842034
training @ iter = 417700 , error =  0.0
training @ iter = 417800 , loss =  0.000732979504392
training @ iter = 417800 , error =  0.0
training @ iter = 417900 , loss =  0.00715215737
training @ iter = 417900 , error =  0.0
training @ iter = 418000 , loss =  0.0145797859877
training @ iter = 418000 , error =  0.0
training @ iter = 418100 , loss =  0.00240372237749
training @ iter = 418100 , error =  0.0
training @ iter = 418200 , loss =  0.0326388515532
training @ iter = 418200 , error =  0.02
training @ iter = 418300 , loss =  0.000529335986357
training @ iter = 418300 , error =  0.0
training @ iter = 418400 , loss =  0.00170965399593
training @ iter = 418400 , error =  0.0
training @ iter = 418500 , loss =  0.019211506471
training @ iter = 418500 , error =  0.0
training @ iter = 418600 , loss =  0.00119855511002
training @ iter = 418600 , error =  0.0
training @ iter = 418700 , loss =  0.044337105006
training @ iter = 418700 , error =  0.04
training @ iter = 418800 , loss =  0.0265895612538
training @ iter = 418800 , error =  0.0
training @ iter = 418900 , loss =  0.148153841496
training @ iter = 418900 , error =  0.04
--> train minibatch error =  0.14  at iter  418928
-->  23 31900 chunk_8_50000.pkl
training @ iter = 419000 , loss =  0.0014679771848
training @ iter = 419000 , error =  0.0
training @ iter = 419100 , loss =  0.00848887581378
training @ iter = 419100 , error =  0.0
training @ iter = 419200 , loss =  0.000951146939769
training @ iter = 419200 , error =  0.0
training @ iter = 419300 , loss =  0.0063325301744
training @ iter = 419300 , error =  0.0
training @ iter = 419400 , loss =  0.00119984266348
training @ iter = 419400 , error =  0.0
training @ iter = 419500 , loss =  0.117031939328
training @ iter = 419500 , error =  0.04
training @ iter = 419600 , loss =  0.00834676064551
training @ iter = 419600 , error =  0.02
training @ iter = 419700 , loss =  0.0015466415789
training @ iter = 419700 , error =  0.0
training @ iter = 419800 , loss =  0.0195553246886
training @ iter = 419800 , error =  0.0
training @ iter = 419900 , loss =  0.000793388928287
training @ iter = 419900 , error =  0.0
--> train minibatch error =  0.22  at iter  419984
-->  24 34700 chunk_9_50000.pkl
--> train minibatch error =  0.2  at iter  419985
-->  24 34750 chunk_9_50000.pkl
--> train minibatch error =  0.14  at iter  419986
-->  24 34800 chunk_9_50000.pkl
validation @ iter 420000
epoch 0, iter 420000, train buffer error 2.200000 %
epoch 0, iter 420000, validation loss 0.020524
epoch 0, iter 420000, validation error 0.640000 %
patience before checkBest 480000
patience after checkBest 480000
training @ iter = 420000 , loss =  0.0155646679923
training @ iter = 420000 , error =  0.0
training @ iter = 420100 , loss =  0.00306131574325
training @ iter = 420100 , error =  0.0
training @ iter = 420200 , loss =  0.00547050777823
training @ iter = 420200 , error =  0.0
Epoch  17 , iteration  420291 training @ iter = 420300 , loss =  0.0841388478875
training @ iter = 420300 , error =  0.02
training @ iter = 420400 , loss =  0.00110556965228
training @ iter = 420400 , error =  0.0
training @ iter = 420500 , loss =  0.0683160796762
training @ iter = 420500 , error =  0.02
training @ iter = 420600 , loss =  0.000686091487296
training @ iter = 420600 , error =  0.0
training @ iter = 420700 , loss =  0.00297128292732
training @ iter = 420700 , error =  0.0
training @ iter = 420800 , loss =  0.00231617712416
training @ iter = 420800 , error =  0.0
training @ iter = 420900 , loss =  0.00101951346733
training @ iter = 420900 , error =  0.0
training @ iter = 421000 , loss =  0.00363915390335
training @ iter = 421000 , error =  0.0
training @ iter = 421100 , loss =  0.000259846361587
training @ iter = 421100 , error =  0.0
training @ iter = 421200 , loss =  0.00394962914288
training @ iter = 421200 , error =  0.0
training @ iter = 421300 , loss =  0.0040015373379
training @ iter = 421300 , error =  0.0
training @ iter = 421400 , loss =  0.0481590554118
training @ iter = 421400 , error =  0.02
training @ iter = 421500 , loss =  0.00190815504175
training @ iter = 421500 , error =  0.0
training @ iter = 421600 , loss =  0.00099720119033
training @ iter = 421600 , error =  0.0
training @ iter = 421700 , loss =  0.00122923357412
training @ iter = 421700 , error =  0.0
training @ iter = 421800 , loss =  0.00465116277337
training @ iter = 421800 , error =  0.0
training @ iter = 421900 , loss =  0.0295026376843
training @ iter = 421900 , error =  0.02
training @ iter = 422000 , loss =  0.000645675288979
training @ iter = 422000 , error =  0.0
training @ iter = 422100 , loss =  0.155103638768
training @ iter = 422100 , error =  0.04
training @ iter = 422200 , loss =  0.000522459158674
training @ iter = 422200 , error =  0.0
training @ iter = 422300 , loss =  0.00111417775042
training @ iter = 422300 , error =  0.0
training @ iter = 422400 , loss =  0.00129430054221
training @ iter = 422400 , error =  0.0
training @ iter = 422500 , loss =  0.0196811240166
training @ iter = 422500 , error =  0.0
training @ iter = 422600 , loss =  0.155094265938
training @ iter = 422600 , error =  0.02
training @ iter = 422700 , loss =  0.000736032845452
training @ iter = 422700 , error =  0.0
training @ iter = 422800 , loss =  0.00578236207366
training @ iter = 422800 , error =  0.0
training @ iter = 422900 , loss =  0.098440952599
training @ iter = 422900 , error =  0.02
training @ iter = 423000 , loss =  0.0431122966111
training @ iter = 423000 , error =  0.02
training @ iter = 423100 , loss =  0.00218768417835
training @ iter = 423100 , error =  0.0
training @ iter = 423200 , loss =  0.00332641461864
training @ iter = 423200 , error =  0.0
training @ iter = 423300 , loss =  0.00167990173213
training @ iter = 423300 , error =  0.0
training @ iter = 423400 , loss =  0.00871678441763
training @ iter = 423400 , error =  0.0
training @ iter = 423500 , loss =  0.00103118061088
training @ iter = 423500 , error =  0.0
training @ iter = 423600 , loss =  0.00227306480519
training @ iter = 423600 , error =  0.0
training @ iter = 423700 , loss =  0.00323726958595
training @ iter = 423700 , error =  0.0
training @ iter = 423800 , loss =  0.0322731584311
training @ iter = 423800 , error =  0.02
training @ iter = 423900 , loss =  0.0408531874418
training @ iter = 423900 , error =  0.02
training @ iter = 424000 , loss =  0.00232780515216
training @ iter = 424000 , error =  0.0
training @ iter = 424100 , loss =  0.0027181848418
training @ iter = 424100 , error =  0.0
training @ iter = 424200 , loss =  0.00165006634779
training @ iter = 424200 , error =  0.0
training @ iter = 424300 , loss =  0.000509034085553
training @ iter = 424300 , error =  0.0
training @ iter = 424400 , loss =  0.00188825430814
training @ iter = 424400 , error =  0.0
training @ iter = 424500 , loss =  0.203008174896
training @ iter = 424500 , error =  0.02
training @ iter = 424600 , loss =  0.00771101890132
training @ iter = 424600 , error =  0.0
training @ iter = 424700 , loss =  0.00063110498013
training @ iter = 424700 , error =  0.0
training @ iter = 424800 , loss =  0.00434641167521
training @ iter = 424800 , error =  0.0
training @ iter = 424900 , loss =  0.0012546768412
training @ iter = 424900 , error =  0.0
Saving @ iter  425000
training @ iter = 425000 , loss =  0.0328215435147
training @ iter = 425000 , error =  0.02
training @ iter = 425100 , loss =  0.00567640224472
training @ iter = 425100 , error =  0.0
training @ iter = 425200 , loss =  0.026124605909
training @ iter = 425200 , error =  0.02
training @ iter = 425300 , loss =  0.161170393229
training @ iter = 425300 , error =  0.02
training @ iter = 425400 , loss =  0.000604042201303
training @ iter = 425400 , error =  0.0
training @ iter = 425500 , loss =  0.0239463020116
training @ iter = 425500 , error =  0.0
training @ iter = 425600 , loss =  0.00189178495202
training @ iter = 425600 , error =  0.0
training @ iter = 425700 , loss =  0.00403617834672
training @ iter = 425700 , error =  0.0
training @ iter = 425800 , loss =  0.00273348414339
training @ iter = 425800 , error =  0.0
training @ iter = 425900 , loss =  0.00188859726768
training @ iter = 425900 , error =  0.0
training @ iter = 426000 , loss =  0.0701491236687
training @ iter = 426000 , error =  0.02
training @ iter = 426100 , loss =  0.000391924171709
training @ iter = 426100 , error =  0.0
training @ iter = 426200 , loss =  0.0151684805751
training @ iter = 426200 , error =  0.02
training @ iter = 426300 , loss =  0.000332879862981
training @ iter = 426300 , error =  0.0
training @ iter = 426400 , loss =  0.00155022006948
training @ iter = 426400 , error =  0.0
training @ iter = 426500 , loss =  0.00645383819938
training @ iter = 426500 , error =  0.0
training @ iter = 426600 , loss =  0.0375953540206
training @ iter = 426600 , error =  0.02
training @ iter = 426700 , loss =  0.00235761096701
training @ iter = 426700 , error =  0.0
training @ iter = 426800 , loss =  0.047240331769
training @ iter = 426800 , error =  0.02
training @ iter = 426900 , loss =  0.00106621615123
training @ iter = 426900 , error =  0.0
training @ iter = 427000 , loss =  0.00171002536081
training @ iter = 427000 , error =  0.0
training @ iter = 427100 , loss =  0.00223558093421
training @ iter = 427100 , error =  0.0
training @ iter = 427200 , loss =  0.126889035106
training @ iter = 427200 , error =  0.02
training @ iter = 427300 , loss =  0.00275482540019
training @ iter = 427300 , error =  0.0
training @ iter = 427400 , loss =  0.120814189315
training @ iter = 427400 , error =  0.02
training @ iter = 427500 , loss =  0.00642056483775
training @ iter = 427500 , error =  0.0
training @ iter = 427600 , loss =  0.00311717693694
training @ iter = 427600 , error =  0.0
training @ iter = 427700 , loss =  0.000537203333806
training @ iter = 427700 , error =  0.0
training @ iter = 427800 , loss =  0.00743815302849
training @ iter = 427800 , error =  0.0
training @ iter = 427900 , loss =  0.0184077117592
training @ iter = 427900 , error =  0.0
--> train minibatch error =  0.18  at iter  427957
-->  7 33350 chunk_17_50000.pkl
training @ iter = 428000 , loss =  0.0141696929932
training @ iter = 428000 , error =  0.0
training @ iter = 428100 , loss =  0.00179917900823
training @ iter = 428100 , error =  0.0
training @ iter = 428200 , loss =  0.00170195067767
training @ iter = 428200 , error =  0.0
training @ iter = 428300 , loss =  0.0283610112965
training @ iter = 428300 , error =  0.02
--> train minibatch error =  0.12  at iter  428385
-->  8 4750 chunk_18_50000.pkl
training @ iter = 428400 , loss =  0.000925892440137
training @ iter = 428400 , error =  0.0
training @ iter = 428500 , loss =  0.000769166217651
training @ iter = 428500 , error =  0.0
training @ iter = 428600 , loss =  0.00304334540851
training @ iter = 428600 , error =  0.0
training @ iter = 428700 , loss =  0.00259078363888
training @ iter = 428700 , error =  0.0
training @ iter = 428800 , loss =  0.00292891263962
training @ iter = 428800 , error =  0.0
--> train minibatch error =  0.24  at iter  428897
-->  8 30350 chunk_18_50000.pkl
training @ iter = 428900 , loss =  0.00156660971697
training @ iter = 428900 , error =  0.0
training @ iter = 429000 , loss =  0.0673996508121
training @ iter = 429000 , error =  0.02
training @ iter = 429100 , loss =  0.0256974324584
training @ iter = 429100 , error =  0.0
training @ iter = 429200 , loss =  0.00138157070614
training @ iter = 429200 , error =  0.0
training @ iter = 429300 , loss =  0.000342637300491
training @ iter = 429300 , error =  0.0
training @ iter = 429400 , loss =  0.0108612701297
training @ iter = 429400 , error =  0.0
training @ iter = 429500 , loss =  0.0081602036953
training @ iter = 429500 , error =  0.0
--> train minibatch error =  0.12  at iter  429501
-->  9 10550 chunk_19_50000.pkl
training @ iter = 429600 , loss =  0.0120928399265
training @ iter = 429600 , error =  0.0
training @ iter = 429700 , loss =  0.00104148243554
training @ iter = 429700 , error =  0.0
training @ iter = 429800 , loss =  0.00110787514132
training @ iter = 429800 , error =  0.0
training @ iter = 429900 , loss =  0.00171471072827
training @ iter = 429900 , error =  0.0
validation @ iter 430000
epoch 0, iter 430000, train buffer error 0.300000 %
epoch 0, iter 430000, validation loss 0.017512
epoch 0, iter 430000, validation error 0.540000 %
patience before checkBest 480000
patience after checkBest 480000
training @ iter = 430000 , loss =  0.0114652812481
training @ iter = 430000 , error =  0.0
training @ iter = 430100 , loss =  0.105220466852
training @ iter = 430100 , error =  0.02
training @ iter = 430200 , loss =  0.00254945340566
training @ iter = 430200 , error =  0.0
training @ iter = 430300 , loss =  0.0140569005162
training @ iter = 430300 , error =  0.0
training @ iter = 430400 , loss =  0.106559209526
training @ iter = 430400 , error =  0.04
--> train minibatch error =  0.18  at iter  430472
-->  10 9100 chunk_20_50000.pkl
training @ iter = 430500 , loss =  0.00131761003286
training @ iter = 430500 , error =  0.0
training @ iter = 430600 , loss =  0.0955158695579
training @ iter = 430600 , error =  0.02
--> train minibatch error =  0.12  at iter  430624
-->  10 16700 chunk_20_50000.pkl
training @ iter = 430700 , loss =  0.00147460668813
training @ iter = 430700 , error =  0.0
training @ iter = 430800 , loss =  0.00231979228556
training @ iter = 430800 , error =  0.0
training @ iter = 430900 , loss =  0.000873672950547
training @ iter = 430900 , error =  0.0
training @ iter = 431000 , loss =  0.0010426773224
training @ iter = 431000 , error =  0.0
training @ iter = 431100 , loss =  0.0053367447108
training @ iter = 431100 , error =  0.0
training @ iter = 431200 , loss =  0.00564223807305
training @ iter = 431200 , error =  0.0
training @ iter = 431300 , loss =  0.000430693151429
training @ iter = 431300 , error =  0.0
training @ iter = 431400 , loss =  0.0135332476348
training @ iter = 431400 , error =  0.0
training @ iter = 431500 , loss =  0.000705395883415
training @ iter = 431500 , error =  0.0
training @ iter = 431600 , loss =  0.00244295177981
training @ iter = 431600 , error =  0.0
training @ iter = 431700 , loss =  0.013181257993
training @ iter = 431700 , error =  0.0
training @ iter = 431800 , loss =  0.016853461042
training @ iter = 431800 , error =  0.0
--> train minibatch error =  0.12  at iter  431893
-->  11 30150 chunk_21_50000.pkl
training @ iter = 431900 , loss =  0.00630665291101
training @ iter = 431900 , error =  0.0
training @ iter = 432000 , loss =  0.00150171469431
training @ iter = 432000 , error =  0.0
training @ iter = 432100 , loss =  0.00082009943435
training @ iter = 432100 , error =  0.0
training @ iter = 432200 , loss =  0.00067917740671
training @ iter = 432200 , error =  0.0
training @ iter = 432300 , loss =  0.00176971580368
training @ iter = 432300 , error =  0.0
training @ iter = 432400 , loss =  0.000907754816581
training @ iter = 432400 , error =  0.0
training @ iter = 432500 , loss =  0.00331981666386
training @ iter = 432500 , error =  0.0
training @ iter = 432600 , loss =  0.00723415566608
training @ iter = 432600 , error =  0.0
training @ iter = 432700 , loss =  0.00215664901771
training @ iter = 432700 , error =  0.0
training @ iter = 432800 , loss =  0.0041332738474
training @ iter = 432800 , error =  0.0
training @ iter = 432900 , loss =  0.00126094103325
training @ iter = 432900 , error =  0.0
training @ iter = 433000 , loss =  0.00235082861036
training @ iter = 433000 , error =  0.0
training @ iter = 433100 , loss =  0.000786218210123
training @ iter = 433100 , error =  0.0
training @ iter = 433200 , loss =  0.000924292195123
training @ iter = 433200 , error =  0.0
training @ iter = 433300 , loss =  0.000409293803386
training @ iter = 433300 , error =  0.0
training @ iter = 433400 , loss =  0.000780747854151
training @ iter = 433400 , error =  0.0
--> train minibatch error =  0.14  at iter  433486
-->  13 9800 chunk_23_50000.pkl
training @ iter = 433500 , loss =  0.00964783784002
training @ iter = 433500 , error =  0.0
training @ iter = 433600 , loss =  0.00367879401892
training @ iter = 433600 , error =  0.0
training @ iter = 433700 , loss =  0.0521700829268
training @ iter = 433700 , error =  0.02
training @ iter = 433800 , loss =  0.015299023129
training @ iter = 433800 , error =  0.02
training @ iter = 433900 , loss =  0.00153990392573
training @ iter = 433900 , error =  0.0
training @ iter = 434000 , loss =  0.00140108331107
training @ iter = 434000 , error =  0.0
training @ iter = 434100 , loss =  0.000646428961772
training @ iter = 434100 , error =  0.0
training @ iter = 434200 , loss =  0.0474362820387
training @ iter = 434200 , error =  0.0
training @ iter = 434300 , loss =  0.0125248124823
training @ iter = 434300 , error =  0.0
training @ iter = 434400 , loss =  0.0063308943063
training @ iter = 434400 , error =  0.0
training @ iter = 434500 , loss =  0.00170057627838
training @ iter = 434500 , error =  0.0
training @ iter = 434600 , loss =  0.117762975395
training @ iter = 434600 , error =  0.02
training @ iter = 434700 , loss =  0.000406978419051
training @ iter = 434700 , error =  0.0
training @ iter = 434800 , loss =  0.00363455177285
training @ iter = 434800 , error =  0.0
training @ iter = 434900 , loss =  0.00297272088937
training @ iter = 434900 , error =  0.0
training @ iter = 435000 , loss =  0.00387746654451
training @ iter = 435000 , error =  0.0
training @ iter = 435100 , loss =  0.0824060216546
training @ iter = 435100 , error =  0.02
training @ iter = 435200 , loss =  0.00366898346692
training @ iter = 435200 , error =  0.0
training @ iter = 435300 , loss =  0.12178670615
training @ iter = 435300 , error =  0.02
training @ iter = 435400 , loss =  0.0018386754673
training @ iter = 435400 , error =  0.0
training @ iter = 435500 , loss =  0.00771709252149
training @ iter = 435500 , error =  0.0
training @ iter = 435600 , loss =  0.0337040051818
training @ iter = 435600 , error =  0.02
training @ iter = 435700 , loss =  0.000826897041406
training @ iter = 435700 , error =  0.0
training @ iter = 435800 , loss =  0.0596843063831
training @ iter = 435800 , error =  0.02
training @ iter = 435900 , loss =  0.000569296185859
training @ iter = 435900 , error =  0.0
training @ iter = 436000 , loss =  0.00202014273964
training @ iter = 436000 , error =  0.0
training @ iter = 436100 , loss =  0.00766416545957
training @ iter = 436100 , error =  0.0
training @ iter = 436200 , loss =  0.0804355442524
training @ iter = 436200 , error =  0.02
training @ iter = 436300 , loss =  0.00242494815029
training @ iter = 436300 , error =  0.0
training @ iter = 436400 , loss =  0.0276153758168
training @ iter = 436400 , error =  0.02
training @ iter = 436500 , loss =  0.0012673297897
training @ iter = 436500 , error =  0.0
training @ iter = 436600 , loss =  0.000381590944016
training @ iter = 436600 , error =  0.0
training @ iter = 436700 , loss =  0.00165947107598
training @ iter = 436700 , error =  0.0
training @ iter = 436800 , loss =  0.00469179591164
training @ iter = 436800 , error =  0.0
training @ iter = 436900 , loss =  0.00932625960559
training @ iter = 436900 , error =  0.0
training @ iter = 437000 , loss =  0.00744593981653
training @ iter = 437000 , error =  0.02
training @ iter = 437100 , loss =  0.0452462248504
training @ iter = 437100 , error =  0.02
training @ iter = 437200 , loss =  0.00340777169913
training @ iter = 437200 , error =  0.0
--> train minibatch error =  0.14  at iter  437278
-->  16 49400 chunk_26_50000.pkl
training @ iter = 437300 , loss =  0.00336647266522
training @ iter = 437300 , error =  0.0
training @ iter = 437400 , loss =  0.0027310794685
training @ iter = 437400 , error =  0.0
training @ iter = 437500 , loss =  0.00378041202202
training @ iter = 437500 , error =  0.0
training @ iter = 437600 , loss =  0.000973662710749
training @ iter = 437600 , error =  0.0
training @ iter = 437700 , loss =  0.146397471428
training @ iter = 437700 , error =  0.04
training @ iter = 437800 , loss =  0.00176539865788
training @ iter = 437800 , error =  0.0
training @ iter = 437900 , loss =  0.0352309383452
training @ iter = 437900 , error =  0.02
training @ iter = 438000 , loss =  0.00100628938526
training @ iter = 438000 , error =  0.0
training @ iter = 438100 , loss =  0.00404157303274
training @ iter = 438100 , error =  0.0
training @ iter = 438200 , loss =  0.00163812574465
training @ iter = 438200 , error =  0.0
training @ iter = 438300 , loss =  0.0692635327578
training @ iter = 438300 , error =  0.04
training @ iter = 438400 , loss =  0.00110519363079
training @ iter = 438400 , error =  0.0
training @ iter = 438500 , loss =  0.024930851534
training @ iter = 438500 , error =  0.0
training @ iter = 438600 , loss =  0.000387470499845
training @ iter = 438600 , error =  0.0
training @ iter = 438700 , loss =  0.00571368681267
training @ iter = 438700 , error =  0.0
training @ iter = 438800 , loss =  0.000574438483454
training @ iter = 438800 , error =  0.0
training @ iter = 438900 , loss =  0.0134455701336
training @ iter = 438900 , error =  0.0
training @ iter = 439000 , loss =  0.004001442343
training @ iter = 439000 , error =  0.0
ERROR:  /home/shared/Fields_12-2015/chunks_feat_50000/chunks_train/chunk_28_50000.pkl  has  4  candidates.
training @ iter = 439100 , loss =  0.108501978219
training @ iter = 439100 , error =  0.02
training @ iter = 439200 , loss =  0.000493799510878
training @ iter = 439200 , error =  0.0
training @ iter = 439300 , loss =  0.0894285589457
training @ iter = 439300 , error =  0.04
training @ iter = 439400 , loss =  0.00209202547558
training @ iter = 439400 , error =  0.0
training @ iter = 439500 , loss =  0.000357905315468
training @ iter = 439500 , error =  0.0
training @ iter = 439600 , loss =  0.0144640533254
training @ iter = 439600 , error =  0.0
training @ iter = 439700 , loss =  0.105680197477
training @ iter = 439700 , error =  0.04
training @ iter = 439800 , loss =  0.0129595408216
training @ iter = 439800 , error =  0.0
training @ iter = 439900 , loss =  0.00279474607669
training @ iter = 439900 , error =  0.0
validation @ iter 440000
epoch 0, iter 440000, train buffer error 0.500000 %
epoch 0, iter 440000, validation loss 0.017972
epoch 0, iter 440000, validation error 0.554000 %
patience before checkBest 480000
patience after checkBest 480000
training @ iter = 440000 , loss =  0.000900718732737
training @ iter = 440000 , error =  0.0
training @ iter = 440100 , loss =  0.0547977387905
training @ iter = 440100 , error =  0.02
--> train minibatch error =  0.26  at iter  440131
-->  20 5900 chunk_5_50000.pkl
--> train minibatch error =  0.16  at iter  440132
-->  20 5950 chunk_5_50000.pkl
training @ iter = 440200 , loss =  0.00728492485359
training @ iter = 440200 , error =  0.0
training @ iter = 440300 , loss =  0.000961511279456
training @ iter = 440300 , error =  0.0
training @ iter = 440400 , loss =  0.000325827277265
training @ iter = 440400 , error =  0.0
training @ iter = 440500 , loss =  0.0026520753745
training @ iter = 440500 , error =  0.0
training @ iter = 440600 , loss =  0.000595461518969
training @ iter = 440600 , error =  0.0
training @ iter = 440700 , loss =  0.00184124975931
training @ iter = 440700 , error =  0.0
training @ iter = 440800 , loss =  0.0763904154301
training @ iter = 440800 , error =  0.02
training @ iter = 440900 , loss =  0.00168350432068
training @ iter = 440900 , error =  0.0
training @ iter = 441000 , loss =  0.187214359641
training @ iter = 441000 , error =  0.02
training @ iter = 441100 , loss =  0.00150170212146
training @ iter = 441100 , error =  0.0
training @ iter = 441200 , loss =  0.00153220375068
training @ iter = 441200 , error =  0.0
training @ iter = 441300 , loss =  0.00282806809992
training @ iter = 441300 , error =  0.0
training @ iter = 441400 , loss =  0.000971349771135
training @ iter = 441400 , error =  0.0
training @ iter = 441500 , loss =  0.00184708123561
training @ iter = 441500 , error =  0.0
training @ iter = 441600 , loss =  0.00215281662531
training @ iter = 441600 , error =  0.0
training @ iter = 441700 , loss =  0.0116177359596
training @ iter = 441700 , error =  0.0
training @ iter = 441800 , loss =  0.039354108274
training @ iter = 441800 , error =  0.02
training @ iter = 441900 , loss =  0.00342894415371
training @ iter = 441900 , error =  0.0
training @ iter = 442000 , loss =  0.000555151316803
training @ iter = 442000 , error =  0.0
training @ iter = 442100 , loss =  0.0144390370697
training @ iter = 442100 , error =  0.02
training @ iter = 442200 , loss =  0.0138020869344
training @ iter = 442200 , error =  0.0
training @ iter = 442300 , loss =  0.0124546699226
training @ iter = 442300 , error =  0.0
training @ iter = 442400 , loss =  0.0049469540827
training @ iter = 442400 , error =  0.0
training @ iter = 442500 , loss =  0.00160086492542
training @ iter = 442500 , error =  0.0
training @ iter = 442600 , loss =  0.00857397634536
training @ iter = 442600 , error =  0.0
training @ iter = 442700 , loss =  0.001260522753
training @ iter = 442700 , error =  0.0
training @ iter = 442800 , loss =  0.0544190518558
training @ iter = 442800 , error =  0.02
training @ iter = 442900 , loss =  0.00267263734713
training @ iter = 442900 , error =  0.0
training @ iter = 443000 , loss =  0.00329186138697
training @ iter = 443000 , error =  0.0
training @ iter = 443100 , loss =  0.00699252821505
training @ iter = 443100 , error =  0.0
training @ iter = 443200 , loss =  0.00133706373163
training @ iter = 443200 , error =  0.0
training @ iter = 443300 , loss =  0.00232719769701
training @ iter = 443300 , error =  0.0
training @ iter = 443400 , loss =  0.00227328459732
training @ iter = 443400 , error =  0.0
training @ iter = 443500 , loss =  0.211836069822
training @ iter = 443500 , error =  0.02
training @ iter = 443600 , loss =  0.000810865778476
training @ iter = 443600 , error =  0.0
--> train minibatch error =  0.14  at iter  443651
-->  23 31900 chunk_8_50000.pkl
training @ iter = 443700 , loss =  0.00267390836962
training @ iter = 443700 , error =  0.0
training @ iter = 443800 , loss =  0.00140590697993
training @ iter = 443800 , error =  0.0
training @ iter = 443900 , loss =  0.00284230266698
training @ iter = 443900 , error =  0.0
training @ iter = 444000 , loss =  0.0334720239043
training @ iter = 444000 , error =  0.02
training @ iter = 444100 , loss =  0.0341253764927
training @ iter = 444100 , error =  0.0
training @ iter = 444200 , loss =  0.00161316304002
training @ iter = 444200 , error =  0.0
training @ iter = 444300 , loss =  0.000729073537514
training @ iter = 444300 , error =  0.0
training @ iter = 444400 , loss =  0.032618843019
training @ iter = 444400 , error =  0.0
training @ iter = 444500 , loss =  0.000606883491855
training @ iter = 444500 , error =  0.0
training @ iter = 444600 , loss =  0.00271384743974
training @ iter = 444600 , error =  0.0
training @ iter = 444700 , loss =  0.000778651447035
training @ iter = 444700 , error =  0.0
--> train minibatch error =  0.22  at iter  444707
-->  24 34700 chunk_9_50000.pkl
--> train minibatch error =  0.2  at iter  444708
-->  24 34750 chunk_9_50000.pkl
--> train minibatch error =  0.14  at iter  444709
-->  24 34800 chunk_9_50000.pkl
training @ iter = 444800 , loss =  0.00471126614138
training @ iter = 444800 , error =  0.0
training @ iter = 444900 , loss =  0.0348133780062
training @ iter = 444900 , error =  0.02
training @ iter = 445000 , loss =  0.0237122513354
training @ iter = 445000 , error =  0.02
Epoch  18 , iteration  445014 training @ iter = 445100 , loss =  0.126295074821
training @ iter = 445100 , error =  0.02
training @ iter = 445200 , loss =  0.0114598823711
training @ iter = 445200 , error =  0.0
training @ iter = 445300 , loss =  0.00541781820357
training @ iter = 445300 , error =  0.0
training @ iter = 445400 , loss =  0.00271892687306
training @ iter = 445400 , error =  0.0
training @ iter = 445500 , loss =  0.0118331443518
training @ iter = 445500 , error =  0.0
training @ iter = 445600 , loss =  0.00131964345928
training @ iter = 445600 , error =  0.0
training @ iter = 445700 , loss =  0.00337409554049
training @ iter = 445700 , error =  0.0
training @ iter = 445800 , loss =  0.00297428877093
training @ iter = 445800 , error =  0.0
training @ iter = 445900 , loss =  0.00092427956406
training @ iter = 445900 , error =  0.0
training @ iter = 446000 , loss =  0.00174009229522
training @ iter = 446000 , error =  0.0
training @ iter = 446100 , loss =  0.0320774018764
training @ iter = 446100 , error =  0.02
training @ iter = 446200 , loss =  0.013377610594
training @ iter = 446200 , error =  0.0
training @ iter = 446300 , loss =  0.0676947236061
training @ iter = 446300 , error =  0.02
training @ iter = 446400 , loss =  0.0030773205217
training @ iter = 446400 , error =  0.0
training @ iter = 446500 , loss =  0.000738238624763
training @ iter = 446500 , error =  0.0
training @ iter = 446600 , loss =  0.00853548385203
training @ iter = 446600 , error =  0.0
training @ iter = 446700 , loss =  0.00584150059149
training @ iter = 446700 , error =  0.0
training @ iter = 446800 , loss =  0.00172331870999
training @ iter = 446800 , error =  0.0
training @ iter = 446900 , loss =  0.0102239875123
training @ iter = 446900 , error =  0.0
training @ iter = 447000 , loss =  0.000506188778672
training @ iter = 447000 , error =  0.0
training @ iter = 447100 , loss =  0.0119261173531
training @ iter = 447100 , error =  0.0
training @ iter = 447200 , loss =  0.0646864101291
training @ iter = 447200 , error =  0.02
training @ iter = 447300 , loss =  0.00321704265662
training @ iter = 447300 , error =  0.0
training @ iter = 447400 , loss =  0.00628633983433
training @ iter = 447400 , error =  0.02
training @ iter = 447500 , loss =  0.00302207539789
training @ iter = 447500 , error =  0.0
training @ iter = 447600 , loss =  0.0368809066713
training @ iter = 447600 , error =  0.02
training @ iter = 447700 , loss =  0.00420051021501
training @ iter = 447700 , error =  0.0
training @ iter = 447800 , loss =  0.00269389082678
training @ iter = 447800 , error =  0.0
training @ iter = 447900 , loss =  0.005141264759
training @ iter = 447900 , error =  0.0
training @ iter = 448000 , loss =  0.00173328409437
training @ iter = 448000 , error =  0.0
training @ iter = 448100 , loss =  0.0015003773151
training @ iter = 448100 , error =  0.0
training @ iter = 448200 , loss =  0.005450328812
training @ iter = 448200 , error =  0.0
training @ iter = 448300 , loss =  0.000410942942835
training @ iter = 448300 , error =  0.0
training @ iter = 448400 , loss =  0.00490147154778
training @ iter = 448400 , error =  0.0
training @ iter = 448500 , loss =  0.00267434050329
training @ iter = 448500 , error =  0.0
training @ iter = 448600 , loss =  0.000570225645788
training @ iter = 448600 , error =  0.0
training @ iter = 448700 , loss =  0.0103216907009
training @ iter = 448700 , error =  0.0
training @ iter = 448800 , loss =  0.00576934171841
training @ iter = 448800 , error =  0.0
training @ iter = 448900 , loss =  0.00645869737491
training @ iter = 448900 , error =  0.0
training @ iter = 449000 , loss =  0.000645862193778
training @ iter = 449000 , error =  0.0
training @ iter = 449100 , loss =  0.000623958010692
training @ iter = 449100 , error =  0.0
training @ iter = 449200 , loss =  0.00668015191332
training @ iter = 449200 , error =  0.0
training @ iter = 449300 , loss =  0.00537152402103
training @ iter = 449300 , error =  0.0
training @ iter = 449400 , loss =  0.00225193239748
training @ iter = 449400 , error =  0.0
training @ iter = 449500 , loss =  0.00524848280475
training @ iter = 449500 , error =  0.0
training @ iter = 449600 , loss =  0.163956090808
training @ iter = 449600 , error =  0.02
training @ iter = 449700 , loss =  0.00376501074061
training @ iter = 449700 , error =  0.0
training @ iter = 449800 , loss =  0.0045562274754
training @ iter = 449800 , error =  0.0
training @ iter = 449900 , loss =  0.00190993701108
training @ iter = 449900 , error =  0.0
Saving @ iter  450000
validation @ iter 450000
epoch 0, iter 450000, train buffer error 0.200000 %
epoch 0, iter 450000, validation loss 0.017951
epoch 0, iter 450000, validation error 0.538000 %
patience before checkBest 480000
patience after checkBest 480000
training @ iter = 450000 , loss =  0.000900756567717
training @ iter = 450000 , error =  0.0
training @ iter = 450100 , loss =  0.0012036440894
training @ iter = 450100 , error =  0.0
training @ iter = 450200 , loss =  0.000972522364464
training @ iter = 450200 , error =  0.0
training @ iter = 450300 , loss =  0.00203347136267
training @ iter = 450300 , error =  0.0
training @ iter = 450400 , loss =  0.00141795293894
training @ iter = 450400 , error =  0.0
training @ iter = 450500 , loss =  0.00325038842857
training @ iter = 450500 , error =  0.0
training @ iter = 450600 , loss =  0.00129414990079
training @ iter = 450600 , error =  0.0
training @ iter = 450700 , loss =  0.0323484838009
training @ iter = 450700 , error =  0.0
training @ iter = 450800 , loss =  0.0162659063935
training @ iter = 450800 , error =  0.02
training @ iter = 450900 , loss =  0.000506861193571
training @ iter = 450900 , error =  0.0
training @ iter = 451000 , loss =  0.000628578243777
training @ iter = 451000 , error =  0.0
training @ iter = 451100 , loss =  0.00344927422702
training @ iter = 451100 , error =  0.0
training @ iter = 451200 , loss =  0.000290850584861
training @ iter = 451200 , error =  0.0
training @ iter = 451300 , loss =  0.00414058705792
training @ iter = 451300 , error =  0.0
training @ iter = 451400 , loss =  0.00224832375534
training @ iter = 451400 , error =  0.0
training @ iter = 451500 , loss =  0.000874865625519
training @ iter = 451500 , error =  0.0
training @ iter = 451600 , loss =  0.105230733752
training @ iter = 451600 , error =  0.04
training @ iter = 451700 , loss =  0.0169239714742
training @ iter = 451700 , error =  0.0
training @ iter = 451800 , loss =  0.0688482820988
training @ iter = 451800 , error =  0.04
training @ iter = 451900 , loss =  0.00166821596213
training @ iter = 451900 , error =  0.0
training @ iter = 452000 , loss =  0.0155355064198
training @ iter = 452000 , error =  0.0
training @ iter = 452100 , loss =  0.000469948659884
training @ iter = 452100 , error =  0.0
training @ iter = 452200 , loss =  0.150951504707
training @ iter = 452200 , error =  0.02
training @ iter = 452300 , loss =  0.00131515157409
training @ iter = 452300 , error =  0.0
training @ iter = 452400 , loss =  0.0719980224967
training @ iter = 452400 , error =  0.02
training @ iter = 452500 , loss =  0.00545893982053
training @ iter = 452500 , error =  0.0
training @ iter = 452600 , loss =  0.00429128715768
training @ iter = 452600 , error =  0.0
--> train minibatch error =  0.18  at iter  452680
-->  7 33350 chunk_17_50000.pkl
training @ iter = 452700 , loss =  0.00454415706918
training @ iter = 452700 , error =  0.0
training @ iter = 452800 , loss =  0.00645031686872
training @ iter = 452800 , error =  0.0
training @ iter = 452900 , loss =  0.0440732091665
training @ iter = 452900 , error =  0.02
training @ iter = 453000 , loss =  0.00112616620027
training @ iter = 453000 , error =  0.0
training @ iter = 453100 , loss =  0.00700164213777
training @ iter = 453100 , error =  0.0
--> train minibatch error =  0.12  at iter  453108
-->  8 4750 chunk_18_50000.pkl
training @ iter = 453200 , loss =  0.00158004404511
training @ iter = 453200 , error =  0.0
training @ iter = 453300 , loss =  0.00226026703604
training @ iter = 453300 , error =  0.0
training @ iter = 453400 , loss =  0.00080246507423
training @ iter = 453400 , error =  0.0
training @ iter = 453500 , loss =  0.0017198799178
training @ iter = 453500 , error =  0.0
training @ iter = 453600 , loss =  0.000826169387437
training @ iter = 453600 , error =  0.0
--> train minibatch error =  0.22  at iter  453620
-->  8 30350 chunk_18_50000.pkl
training @ iter = 453700 , loss =  0.00245464826003
training @ iter = 453700 , error =  0.0
training @ iter = 453800 , loss =  0.0522317327559
training @ iter = 453800 , error =  0.02
training @ iter = 453900 , loss =  0.00620354758576
training @ iter = 453900 , error =  0.0
training @ iter = 454000 , loss =  0.000883380416781
training @ iter = 454000 , error =  0.0
training @ iter = 454100 , loss =  0.00116690574214
training @ iter = 454100 , error =  0.0
training @ iter = 454200 , loss =  0.0117211518809
training @ iter = 454200 , error =  0.0
--> train minibatch error =  0.12  at iter  454224
-->  9 10550 chunk_19_50000.pkl
training @ iter = 454300 , loss =  0.000343462277669
training @ iter = 454300 , error =  0.0
training @ iter = 454400 , loss =  0.00109683140181
training @ iter = 454400 , error =  0.0
training @ iter = 454500 , loss =  0.000872626027558
training @ iter = 454500 , error =  0.0
training @ iter = 454600 , loss =  0.007391652558
training @ iter = 454600 , error =  0.0
training @ iter = 454700 , loss =  0.0406917780638
training @ iter = 454700 , error =  0.0
training @ iter = 454800 , loss =  0.045599590987
training @ iter = 454800 , error =  0.02
training @ iter = 454900 , loss =  0.00179949542508
training @ iter = 454900 , error =  0.0
training @ iter = 455000 , loss =  0.0252870228142
training @ iter = 455000 , error =  0.0
training @ iter = 455100 , loss =  0.000364319304936
training @ iter = 455100 , error =  0.0
--> train minibatch error =  0.18  at iter  455195
-->  10 9100 chunk_20_50000.pkl
training @ iter = 455200 , loss =  0.00074908795068
training @ iter = 455200 , error =  0.0
training @ iter = 455300 , loss =  0.00575222540647
training @ iter = 455300 , error =  0.0
--> train minibatch error =  0.12  at iter  455347
-->  10 16700 chunk_20_50000.pkl
training @ iter = 455400 , loss =  0.00438935915008
training @ iter = 455400 , error =  0.0
training @ iter = 455500 , loss =  0.035697221756
training @ iter = 455500 , error =  0.02
training @ iter = 455600 , loss =  0.00259108329192
training @ iter = 455600 , error =  0.0
training @ iter = 455700 , loss =  0.000536856008694
training @ iter = 455700 , error =  0.0
training @ iter = 455800 , loss =  0.00273765739985
training @ iter = 455800 , error =  0.0
training @ iter = 455900 , loss =  0.00495545519516
training @ iter = 455900 , error =  0.0
training @ iter = 456000 , loss =  0.00179407850374
training @ iter = 456000 , error =  0.0
training @ iter = 456100 , loss =  0.00148900807835
training @ iter = 456100 , error =  0.0
training @ iter = 456200 , loss =  0.00201477971859
training @ iter = 456200 , error =  0.0
training @ iter = 456300 , loss =  0.0609366893768
training @ iter = 456300 , error =  0.02
training @ iter = 456400 , loss =  0.205132097006
training @ iter = 456400 , error =  0.08
training @ iter = 456500 , loss =  0.0037347280886
training @ iter = 456500 , error =  0.0
training @ iter = 456600 , loss =  0.0360151343048
training @ iter = 456600 , error =  0.0
training @ iter = 456700 , loss =  0.000913477560971
training @ iter = 456700 , error =  0.0
training @ iter = 456800 , loss =  0.0815387517214
training @ iter = 456800 , error =  0.02
training @ iter = 456900 , loss =  0.00250063836575
training @ iter = 456900 , error =  0.0
training @ iter = 457000 , loss =  0.0109891723841
training @ iter = 457000 , error =  0.0
training @ iter = 457100 , loss =  0.00565306469798
training @ iter = 457100 , error =  0.0
training @ iter = 457200 , loss =  0.00416062865406
training @ iter = 457200 , error =  0.0
training @ iter = 457300 , loss =  0.00409590406343
training @ iter = 457300 , error =  0.0
training @ iter = 457400 , loss =  0.00108450872358
training @ iter = 457400 , error =  0.0
training @ iter = 457500 , loss =  0.00188673986122
training @ iter = 457500 , error =  0.0
training @ iter = 457600 , loss =  0.00506002642214
training @ iter = 457600 , error =  0.0
training @ iter = 457700 , loss =  0.106441743672
training @ iter = 457700 , error =  0.04
training @ iter = 457800 , loss =  0.000899754290003
training @ iter = 457800 , error =  0.0
training @ iter = 457900 , loss =  0.00208125077188
training @ iter = 457900 , error =  0.0
training @ iter = 458000 , loss =  0.0010653543286
training @ iter = 458000 , error =  0.0
training @ iter = 458100 , loss =  0.000438041548477
training @ iter = 458100 , error =  0.0
training @ iter = 458200 , loss =  0.000718849070836
training @ iter = 458200 , error =  0.0
--> train minibatch error =  0.14  at iter  458209
-->  13 9800 chunk_23_50000.pkl
training @ iter = 458300 , loss =  0.0550309978426
training @ iter = 458300 , error =  0.02
training @ iter = 458400 , loss =  0.000872446515132
training @ iter = 458400 , error =  0.0
training @ iter = 458500 , loss =  0.000529138196725
training @ iter = 458500 , error =  0.0
training @ iter = 458600 , loss =  0.000977456686087
training @ iter = 458600 , error =  0.0
training @ iter = 458700 , loss =  0.00297079677694
training @ iter = 458700 , error =  0.0
training @ iter = 458800 , loss =  0.0111847640947
training @ iter = 458800 , error =  0.0
training @ iter = 458900 , loss =  0.000542043009773
training @ iter = 458900 , error =  0.0
training @ iter = 459000 , loss =  0.00301249674521
training @ iter = 459000 , error =  0.0
training @ iter = 459100 , loss =  0.000985100516118
training @ iter = 459100 , error =  0.0
training @ iter = 459200 , loss =  0.000889993039891
training @ iter = 459200 , error =  0.0
training @ iter = 459300 , loss =  0.00121916423086
training @ iter = 459300 , error =  0.0
training @ iter = 459400 , loss =  0.00396894942969
training @ iter = 459400 , error =  0.0
training @ iter = 459500 , loss =  0.0105282366276
training @ iter = 459500 , error =  0.0
training @ iter = 459600 , loss =  0.0131741706282
training @ iter = 459600 , error =  0.02
training @ iter = 459700 , loss =  0.0147856473923
training @ iter = 459700 , error =  0.0
training @ iter = 459800 , loss =  0.0288273785263
training @ iter = 459800 , error =  0.02
training @ iter = 459900 , loss =  0.00109446374699
training @ iter = 459900 , error =  0.0
validation @ iter 460000
epoch 0, iter 460000, train buffer error 0.400000 %
epoch 0, iter 460000, validation loss 0.017640
epoch 0, iter 460000, validation error 0.541000 %
patience before checkBest 480000
patience after checkBest 480000
training @ iter = 460000 , loss =  0.00101801997516
training @ iter = 460000 , error =  0.0
training @ iter = 460100 , loss =  0.0349832214415
training @ iter = 460100 , error =  0.02
training @ iter = 460200 , loss =  0.00631431210786
training @ iter = 460200 , error =  0.0
training @ iter = 460300 , loss =  0.00142087554559
training @ iter = 460300 , error =  0.0
training @ iter = 460400 , loss =  0.00230013462715
training @ iter = 460400 , error =  0.0
training @ iter = 460500 , loss =  0.0014128445182
training @ iter = 460500 , error =  0.0
training @ iter = 460600 , loss =  0.00220682192594
training @ iter = 460600 , error =  0.0
training @ iter = 460700 , loss =  0.000626577588264
training @ iter = 460700 , error =  0.0
training @ iter = 460800 , loss =  0.0010569965234
training @ iter = 460800 , error =  0.0
training @ iter = 460900 , loss =  0.000659817364067
training @ iter = 460900 , error =  0.0
training @ iter = 461000 , loss =  0.00753181334585
training @ iter = 461000 , error =  0.0
training @ iter = 461100 , loss =  0.0778379663825
training @ iter = 461100 , error =  0.02
training @ iter = 461200 , loss =  0.00234999437816
training @ iter = 461200 , error =  0.0
training @ iter = 461300 , loss =  0.00300017674454
training @ iter = 461300 , error =  0.0
training @ iter = 461400 , loss =  0.000646139029413
training @ iter = 461400 , error =  0.0
training @ iter = 461500 , loss =  0.00687960721552
training @ iter = 461500 , error =  0.0
training @ iter = 461600 , loss =  0.0158694740385
training @ iter = 461600 , error =  0.0
training @ iter = 461700 , loss =  0.0433620661497
training @ iter = 461700 , error =  0.02
training @ iter = 461800 , loss =  0.00195062160492
training @ iter = 461800 , error =  0.0
training @ iter = 461900 , loss =  0.000487102312036
training @ iter = 461900 , error =  0.0
training @ iter = 462000 , loss =  0.0464250296354
training @ iter = 462000 , error =  0.04
--> train minibatch error =  0.14  at iter  462001
-->  16 49400 chunk_26_50000.pkl
training @ iter = 462100 , loss =  0.00616247486323
training @ iter = 462100 , error =  0.0
training @ iter = 462200 , loss =  0.000806502997875
training @ iter = 462200 , error =  0.0
training @ iter = 462300 , loss =  0.000464981974801
training @ iter = 462300 , error =  0.0
training @ iter = 462400 , loss =  0.00137447891757
training @ iter = 462400 , error =  0.0
training @ iter = 462500 , loss =  0.00490717450157
training @ iter = 462500 , error =  0.0
training @ iter = 462600 , loss =  0.000982443336397
training @ iter = 462600 , error =  0.0
training @ iter = 462700 , loss =  0.00112789706327
training @ iter = 462700 , error =  0.0
training @ iter = 462800 , loss =  0.00148296030238
training @ iter = 462800 , error =  0.0
training @ iter = 462900 , loss =  0.0156313963234
training @ iter = 462900 , error =  0.0
training @ iter = 463000 , loss =  0.0531361214817
training @ iter = 463000 , error =  0.02
training @ iter = 463100 , loss =  0.124464407563
training @ iter = 463100 , error =  0.04
training @ iter = 463200 , loss =  0.00655178679153
training @ iter = 463200 , error =  0.0
training @ iter = 463300 , loss =  0.121145702899
training @ iter = 463300 , error =  0.02
training @ iter = 463400 , loss =  0.000995429931208
training @ iter = 463400 , error =  0.0
training @ iter = 463500 , loss =  0.000555310864002
training @ iter = 463500 , error =  0.0
training @ iter = 463600 , loss =  0.00664572650567
training @ iter = 463600 , error =  0.0
training @ iter = 463700 , loss =  0.0129672624171
training @ iter = 463700 , error =  0.0
ERROR:  /home/shared/Fields_12-2015/chunks_feat_50000/chunks_train/chunk_28_50000.pkl  has  4  candidates.
training @ iter = 463800 , loss =  0.00157129345462
training @ iter = 463800 , error =  0.0
training @ iter = 463900 , loss =  0.0098998202011
training @ iter = 463900 , error =  0.0
training @ iter = 464000 , loss =  0.000565121707041
training @ iter = 464000 , error =  0.0
training @ iter = 464100 , loss =  0.0096588274464
training @ iter = 464100 , error =  0.0
training @ iter = 464200 , loss =  0.000600174244028
training @ iter = 464200 , error =  0.0
training @ iter = 464300 , loss =  0.00211877026595
training @ iter = 464300 , error =  0.0
training @ iter = 464400 , loss =  0.00149515236262
training @ iter = 464400 , error =  0.0
training @ iter = 464500 , loss =  0.0014858172508
training @ iter = 464500 , error =  0.0
training @ iter = 464600 , loss =  0.00266424380243
training @ iter = 464600 , error =  0.0
training @ iter = 464700 , loss =  0.00199644966051
training @ iter = 464700 , error =  0.0
training @ iter = 464800 , loss =  0.00223590410315
training @ iter = 464800 , error =  0.0
--> train minibatch error =  0.24  at iter  464854
-->  20 5900 chunk_5_50000.pkl
--> train minibatch error =  0.16  at iter  464855
-->  20 5950 chunk_5_50000.pkl
training @ iter = 464900 , loss =  0.00613696500659
training @ iter = 464900 , error =  0.0
training @ iter = 465000 , loss =  0.00141614640597
training @ iter = 465000 , error =  0.0
training @ iter = 465100 , loss =  0.00101639400236
training @ iter = 465100 , error =  0.0
training @ iter = 465200 , loss =  0.000426113780122
training @ iter = 465200 , error =  0.0
training @ iter = 465300 , loss =  0.0152796022594
training @ iter = 465300 , error =  0.0
training @ iter = 465400 , loss =  0.0840814486146
training @ iter = 465400 , error =  0.02
training @ iter = 465500 , loss =  0.00686655892059
training @ iter = 465500 , error =  0.0
training @ iter = 465600 , loss =  0.0144763281569
training @ iter = 465600 , error =  0.0
training @ iter = 465700 , loss =  0.00510892085731
training @ iter = 465700 , error =  0.0
training @ iter = 465800 , loss =  0.0120838955045
training @ iter = 465800 , error =  0.0
training @ iter = 465900 , loss =  0.0008275929722
training @ iter = 465900 , error =  0.0
training @ iter = 466000 , loss =  0.0533460564911
training @ iter = 466000 , error =  0.02
training @ iter = 466100 , loss =  0.00687256688252
training @ iter = 466100 , error =  0.0
training @ iter = 466200 , loss =  0.00117558124475
training @ iter = 466200 , error =  0.0
training @ iter = 466300 , loss =  0.00600412208587
training @ iter = 466300 , error =  0.0
training @ iter = 466400 , loss =  0.00124458421487
training @ iter = 466400 , error =  0.0
training @ iter = 466500 , loss =  0.0155173353851
training @ iter = 466500 , error =  0.0
training @ iter = 466600 , loss =  0.000581679691095
training @ iter = 466600 , error =  0.0
training @ iter = 466700 , loss =  0.0188699439168
training @ iter = 466700 , error =  0.0
training @ iter = 466800 , loss =  0.00376558722928
training @ iter = 466800 , error =  0.0
training @ iter = 466900 , loss =  0.00651163095608
training @ iter = 466900 , error =  0.0
training @ iter = 467000 , loss =  0.00169170508161
training @ iter = 467000 , error =  0.0
training @ iter = 467100 , loss =  0.000671057088766
training @ iter = 467100 , error =  0.0
training @ iter = 467200 , loss =  0.00195149646606
training @ iter = 467200 , error =  0.0
training @ iter = 467300 , loss =  0.0733302384615
training @ iter = 467300 , error =  0.02
training @ iter = 467400 , loss =  0.0357848368585
training @ iter = 467400 , error =  0.0
training @ iter = 467500 , loss =  0.00291611370631
training @ iter = 467500 , error =  0.0
training @ iter = 467600 , loss =  0.0108319763094
training @ iter = 467600 , error =  0.0
training @ iter = 467700 , loss =  0.00850100535899
training @ iter = 467700 , error =  0.0
training @ iter = 467800 , loss =  0.00832427572459
training @ iter = 467800 , error =  0.0
training @ iter = 467900 , loss =  0.00200984720141
training @ iter = 467900 , error =  0.0
training @ iter = 468000 , loss =  0.00437594251707
training @ iter = 468000 , error =  0.0
training @ iter = 468100 , loss =  0.00251408666372
training @ iter = 468100 , error =  0.0
training @ iter = 468200 , loss =  0.0235807653517
training @ iter = 468200 , error =  0.02
training @ iter = 468300 , loss =  0.0659946128726
training @ iter = 468300 , error =  0.02
--> train minibatch error =  0.12  at iter  468374
-->  23 31900 chunk_8_50000.pkl
training @ iter = 468400 , loss =  0.00588188227266
training @ iter = 468400 , error =  0.0
training @ iter = 468500 , loss =  0.0672780200839
training @ iter = 468500 , error =  0.04
training @ iter = 468600 , loss =  0.00091996131232
training @ iter = 468600 , error =  0.0
training @ iter = 468700 , loss =  0.0235207732767
training @ iter = 468700 , error =  0.0
training @ iter = 468800 , loss =  0.00535078300163
training @ iter = 468800 , error =  0.0
training @ iter = 468900 , loss =  0.00127796339802
training @ iter = 468900 , error =  0.0
training @ iter = 469000 , loss =  0.00412615574896
training @ iter = 469000 , error =  0.0
training @ iter = 469100 , loss =  0.0137223508209
training @ iter = 469100 , error =  0.0
training @ iter = 469200 , loss =  0.0825619921088
training @ iter = 469200 , error =  0.02
training @ iter = 469300 , loss =  0.00737596629187
training @ iter = 469300 , error =  0.0
training @ iter = 469400 , loss =  0.130819022655
training @ iter = 469400 , error =  0.02
--> train minibatch error =  0.22  at iter  469430
-->  24 34700 chunk_9_50000.pkl
--> train minibatch error =  0.2  at iter  469431
-->  24 34750 chunk_9_50000.pkl
training @ iter = 469500 , loss =  0.002071675146
training @ iter = 469500 , error =  0.0
training @ iter = 469600 , loss =  0.00973535422236
training @ iter = 469600 , error =  0.0
training @ iter = 469700 , loss =  0.00369020970538
training @ iter = 469700 , error =  0.0
Epoch  19 , iteration  469737 training @ iter = 469800 , loss =  0.0151818301529
training @ iter = 469800 , error =  0.0
training @ iter = 469900 , loss =  0.0152891399339
training @ iter = 469900 , error =  0.0
validation @ iter 470000
epoch 0, iter 470000, train buffer error 0.500000 %
epoch 0, iter 470000, validation loss 0.017539
epoch 0, iter 470000, validation error 0.532000 %
patience before checkBest 480000
patience after checkBest 480000
training @ iter = 470000 , loss =  0.00241390499286
training @ iter = 470000 , error =  0.0
training @ iter = 470100 , loss =  0.00137564132456
training @ iter = 470100 , error =  0.0
training @ iter = 470200 , loss =  0.0251425281167
training @ iter = 470200 , error =  0.0
training @ iter = 470300 , loss =  0.0132805109024
training @ iter = 470300 , error =  0.0
training @ iter = 470400 , loss =  0.00582435308024
training @ iter = 470400 , error =  0.0
training @ iter = 470500 , loss =  0.00180949852802
training @ iter = 470500 , error =  0.0
training @ iter = 470600 , loss =  0.0115801254287
training @ iter = 470600 , error =  0.0
training @ iter = 470700 , loss =  0.00596172641963
training @ iter = 470700 , error =  0.0
training @ iter = 470800 , loss =  0.0608266070485
training @ iter = 470800 , error =  0.02
training @ iter = 470900 , loss =  0.00421259831637
training @ iter = 470900 , error =  0.0
training @ iter = 471000 , loss =  0.00130459934007
training @ iter = 471000 , error =  0.0
training @ iter = 471100 , loss =  0.0019132286543
training @ iter = 471100 , error =  0.0
training @ iter = 471200 , loss =  0.00663897255436
training @ iter = 471200 , error =  0.0
training @ iter = 471300 , loss =  0.000638735713437
training @ iter = 471300 , error =  0.0
training @ iter = 471400 , loss =  0.0306234695017
training @ iter = 471400 , error =  0.02
training @ iter = 471500 , loss =  0.00170459656511
training @ iter = 471500 , error =  0.0
training @ iter = 471600 , loss =  0.0121285188943
training @ iter = 471600 , error =  0.0
training @ iter = 471700 , loss =  0.00565569056198
training @ iter = 471700 , error =  0.0
training @ iter = 471800 , loss =  0.000589880917687
training @ iter = 471800 , error =  0.0
training @ iter = 471900 , loss =  0.000560678483453
training @ iter = 471900 , error =  0.0
training @ iter = 472000 , loss =  0.00363498926163
training @ iter = 472000 , error =  0.0
training @ iter = 472100 , loss =  0.00646058563143
training @ iter = 472100 , error =  0.0
training @ iter = 472200 , loss =  0.00428809504956
training @ iter = 472200 , error =  0.0
training @ iter = 472300 , loss =  0.0283198282123
training @ iter = 472300 , error =  0.02
training @ iter = 472400 , loss =  0.00637667765841
training @ iter = 472400 , error =  0.0
training @ iter = 472500 , loss =  0.138822108507
training @ iter = 472500 , error =  0.04
training @ iter = 472600 , loss =  0.00195037096273
training @ iter = 472600 , error =  0.0
training @ iter = 472700 , loss =  0.0068820239976
training @ iter = 472700 , error =  0.0
training @ iter = 472800 , loss =  0.0391006805003
training @ iter = 472800 , error =  0.04
training @ iter = 472900 , loss =  0.000934922718443
training @ iter = 472900 , error =  0.0
training @ iter = 473000 , loss =  0.0016721105203
training @ iter = 473000 , error =  0.0
training @ iter = 473100 , loss =  0.00220282841474
training @ iter = 473100 , error =  0.0
training @ iter = 473200 , loss =  0.0138417454436
training @ iter = 473200 , error =  0.0
training @ iter = 473300 , loss =  0.00675047980621
training @ iter = 473300 , error =  0.0
training @ iter = 473400 , loss =  0.00347895780578
training @ iter = 473400 , error =  0.0
training @ iter = 473500 , loss =  0.00493928510696
training @ iter = 473500 , error =  0.0
training @ iter = 473600 , loss =  0.0986616238952
training @ iter = 473600 , error =  0.02
training @ iter = 473700 , loss =  0.00139096053317
training @ iter = 473700 , error =  0.0
training @ iter = 473800 , loss =  0.000681965146214
training @ iter = 473800 , error =  0.0
training @ iter = 473900 , loss =  0.00440540304407
training @ iter = 473900 , error =  0.0
training @ iter = 474000 , loss =  0.136589571834
training @ iter = 474000 , error =  0.02
training @ iter = 474100 , loss =  0.0121991112828
training @ iter = 474100 , error =  0.0
training @ iter = 474200 , loss =  0.000337640056387
training @ iter = 474200 , error =  0.0
training @ iter = 474300 , loss =  0.00418314710259
training @ iter = 474300 , error =  0.0
training @ iter = 474400 , loss =  0.00928704161197
training @ iter = 474400 , error =  0.0
training @ iter = 474500 , loss =  0.0030562847387
training @ iter = 474500 , error =  0.0
training @ iter = 474600 , loss =  0.00131850736216
training @ iter = 474600 , error =  0.0
training @ iter = 474700 , loss =  0.000560608750675
training @ iter = 474700 , error =  0.0
training @ iter = 474800 , loss =  0.00469129253179
training @ iter = 474800 , error =  0.0
training @ iter = 474900 , loss =  0.0137899843976
training @ iter = 474900 , error =  0.0
Saving @ iter  475000
training @ iter = 475000 , loss =  0.0107243992388
training @ iter = 475000 , error =  0.0
training @ iter = 475100 , loss =  0.0349964983761
training @ iter = 475100 , error =  0.02
training @ iter = 475200 , loss =  0.00190342636779
training @ iter = 475200 , error =  0.0
training @ iter = 475300 , loss =  0.00103289040271
training @ iter = 475300 , error =  0.0
training @ iter = 475400 , loss =  0.00312271597795
training @ iter = 475400 , error =  0.0
training @ iter = 475500 , loss =  0.100569359958
training @ iter = 475500 , error =  0.02
training @ iter = 475600 , loss =  0.0291964411736
training @ iter = 475600 , error =  0.02
training @ iter = 475700 , loss =  0.00122575659771
training @ iter = 475700 , error =  0.0
training @ iter = 475800 , loss =  0.000695546506904
training @ iter = 475800 , error =  0.0
training @ iter = 475900 , loss =  0.012637517415
training @ iter = 475900 , error =  0.0
training @ iter = 476000 , loss =  0.000585991365369
training @ iter = 476000 , error =  0.0
training @ iter = 476100 , loss =  0.000917132245377
training @ iter = 476100 , error =  0.0
training @ iter = 476200 , loss =  0.00194465217646
training @ iter = 476200 , error =  0.0
training @ iter = 476300 , loss =  0.00269857677631
training @ iter = 476300 , error =  0.0
training @ iter = 476400 , loss =  0.0533166900277
training @ iter = 476400 , error =  0.04
training @ iter = 476500 , loss =  0.00249996152706
training @ iter = 476500 , error =  0.0
training @ iter = 476600 , loss =  0.0204649455845
training @ iter = 476600 , error =  0.0
training @ iter = 476700 , loss =  0.000347421853803
training @ iter = 476700 , error =  0.0
training @ iter = 476800 , loss =  0.00288665690459
training @ iter = 476800 , error =  0.0
training @ iter = 476900 , loss =  0.00129514362197
training @ iter = 476900 , error =  0.0
training @ iter = 477000 , loss =  0.00189758616034
training @ iter = 477000 , error =  0.0
training @ iter = 477100 , loss =  0.0119726350531
training @ iter = 477100 , error =  0.0
training @ iter = 477200 , loss =  0.00713797332719
training @ iter = 477200 , error =  0.0
training @ iter = 477300 , loss =  0.0185515619814
training @ iter = 477300 , error =  0.0
training @ iter = 477400 , loss =  0.000376283191144
training @ iter = 477400 , error =  0.0
--> train minibatch error =  0.18  at iter  477403
-->  7 33350 chunk_17_50000.pkl
training @ iter = 477500 , loss =  0.0131328795105
training @ iter = 477500 , error =  0.0
training @ iter = 477600 , loss =  0.00115676608402
training @ iter = 477600 , error =  0.0
training @ iter = 477700 , loss =  0.00624979799613
training @ iter = 477700 , error =  0.0
training @ iter = 477800 , loss =  0.0127986241132
training @ iter = 477800 , error =  0.02
--> train minibatch error =  0.12  at iter  477831
-->  8 4750 chunk_18_50000.pkl
training @ iter = 477900 , loss =  0.00490517448634
training @ iter = 477900 , error =  0.0
training @ iter = 478000 , loss =  0.00290235644206
training @ iter = 478000 , error =  0.0
training @ iter = 478100 , loss =  0.00202034739777
training @ iter = 478100 , error =  0.0
training @ iter = 478200 , loss =  0.000663606741
training @ iter = 478200 , error =  0.0
training @ iter = 478300 , loss =  0.00254981429316
training @ iter = 478300 , error =  0.0
--> train minibatch error =  0.24  at iter  478343
-->  8 30350 chunk_18_50000.pkl
training @ iter = 478400 , loss =  0.00236631534062
training @ iter = 478400 , error =  0.0
training @ iter = 478500 , loss =  0.00299843074754
training @ iter = 478500 , error =  0.0
training @ iter = 478600 , loss =  0.00414606230333
training @ iter = 478600 , error =  0.0
training @ iter = 478700 , loss =  0.179982542992
training @ iter = 478700 , error =  0.02
training @ iter = 478800 , loss =  0.00494447955862
training @ iter = 478800 , error =  0.0
training @ iter = 478900 , loss =  0.0021956381388
training @ iter = 478900 , error =  0.0
--> train minibatch error =  0.12  at iter  478947
-->  9 10550 chunk_19_50000.pkl
training @ iter = 479000 , loss =  0.0575172677636
training @ iter = 479000 , error =  0.02
training @ iter = 479100 , loss =  0.00504142744467
training @ iter = 479100 , error =  0.0
training @ iter = 479200 , loss =  0.00466363644227
training @ iter = 479200 , error =  0.0
training @ iter = 479300 , loss =  0.000462416006485
training @ iter = 479300 , error =  0.0
training @ iter = 479400 , loss =  0.0221098754555
training @ iter = 479400 , error =  0.0
training @ iter = 479500 , loss =  0.000545495888218
training @ iter = 479500 , error =  0.0
training @ iter = 479600 , loss =  0.00304424669594
training @ iter = 479600 , error =  0.0
training @ iter = 479700 , loss =  0.0104845725
training @ iter = 479700 , error =  0.0
training @ iter = 479800 , loss =  0.00730961095542
training @ iter = 479800 , error =  0.0
training @ iter = 479900 , loss =  0.00442578690127
training @ iter = 479900 , error =  0.0
--> train minibatch error =  0.18  at iter  479918
-->  10 9100 chunk_20_50000.pkl
patience <= iter 480000 480000
Optimization complete
test set =  100000
Convolutional Layer parameters loaded
Convolutional Layer parameters loaded
Convolutional Layer parameters loaded
Hidden Layer parameters loaded
Logistic Regression parameters loaded
test_pred: [[  9.99028563e-01   9.71484988e-04]
 [  1.31646113e-03   9.98683512e-01]
 [  5.28461765e-04   9.99471605e-01]
 ..., 
 [  9.99307513e-01   6.92535425e-04]
 [  2.81896966e-04   9.99718130e-01]
 [  4.43860004e-03   9.95561361e-01]]
Best validation score of 0.532000 % obtained at iteration 400000, with test performance 0.588000 %
